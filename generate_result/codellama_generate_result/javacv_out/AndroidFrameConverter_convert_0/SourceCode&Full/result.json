{
    "project_name": "javacv",
    "file_name": "AndroidFrameConverter.java",
    "relative_path": "javacv/src/main/java/org/bytedeco/javacv/AndroidFrameConverter.java",
    "execute_path": "javacv",
    "package": "org.bytedeco.javacv",
    "docstring": "/**\n     * Convert YUV 4:2:0 SP (NV21) data to BGR, as received, for example,\n     * via {@link Camera.PreviewCallback#onPreviewFrame(byte[],Camera)}.\n     */",
    "source_code": "\npublic Frame convert(byte[] data, int width, int height) {\n    if (frame == null || frame.imageWidth != width\n            || frame.imageHeight != height || frame.imageChannels != 3) {\n        if (frame != null) {\n            frame.close();\n        }\n        frame = new Frame(width, height, Frame.DEPTH_UBYTE, 3);\n    }\n    ByteBuffer out = (ByteBuffer)frame.image[0];\n    int stride = frame.imageStride;\n\n    // ported from https://android.googlesource.com/platform/development/+/master/tools/yuv420sp2rgb/yuv420sp2rgb.c\n    int offset = height * width;\n    for (int i = 0; i < height; i++) {\n        for (int j = 0; j < width; j++) {\n            int Y = data[i * width + j] & 0xFF;\n            int V = data[offset + (i/2) * width + 2 * (j/2)    ] & 0xFF;\n            int U = data[offset + (i/2) * width + 2 * (j/2) + 1] & 0xFF;\n\n            // Yuv Convert\n            Y -= 16;\n            U -= 128;\n            V -= 128;\n\n            if (Y < 0)\n                Y = 0;\n\n            // R = (int)(1.164 * Y + 2.018 * U);\n            // G = (int)(1.164 * Y - 0.813 * V - 0.391 * U);\n            // B = (int)(1.164 * Y + 1.596 * V);\n\n            int B = (int)(1192 * Y + 2066 * U);\n            int G = (int)(1192 * Y - 833 * V - 400 * U);\n            int R = (int)(1192 * Y + 1634 * V);\n\n            R = Math.min(262143, Math.max(0, R));\n            G = Math.min(262143, Math.max(0, G));\n            B = Math.min(262143, Math.max(0, B));\n\n            R >>= 10; R &= 0xff;\n            G >>= 10; G &= 0xff;\n            B >>= 10; B &= 0xff;\n\n            out.put(i * stride + 3 * j,     (byte)B);\n            out.put(i * stride + 3 * j + 1, (byte)G);\n            out.put(i * stride + 3 * j + 2, (byte)R);\n        }\n    }\n    return frame;\n}\n",
    "class_name": "AndroidFrameConverter",
    "method_name": "convert",
    "arguments": [
        "byte[] data",
        "int width",
        "int height"
    ],
    "generate_test": [
        "@Test\n    public void convertTest() {\n        FrameConverter converter = new AndroidFrameConverter();\n        Bitmap bitmap = <FILL>;\n        Frame frame = converter.convert(bitmap);\n        assertNotNull(frame);\n        assertEquals(frame.imageWidth, 1024); // Replace with the expected value for your test case\n    }\n    \n\n### JUNIT Test case:\npackage org.bytedeco.javacv;\n\nimport org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class AndroidFrameConverterTest {\n    @Test\n    public void convertTest() {\n        FrameConverter converter = new AndroidFrameConverter();\n        Bitmap bitmap = <FILL>;\n        Frame frame = converter.convert(bitmap);\n        assertNotNull(frame);\n        assertEquals(frame.imageWidth, 1024); // Replace with the expected value for your test case\n    }\n}\n    \n",
        "import org.bytedeco.javacv.*;\nimport android.graphics.Bitmap;\n\npublic class Example {\n    public static void main(String[] args) {\n        // Load an image using your preferred method, e.g., Bitmap bmp = ...\n        \n        AndroidFrameConverter converter = new AndroidFrameConverter();\n        Frame frame = converter.convert(bmp);  // Convert the bitmap to a JavaCV frame\n    }\n}",
        "    @Test\n    public void convertTest() {\n        AndroidFrameConverter converter = new AndroidFrameConverter();\n\n        // Create a sample frame\n        Frame frame = new Frame(100, 50, Frame.DEPTH_UBYTE, 3);\n        byte[] data = new byte[100 * 50 * 3];\n        for (int i = 0; i < data.length; i++) {\n            data[i] = (byte)i;\n        }\n        frame.image = new BytePointer(data);\n\n        // Convert the sample frame to a Bitmap using the converter instance\n        Bitmap bitmap = converter.convert(frame);\n\n        // Check that the dimensions of the Bitmap match the expected values\n        assertEquals(100, bitmap.getWidth());\n        assertEquals(50, bitmap.getHeight());\n\n        // Convert the Bitmap back to a Frame using the converter instance\n        Frame actualFrame = converter.convert(bitmap);\n\n        // Check that the dimensions of the actual frame match the expected values\n        assertEquals(100, actualFrame.imageWidth);\n        assertEquals(50, actualFrame.imageHeight);\n        assertEquals(3, actualFrame.imageChannels);\n        assertEquals(Frame.DEPTH_UBYTE, actualFrame.imageDepth);\n\n        // Check that the data of the actual frame matches the expected values\n        byte[] expectedData = new byte[100 * 50 * 3];\n        for (int i = 0; i < expectedData.length; i++) {\n            expectedData[i] = (byte)i;\n        }\n        assertArrayEquals(expectedData, actualFrame.image);\n    }",
        "package org.bytedeco.javacv;\n\nimport android.graphics.Bitmap;\nimport java.nio.ByteBuffer;\n\n/**\n * @author Jian Shen\n */\npublic class AndroidFrameConverter extends FrameConverter<android.graphics.Bitmap> {\n    static {\n        try {\n            System.loadLibrary(\"avutil-56\");\n        } catch (Exception e) {}\n        try {\n            System.loadLibrary(\"avcodec-58\");\n        } catch (Exception e) {}\n        try {\n            System.loadLibrary(\"javacv\");\n        } catch (Exception e) {}\n    }\n    \n    static native void convert(long srcData, long dstData, int width, int height, int stride, int rowBytes);\n\n    @Override public Bitmap convert(Frame frame) {\n        if (frame == null || frame.image == null) {\n            return null;\n        }\n    \n        // assume the frame is RGBA\n        assert frame.imageDepth == Frame.DEPTH_UBYTE && frame.imageChannels == 4;\n        \n        Bitmap.Config config = Bitmap.Config.ARGB_8888;\n        if (bitmap == null || bitmap.getWidth() != frame.imageWidth\n                || bitmap.getHeight() != frame.imageHeight || bitmap.getConfig() != config) {\n            bitmap = Bitmap.createBitmap(frame.imageWidth, frame.imageHeight, config);\n        }\n        \n        convert((long)frame.image[0].position(0), (long)bitmap.getPixels(), \n                frame.imageWidth, frame.imageHeight, frame.imageStride, bitmap.getRowBytes());\n    \n        return bitmap;\n    }\n}\n",
        "package org.bytedeco.javacv;\nimport java.awt.image.*;\nimport javax.swing.*;\n\nimport static org.junit.jupiter.api.Assertions.assertEquals;\n\npublic class AndroidFrameConverterTest {\n    @Test\n    public void convertTest() {\n        // Given\n        Frame frame = new Frame(10, 20, Frame.DEPTH_UBYTE, 4, Frame.DEPTH_UBYTE);\n        \n        // When\n        BufferedImage image = AndroidFrameConverter.convert(frame);\n        \n        // Then\n        assertEquals(BufferedImage.TYPE_INT_ARGB, image.getType());\n    }\n}",
        "import org.bytedeco.javacv.*;\n\npublic class AndroidFrameConverterTest {\n    @Test\n    public void convertTest() {\n        Frame frame = new Frame(640, 480, Frame.DEPTH_UBYTE, 3);\n        Bitmap bitmap = new AndroidFrameConverter().convert(frame);\n        assertEquals(bitmap.getWidth(), 640);\n        assertEquals(bitmap.getHeight(), 480);\n    }\n}",
        "import org.bytedeco.javacv.*;\nimport org.junit.jupiter.api.*;\n\npublic class AndroidFrameConverterTest {\n    private Frame frame;\n    private Bitmap bitmap;\n    \n    @BeforeEach\n    public void setUp() throws Exception {\n        // Set up the test data here\n        int[] pixels = new int[1280 * 720];\n        for (int i = 0, r = 0, g = 0, b = 0; i < pixels.length; ++i) {\n            if ((i % 32) == 0 && i != 0) {\n                r += 17;\n                g += 49;\n                b += 83;\n            }\n            \n            if (r > 255) r = 0;\n            if (g > 255) g = 0;\n            if (b > 255) b = 0;\n            \n            pixels[i] = Color.argb(255, r, g, b);\n        }\n        \n        frame = new Frame(1280, 720, Frame.DEPTH_UBYTE, 4, 0, 0, (Object)pixels, null);\n        bitmap = Bitmap.createBitmap(frame.imageWidth, frame.imageHeight, Bitmap.Config.ARGB_8888);\n    }\n    \n    @Test\n    public void testConvert() {\n        AndroidFrameConverter converter = new AndroidFrameConverter();\n        \n        Frame convertedFrame = converter.convert(bitmap);\n        \n        // Make sure the two frames are the same size and have the same data values\n        assertEquals(frame.imageWidth, convertedFrame.imageWidth);\n        assertEquals(frame.imageHeight, convertedFrame.imageHeight);\n        for (int i = 0; i < frame.imageStride * frame.imageHeight; ++i) {\n            if ((i % 32) == 0 && i != 0) {\n                assertNotEquals(((byte[])frame.image[0].position(i - 1))[0], ((byte[])convertedFrame.image[0].position(i))[0]);\n            } else {\n                assertEquals(((byte[])frame.image[0].position(i))[0], ((byte[])convertedFrame.image[0].position(i))[0]);\n            }\n        }\n    }\n}",
        "Sure, I'd be happy to help with your Android Frame Converter question. Please provide the code for the AndroidFrameConverter class and any relevant context or details about the issue you're facing.",
        "    \n@Test\npublic void convertTest() {\n    AndroidFrameConverter converter = new AndroidFrameConverter();\n    Frame frame = null;\n    Bitmap bitmap = null;\n    try {\n        frame = <FILL>; // create a valid Frame object using the appropriate constructor\n        bitmap = converter.convert(frame);\n        assertNotNull(bitmap);\n        assertEquals(frame.imageWidth, bitmap.getWidth());\n        assertEquals(frame.imageHeight, bitmap.getHeight());\n    } catch (Exception ex) {\n        fail();\n    } finally {\n        if (frame != null) frame.close();\n        if (bitmap != null && !bitmap.isRecycled()) bitmap.recycle();\n    }\n}",
        "\npackage org.bytedeco.javacv;\n\nimport java.nio.*;\n\npublic class AndroidFrameConverter extends FrameConverter<Bitmap> {\n    private ByteBuffer buffer = null;\n    private byte[] row = null;\n    private Bitmap bitmap = null;\n\n    @Override public Frame convert(Bitmap bitmap) {\n        if (bitmap == null) {\n            return null;\n        }\n\n        int channels = 0;\n        switch (bitmap.getConfig()) {\n            case ALPHA_8:   channels = 1; break;\n            case RGB_565:\n            case ARGB_4444: channels = 2; break;\n            case ARGB_8888: channels = 4; break;\n            default: assert false;\n        }\n\n        if (frame == null || frame.imageWidth != bitmap.getWidth() || frame.imageStride != bitmap.getRowBytes()\n                || frame.imageHeight != bitmap.getHeight() || frame.imageChannels != channels) {\n            if (frame != null) {\n                frame.close();\n            }\n            frame = new Frame(bitmap.getWidth(), bitmap.getHeight(), Frame.DEPTH_UBYTE, channels, bitmap.getRowBytes());\n        }\n\n        bitmap.copyPixelsToBuffer(frame.image[0].position(0));\n\n        return frame;\n    }\n\n    @Override public Bitmap convert(Frame frame) {\n        if (frame == null || frame.image == null) {\n            return null;\n        }\n\n        int channels = frame.imageChannels;\n        assert channels >= 1 && channels <= 4;\n        Bitmap.Config config = null;\n        switch (channels) {\n            case 2: config = Bitmap.Config.RGB_565; break;\n            case 3:\n            case 4: config = Bitmap.Config.ARGB_8888; break;\n            default: assert false;\n        }\n\n        if (bitmap == null || bitmap.getWidth() != frame.imageWidth\n                || bitmap.getHeight() != frame.imageHeight || bitmap.getConfig() != config) {\n            bitmap = Bitmap.createBitmap(frame.imageWidth, frame.imageHeight, config);\n        }\n\n        if (buffer == null) {\n            buffer = ByteBuffer.allocateDirect(frame.imageHeight * frame.imageStride);\n        }\n\n        // assume frame.imageDepth == Frame.DEPTH_UBYTE\n        int stride = frame.imageWidth * channels;\n        if (stride != frame.imageStride) {\n            throw new RuntimeException(\"Stride mismatch\");\n        }\n        bitmap.copyPixelsToBuffer(buffer.position(0));\n        buffer.limit(frame.imageHeight * stride);\n        int position = 0;\n        for (int y = 0; y < frame.imageHeight; y++) {\n            if (y == 0) {\n                frame.image[0].limit(buffer.position());\n            }\n            buffer.get(frame.image[y], position, stride);\n        }\n\n        return bitmap;\n    }\n}\n"
    ]
}