{
    "project_name": "javacv",
    "file_name": "ObjectFinder.java",
    "relative_path": "javacv/src/main/java/org/bytedeco/javacv/ObjectFinder.java",
    "execute_path": "javacv",
    "package": "org.bytedeco.javacv",
    "docstring": "/** a rough implementation for object location */",
    "source_code": "\ndouble[] locatePlanarObject(KeyPointVector objectKeypoints, Mat objectDescriptors,\n        KeyPointVector imageKeypoints, Mat imageDescriptors, double[] srcCorners) {\n    ptpairs.clear();\n    if (settings.useFLANN) {\n        flannFindPairs(objectDescriptors, imageDescriptors);\n    } else {\n        findPairs(objectDescriptors, imageDescriptors);\n    }\n    int n = ptpairs.size()/2;\n    logger.info(n + \" matching pairs found\");\n    if (n < settings.matchesMin) {\n        return null;\n    }\n\n    pt1 .resize(n);\n    pt2 .resize(n);\n    mask.resize(n);\n    FloatBuffer pt1Idx = pt1.createBuffer();\n    FloatBuffer pt2Idx = pt2.createBuffer();\n    for (int i = 0; i < n; i++) {\n        Point2f p1 = objectKeypoints.get(ptpairs.get(2*i)).pt();\n        pt1Idx.put(2*i, p1.x()); pt1Idx.put(2*i+1, p1.y());\n        Point2f p2 = imageKeypoints.get(ptpairs.get(2*i+1)).pt();\n        pt2Idx.put(2*i, p2.x()); pt2Idx.put(2*i+1, p2.y());\n    }\n\n    H = findHomography(pt1, pt2, CV_RANSAC, settings.ransacReprojThreshold, mask, 2000, 0.995);\n    if (H.empty() || countNonZero(mask) < settings.matchesMin) {\n        return null;\n    }\n\n    double[] h = (double[])H.createIndexer(false).array();\n    double[] dstCorners = new double[srcCorners.length];\n    for(int i = 0; i < srcCorners.length/2; i++) {\n        double x = srcCorners[2*i], y = srcCorners[2*i + 1];\n        double Z = 1/(h[6]*x + h[7]*y + h[8]);\n        double X = (h[0]*x + h[1]*y + h[2])*Z;\n        double Y = (h[3]*x + h[4]*y + h[5])*Z;\n        dstCorners[2*i    ] = X;\n        dstCorners[2*i + 1] = Y;\n    }\n    return dstCorners;\n}\n",
    "class_name": "ObjectFinder",
    "method_name": "locatePlanarObject",
    "arguments": [
        "KeyPointVector objectKeypoints",
        "Mat objectDescriptors",
        "KeyPointVector imageKeypoints",
        "Mat imageDescriptors",
        "double[] srcCorners"
    ],
    "generate_test": [
        "@Disabled\n@Test\npublic void locatePlanarObjectTest() {\n    // Prepare the input data (the object to find and an image with that object)\n    IplImage object = ...;\n    IplImage image  = ...;\n    \n    // Set up the ObjectFinder parameters\n    ObjectFinder.Settings settings = new ObjectFinder.Settings();\n    settings.objectImage = object;\n    settings.useFLANN = true;\n    settings.ransacReprojThreshold = 5;\n    \n    // Create a new ObjectFinder instance with the given parameters\n    ObjectFinder finder = new ObjectFinder(settings);\n    \n    // Find the object in the image and display the results\n    double[] dst_corners = finder.find(image);\n    if (dst_corners != null) {\n        System.out.println(\"Object found!\");\n        \n        IplImage correspond = ...;  // create an image to visualize the matching keypoints and their corresponding positions\n        \n        for (int i = 0; i < finder.ptpairs.size(); i += 2) {\n            Point2f pt1 = finder.objectKeypoints.get(finder.ptpairs.get(i));\n            Point2f pt2 = finder.imageKeypoints.get(finder.ptpairs.get(i + 1));\n            line(cvarrToMat(correspond), new Point(Math.round(pt1.x()), Math.round(pt1.y())),\n                    new Point(Math.round(pt2.x()), Math.round(pt2.y() + object.height())),\n                    Scalar.WHITE, 1, 8, 0);\n        }\n        \n        CanvasFrame objectFrame = ...; // create a canvas to display the detected object\n        objectFrame.showImage(converter.convert(object));\n        \n        CanvasFrame correspondFrame = ...; // create a canvas to visualize the matching keypoints and their corresponding positions\n        correspondFrame.showImage(converter.convert(correspond));\n    } else {\n        System.out.println(\"Object not found!\");\n    }\n}",
        "<FILL>\n",
        "import org.bytedeco.javacv.*;\nimport static org.bytedeco.javacpp.opencv_core.*;\nimport static org.bytedeco.javacpp.opencv_imgproc.*;\nimport static org.bytedeco.javacpp.opencv_features2d.*;\nimport static org.bytedeco.javacpp.opencv_flann.*;\nimport java.util.*;\n\npublic class ObjectFinder {\n    public static void main(String[] args) throws Exception {\n        String objectFilename = \"/path/to/object/image\";\n        String sceneFilename  = \"/path/to/scene/image\";\n        \n        IplImage object = cvLoadImage(objectFilename, CV_LOAD_IMAGE_GRAYSCALE);\n        IplImage image  = cvLoadImage(sceneFilename,  CV_LOAD_IMAGE_GRAYSCALE);\n        if (object == null || image == null) {\n            System.err.println(\"Can not load \" + objectFilename + \" and/or \" + sceneFilename);\n            System.exit(-1);\n        }\n        \n        // Extract keypoints from the object and scene images\n        IplImageKeypoint objectKeypoints = cvCreateKeyPoint(NULL);\n        CvExtractSURFastFeaturePoints(object, 0, NULL, objectKeypoints);\n        int nObjectKeypoints = cvSeqPush(objectKeypoints);\n        \n        IplImageKeypoint imageKeypoints = cvCreateKeyPoint(NULL);\n        CvExtractSURFastFeaturePoints(image, 0, NULL, imageKeypoints);\n        int nImageKeypoints = cvSeqPush(imageKeypoints);\n        \n        // Find object keypoints in the scene\n        IplImageMatch match = cvCreateImageMatch(NULL);\n        CvFlannBasedFeatureMatch(objectKeypoints, nObjectKeypoints,\n            imageKeypoints, nImageKeypoints, match);\n        \n        // Get matches with distance less than 20 pixels\n        int nGoodMatches;\n        float minDistance = 20.f;\n        IplImageMatch goodMatch = cvCreateImageMatch(NULL);\n        CvGetMinDistMatch(match, minDistance, nGoodMatches, goodMatch);\n        \n        // Draw the lines between matches and the object in the scene\n        IplImage correspondence = cvCreateImage(CV_8U, 1, NULL);\n        cvCvtColor(correspondence, CV_RGB(255, 0, 0));\n        for (int i = 0; i < nGoodMatches; ++i) {\n            CvDrawLine(object, objectKeypoints[i], image, imageKeypoints[i + 1]);\n            CvDrawMarker(image, imageKeypoints[i], CV_RGB(255, 0, 0), 3);\n        }\n        \n        // Save the correspondence image to disk\n        cvSaveImage(\"correspondence.png\", correspondence);\n    }\n}",
        "\npublic class ObjectFinder {\n    private static final Logger logger = Logger.getLogger(ObjectFinder.class.getName());\n    \n    public static class Settings extends Object {\n        Mat objectImage; // the image to be detected\n        boolean useFLANN; // use FLANN-based matcher (true) or BruteForce matcher (false)\n        int matchesMin; // the minimal number of good matches required for homography estimation\n        double ransacReprojThreshold; // RANSAC reprojection error threshold\n        \n        Settings() {}\n    }\n    \n    private List<KeyPoint> objectKeypoints, imageKeypoints;\n    private Mat ptpairs = new Mat();\n    \n    public ObjectFinder(Settings settings) {\n        Mat mask = new Mat();\n        FeatureDetector detector = ORB.create(500);\n        \n        // extract keypoints from object and image images\n        detector.detect(settings.objectImage, new MatOfKeyPoint(), mask);\n        objectKeypoints = detector.describe(settings.objectImage, new Mat(), mask);\n        logger.info(\"Object: \" + objectKeypoints.size() + \" key points\");\n        \n        detector = ORB.create();\n        MatOfKeyPoint imageKeypoints = new MatOfKeyPoint();\n        \n        // extract keypoints from the image and their descriptors\n        mask = new Mat(image);\n        detector.detect(image, imageKeypoints, mask);\n        imageKeypoints = detector.describe(image, null, mask);\n        logger.info(\"Image: \" + imageKeypoints.size() + \" key points\");\n        \n        // match object and image keypoints\n        if (settings.useFLANN) {\n            logger.info(\"Matching using FLANN\");\n            \n            FlannBasedMatcher matcher = new FlannBasedMatcher();\n            MatOfDMatch matches = new MatOfDMatch(1);\n            \n            // find the k closest key points to object keypoints\n            matcher.match(imageKeypoints, objectKeypoints, matches);\n            \n            \n            // filter out best matches using Lowe's ratio test\n            mask = new Mat(matches);\n            double minDistRatio = 0.6;\n            for (int i = 0; i < matches.rows(); i++) {\n                if (matches.get(i, 0) > settings.matchesMin) {\n                    continue;\n                }\n                // keep the key points which have distance ratio smaller than minDistRatio\n                mask.put((int) matches.get(i, 1), (byte) 255);\n            }\n            \n            // select only pairs of keypoints that satisfy Lowe's ratio test\n            mask = new Mat(mask);\n            MatOfByte goodMatchesMask = new MatOfByte();\n            Core.inRange(mask, new Scalar(0), new Scalar(1), goodMatchesMask);\n            \n            // select only pairs of key points that satisfy distance ratio test\n            ptpairs = new MatOfInt(goodMatchesMask.rows(), 2);\n            int index = 0;\n            for (int i = 0; i < goodMatchesMask.rows(); i++) {\n                if (goodMatchesMask.get(i, 0) != (byte) 255) {\n                    continue;\n                }\n                ptpairs.put((int) index++, (int) matches.get(i, 0));\n                ptpairs.put((int) index++, (int) matches.get(i, 1));\n            }\n        } else {\n            logger.info(\"Matching using BruteForce\");\n            \n            // match object and image keypoints using brute force matching algorithm\n            BFMatcher matcher = new BFMatcher();\n            MatOfDMatch matches = new MatOfDMatch(1);\n            \n            matcher.match(imageKeypoints, objectKeypoints, matches);\n            ptpairs = new MatOfInt(matches.size(), 2);\n            for (int i = 0; i < matches.rows(); i++) {\n                ptpairs.put((int) i * 2 + 0, (int) matches.get(i, 0));\n                ptpairs.put((int) i * 2 + 1, (int) matches.get(i, 1));\n            }\n        }\n        \n        // draw only inliers\n        MatOfByte drawMatchesMask = new MatOfByte();\n        Core.inRange(drawMatchesMask, new Scalar(0), new Scalar(1), drawMatchesMask);\n        Imgproc.putText(image, \"matches: \" + ptpairs.size(), new Point(5, 20), Core.FONT_HERSHEY_SIMPLEX, new Scalar(1), 1, false);\n        \n        // draw only good matches\n        MatOfByte inliersMask = new MatOfByte();\n        Core.inRange(inliersMask, new Scalar(0), new Scalar(1), inliersMask);\n        for (int i = 0; i < ptpairs.rows(); i++) {\n            int queryIdx = (int) ptpairs.get(i, 0);\n            int trainIdx = (int) ptpairs.get(i, 1);\n            inliersMask.put((int) queryIdx, (byte) 255);\n            inliersMask.put((int) trainIdx, (byte) 255);\n        }\n        \n        // draw only inliers\n        Imgproc.putText(image, \"inliers: \" + ptpairs.size(), new Point(5, 30), Core.FONT_HERSHEY_SIMPLEX, new Scalar(1), 1, false);\n        \n        // show image with inliers and matches\n        Imgproc.putText(image, \"src: \" + objectKeypoints.size() + \", dst: \" + imageKeypoints.size(), new Point(5, 40), Core.FONT_HERSHEY_SIMPLEX, new Scalar(1), 1, false);\n        Imgproc.putText(image, \"good matches: \" + ptpairs.rows() + \", k=2\", new Point(5, 50), Core.FONT_HERSHEY_SIMPLEX, new Scalar(1), 1, false);\n        Imgproc.putText(image, \"draw matches: \" + drawMatchesMask.rows(), new Point(5, 60), Core.FONT_HERSHEY_SIMPLEX, new Scalar(1), 1, false);\n        \n        // show image with inliers and matches\n        Imgcodec imgEncoder = Imgcodec.createImgCodec();\n        String encodedImageString;\n        if (imgEncoder != null) {\n            encodedImageString = imgEncoder.encodeBitmap(image, Imgcodec.JPEG, 85).toString();\n            \n            // save image with inliers and matches to file\n            FileOutputStream outputStream = new FileOutputStream(\"matched_keypoints\" + System.currentTimeMillis() + \".jpg\");\n            if (outputStream != null) {\n                outputStream.write(encodedImageString.getBytes());\n                \n                outputStream.close();\n            }\n        } else {\n            logger.info(\"Failed to load imgEncoder\");\n            \n            // draw matches on the image itself\n            MatOfByte drawMatchesMask = new MatOfByte();\n            Core.inRange(drawMatchesMask, new Scalar(0), new Scalar(1), drawMatchesMask);\n            Imgproc.cvtDrawMatches(imageKeypoints, objectDescriptors, imageDescriptors, matches, 2, new Scalar(50));\n            \n            // show image with inliers and matches\n            MatOfByte inliersMask = new MatOfByte();\n            Core.inRange(inliersMask, new Scalar(0), new Scalar(1), inliersMask);\n            Imgproc.cvtDrawMatches(imageKeypoints, objectDescriptors, imageDescriptors, ptpairs, 2, new Scalar(50));\n        }\n        \n        // free resources\n        if (inliersMask != null) {\n            inliersMask.release();\n            \n            logger.info(\"Released resources\");\n        }\n    }\n    \n    /**\n     * \n     */\n    @Test\n    public void testLocatePlanarObject() throws Exception {\n        \n        // debug mode: set debug to true, false otherwise\n        boolean debug = false;\n        \n        \n        \n        // Setup test\n        logger.info(\"Setup test\");\n        Mat imgRgba = Imgcodec.imread(new File(filePath + \"palm.jpg\"));\n        Imgproc.cvtColor(imgRgba, imgRgba, Core.CV_BGR2RGB);\n        \n        \n        // detect object in the image\n        MatOfKeyPoint keypoints = new MatOfKeyPoint();\n        Mat descriptors = new Mat();\n        Features2d.drawKeypoints(imgRgba, keypoints, imgRgba, new Scalar(-1), 4);\n        \n        \n        // show detected object in the image\n        Imgproc.putText(imgRgba, \"Detected objects: \" + keypoints.size(), new Point(5, 20), Core.FONT_HERSHEY_SIMPLEX, new Scalar(-1), 2);\n        \n        \n        // draw detected object in the image\n        MatOfByte drawKeypoints = new MatOfByte();\n        Core.inRange(drawKeypoints, new Scalar(0), new Scalar(1), drawKeypoints);\n        Features2d.drawKeypoints(imgRgba, keypoints, imgRgba, new Scalar(-1), 4);\n        \n        \n        // show image with drawn detected object in the image\n        Imgproc.putText(imgRgba, \"Draw keypoints: \" + drawKeypoints.rows(), new Point(5, 30), Core.FONT_HERSHEY_SIMPLEX, new Scalar(-1), 2);\n        \n        \n        // create a list of points to be used for the detection\n        List<MatOfPoint> pointList = new ArrayList<>();\n        for (int i = 0; i < keypoints.size().height; i++) {\n            MatOfPoint matOfPoint = keypoints.row(i);\n            \n            \n            // add the points to the list of points to be used for the detection\n            pointList.add(matOfPoint);\n        }\n        \n        \n        \n        // free resources\n        if (keypoints != null) {\n            keypoints.release();\n            \n            logger.info(\"Released resources\");\n        }\n        \n        \n        // Setup planar object detection test\n        logger.info(\"Setup planar object detection test\");\n        Mat imgPlanar = Imgcodec.imread(new File(filePath + \"palm.jpg\"));\n        \n        \n        // detect planar objects in the image\n        keypoints = new MatOfKeyPoint();\n        descriptors = new Mat();\n        Features2d.detectPlanarObject(imgPlanar, keypoints, descriptors);\n        \n        \n        // show detected object in the image\n        Imgproc.cvtColor(imgPlanar, imgPlanar, Core.CV_BGR2RGB);\n        Features2d.drawKeyPoints(imgPlanar, keypoints, imgPlanar, new Scalar(-1), 4);\n        \n        \n        // draw detected object in the image\n        MatOfByte drawPlanarObject = new MatOfByte();\n        Core.inRange(drawPlanarObject, new Scalar(0), new Scalar(1), drawPlanarObject);\n        Features2d.drawPlanarObjects(imgPlanar, keypoints, descriptors, imgPlanar, new Scalar(-1), 4);\n        \n        \n        // show image with drawn detected object in the image\n        Imgproc.putText(imgPlanar, \"Draw planar objects: \" + drawPlanarObject.rows(), new Point(5, 30), Core.FONT_HERSHEY_SIMPLEX, new Scalar(-1), 2);\n        \n        \n        // create a list of points to be used for the detection\n        pointList = new ArrayList<>();\n        for (int i = 0; i < keypoints.size().height; i++) {\n            MatOfPoint matOfPoint = keypoints.row(i);\n            \n            \n            // add the points to the list of points to be used for the detection\n            pointList.add(matOfPoint);\n        }\n        \n        \n        \n        // free resources\n        if (keypoints != null) {\n            keypoints.release();\n            \n            logger.info(\"Released resources\");\n        }\n    }\n    \n}",
        "\n<FILL>\n",
        "\n@Test\npublic void locatePlanarObjectTest() {\n    String objectFilename = \"/usr/local/share/OpenCV/samples/c/box.png\";\n    String sceneFilename  = \"/usr/local/share/OpenCV/samples/c/box_in_scene.png\";\n\n    IplImage object = cvLoadImage(objectFilename, IMREAD_GRAYSCALE);\n    IplImage image  = cvLoadImage(sceneFilename,  IMREAD_GRAYSCALE);\n    if (object == null || image == null) {\n        System.err.println(\"Can not load \" + objectFilename + \" and/or \" + sceneFilename);\n        System.exit(-1);\n    }\n\n    IplImage correspond = IplImage.create(image.width(), object.height()+ image.height(), 8, 1);\n    cvSetImageROI(correspond, cvRect(0, 0, object.width(), object.height()));\n    cvCopy(object, correspond);\n    cvSetImageROI(correspond, cvRect(0, object.height(), correspond.width(), correspond.height()));\n    cvCopy(image,\n    if (dst_corners != null) {\n        for (int i = 0; i < 4; i++) {\n            int j = (i+1)%4;\n            int x1 = Math.round(dst_corners[2*i]);\n            int y1 = Math.round(dst_corners[2*i + 1]) + object.height();\n            int x2 = Math.round(dst_corners[2*j]);\n            int y2 = Math.round(dst_corners[2*j + 1]) + object.height();\n            line(cvarrToMat(correspond), new Point(x1, y1),\n                    new Point(x2, y2),\n                    Scalar.WHITE, 1, 8, 0);\n        }\n        for (int i = 0; i < finder.ptpairs.size(); i += 2) {\n            Point2f pt1 = finder.objectKeypoints.get(finder.ptpairs.get(i));\n            Point2f pt2 = finder.imageKeypoints.get(finder.ptpairs.get(i + 1));\n            line(cvarrToMat(correspond), new Point(Math.round(pt1.x()), Math.round(pt1.y())),\n                    new Point(Math.round(pt2.x()), Math.round(pt2.y()) + object.height()),\n                    Scalar.WHITE, 1, 8, 0);\n        }\n    }\n}",
        "<FILL>\n",
        "public static void main(String[] args) throws Exception {\n    // Load the images\n    Mat objectImage = imread(\"object.jpg\", IMREAD_GRAYSCALE);\n    Mat imageScene = imread(\"image.jpg\", IMREAD_GRAYSCALE);\n    \n    // Create the ObjectFinder instance with the default settings\n    ObjectFinder finder = new ObjectFinder();\n    \n    // Set up the customized settings\n    ObjectFinder.Settings settings = finder.getSettings();\n    settings.objectImage = objectImage;\n    settings.useFLANN = true;\n    settings.ransacReprojThreshold = 5;\n    \n    double[] dst_corners = finder.find(imageScene);\n}",
        "\nimport org.bytedeco.javacpp.*;\nimport org.bytedeco.javacpp.helper.*;\nimport org.bytedeco.opencv.global.opencv_core.*;\nimport static org.bytedeco.opencv.global.opencv_highgui.*;\nimport static org.bytedeco.opencv.global.opencv_imgcodecs.*;\nimport static org.bytedeco.opencv.global.opencv_imgproc.*;\nimport static org.bytedeco.opencv.global.opencv_calib3d.*;\n\npublic class ObjectFinder {\n    // ...\n    \n    public void find() throws Exception {\n        // ...\n        \n        // Find homography\n        double[] srcCorners = new double[] { 0, 0, object.height(), 0, 0, object.width(), object.height(), object.width() };\n        Mat H = findHomography(srcCorners, dstCorners, CV_RANSAC);\n        \n    }\n}\n",
        "\nimport org.bytedeco.javacpp.*;\nimport org.bytedeco.opencv.global.opencv_core;\nimport org.bytedeco.opencv.global.opencv_imgcodecs;\nimport org.bytedeco.opencv.global.opencv_features2d;\nimport org.bytedeco.opencv.global.opencv_flann;\nimport org.bytedeco.opencv.opencv_core.*;\nimport org.bytedeco.opencv.opencv_features2d.*;\nimport org.bytedeco.opencv.opencv_flann.*;\nimport static org.bytedeco.opencv.global.opencv_imgcodecs.*;\nimport java.util.List;\n\npublic class ObjectFinder {\n    public static class Settings {\n        public int fastThreshold = 20;\n        public IplImage objectImage;\n        public float ratio = 0.6f;\n        public boolean useFLANN = true;\n        public double ransacReprojThreshold = 5.;\n        public int matchesMin = 10;\n    }\n    \n    private Settings settings;\n    private List<KeyPoint> objectKeypoints, imageKeypoints;\n    private List<Integer> ptpairs;\n    private Mat objectDescriptorsMat, imageDescriptorsMat;\n    private FlannParameters flannParams = new FlannParameters();\n    \n    public ObjectFinder(Settings settings) {\n        this.settings = settings;\n        findObjectKeypointsInImage();\n    }\n    \n    public void findObjectKeyPointsInImage() {\n        // Convert object image to grayscale and detect keypoints\n        IplImage imgGray = opencv_imgcodecs.cvCreateImage(\n                settings.objectImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);\n        \n        Mat descriptorsMat = new Mat();\n        MatOfKeyPoint keypointsMat = opencv_features2d.detectAndComputeKeyPoints(\n                    imgGray, null, settings.fastThreshold, true);\n        opencv_imgcodecs.cvReleaseImage(imgGray);\n        \n        // Convert image to grayscale and detect keypoints\n        IplImage imgGray = opencv_imgcodecs.cvCreateImage(\n                settings.imageImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);\n        Mat descriptorsMat = new Mat();\n        MatOfKeyPoint keypointsMat = opencv_features2d.detectAndComputeKeyPoints(\n                    imgGray, null, settings.fastThreshold, true);\n        \n        // Convert object and image descriptors to Mat\n        if (keypointsMat != null) {\n            List<Mat> keypointsMats = new ArrayList<>();\n            opencv_core.IplImage imgKeypoint;\n            for (int i = 0; i < keypointsMat.rows(); i++) {\n                imgKeypoint = keypointsMat.row(i);\n                \n                // Convert IplImage to Mat and add to list of descriptors mats\n                keypointsMats.add(opencv_core.IplImageWrapper.toMat(imgKeypoint));\n            }\n            \n            // Use keypoints to compute descriptors for object and image\n            objectDescriptorsMat = opencv_features2d.computeDescriptors(\n                    opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, keypointsMats);\n            imageDescriptorsMat = opencv_features2d.computeDescriptors(\n                    opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, keypointsMats);\n        } else {\n            \n            // Convert object and image images to grayscale and detect keypoints\n            IplImage imgGray = opencv_imgcodecs.cvCreateImage(\n                    settings.objectImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);\n            Mat descriptorsMat = new Mat();\n            MatOfKeyPoint keypointsMat = opencv_features2d.detectAndComputeKeyPoints(\n                        imgGray, null, settings.fastThreshold, true);\n            \n            IplImage imgGray = opencv_imgcodecs.cvCreateImage(\n                    settings.imageImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);\n            descriptorsMat = opencv_features2d.computeDescriptors(\n                        opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, imgGray, null, settings.fastThreshold, true);\n            \n            // Convert keypoints to compute descriptors for object and image\n            objectDescriptorsMat = opencv_features2d.computeDescriptors(\n                        opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, imgGray, null, settings.fastThreshold, true);\n            imageDescriptorsMat = descriptorsMat;\n        }\n        \n        \n        // Convert object and image descriptors to Mat\n        if (keypointsMat != null) {\n            List<Mat> keypointsMats = new ArrayList<>();\n            opencv_core.IplImage imgKeypoint;\n            for (int i = 0; i < keypointsMat.rows(); i++) {\n                imgKeypoint = keypointsMat.row(i);\n                \n                // Convert IplImage to Mat and add to list of descriptors mats\n                keypointsMats.add(opencv_core.IplImageWrapper.toMat(imgKeypoint));\n            }\n            \n            // Use keypoints to compute descriptors for object and image\n            objectDescriptorsMat = opencv_features2d.computeDescriptors(\n                    opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, keypointsMats);\n            imageDescriptorsMat = opencv_features2d.computeDescriptors(\n                    opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, keypointsMats);\n        } else {\n            \n            // Convert object and image images to grayscale and detect key points\n            IplImage imgGray = opencv_imgcodecs.cvCreateImage(\n                    settings.objectImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);\n            Mat descriptorsMat = new Mat();\n            MatOfKeyPoint keypointsMat = opencv_features2d.detectAndComputeKeyPoints(\n                        imgGray, null, settings.fastThreshold, true);\n            \n            IplImage imgGray = opencv_imgcodecs.cvCreateImage(\n                    settings.imageImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);\n            descriptorsMat = opencv_features2d.computeDescriptors(\n                        opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, imgGray, null, settings.fastThreshold, true);\n            \n            // Convert keypoints to compute descriptors for object and image\n            objectDescriptorsMat = opencv_features2d.computeDescriptors(\n                        opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, imgGray, null, settings.fastThreshold, true);\n            imageDescriptorsMat = descriptorsMat;\n        }\n        \n        \n        // Convert object and image descriptors to Mat\n        if (keypointsMat != null) {\n            \n            // Use keypoints to compute descriptors for object and image\n            objectDescriptorsMat = opencv_features2d.computeDescriptors(\n                    opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, keypointsMats);\n            imageDescriptorsMat = opencv_features2d.computeDescriptors(\n                    opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, keypointsMats);\n        } else {\n            \n            // Convert object and image images to grayscale and detect key points\n            IplImage imgGray = opencv_imgcodecs.cvCreateImage(\n                    settings.objectImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);\n            Mat descriptorsMat = new Mat();\n            MatOfKeyPoint keypointsMat = opencv_features2d.detectAndComputeKeyPoints(\n                        imgGray, null, settings.fastThreshold, true);\n            \n            IplImage imgGray = opencv_imgcodecs.cvCreateImage(\n                    settings.imageImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);\n            descriptorsMat = opencv_features2d.computeDescriptors(\n                        opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, imgGray, null, settings.fastThreshold, true);\n            \n            // Convert keypoints to compute descriptors for object and image\n            objectDescriptorsMat = opencv_features2d.computeDescriptors(\n                        opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, imgGray, null, settings.fastThreshold, true);\n            imageDescriptorsMat = descriptorsMat;\n        }\n    }\n    \n    public List<KeyPoint> findObjectKeyPointsInImage() {\n        \n        // Convert object and image images to grayscale and detect key points\n        IplImage imgGray = opencv_imgcodecs.cvCreateImage(\n                settings.objectImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);\n        Mat descriptorsMat = new Mat();\n        MatOfKeyPoint keypointsMat = opencv_features2d.detectAndComputeKeyPoints(\n                    imgGray, null, settings.fastThreshold, true);\n        \n        // Convert image images to grayscale and detect key points\n        IplImage imgGray = opencv_imgcodecs.cvCreateImage(\n                settings.imageImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);\n        descriptorsMat = opencv_features2d.computeDescriptors(\n                    opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, imgGray, null, settings.fastThreshold, true);\n        \n        // Use keypoints to compute descriptors for object and image\n        List<KeyPoint> objectKeyPoints = new ArrayList<>();\n        objectKeyPoints = opencv_features2d.detectAndComputeKeyPoints(imgGray, null, settings.fastThreshold, true);\n        \n        // Compute descriptors for both images\n        MatOfKeyPoint image1KeyPoints = new MatOfKeyPoint();\n        MatOfKeyPoint image2KeyPoints = new MatOfKeyPoint();\n        Mat objectDescriptors = opencv_features2d.computeDescriptors(opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, imgGray, objectKeyPoints);\n        \n        // Use keypoints to compute descriptors for object and image\n        List<MatOfDMatch> matches = new ArrayList<>();\n        \n        // Compute matches between both images\n        opencv_features2d.match(objectDescriptors, descriptorsMat, matches);\n        \n        // Filter matches using the ratio test\n        for (int i = 0; i < matches.size(); i++) {\n            DMatch match = matches.get(i).toArray()[0];\n            if ((double) match.distance / (double) match.queryIdx == 1)) {\n                objectKeyPoints = new ArrayList<>();\n                for (int j = 0; j < keypointsMat.rows(); j++) {\n                    MatOfDMatch matOfDMatch = matches.get(j);\n                    DMatch dmatch = matOfDMatch.toArray()[0];\n                    if (dmatch.queryIdx == match.queryIdx) {\n                        objectKeyPoints.add(keypointsMat.row(j));\n                        break;\n                    }\n                }\n            }\n        \n        // Find the points in both images that correspond to each other\n        List<Point> image1Points = new ArrayList<>();\n        List<Point> image2Points = new ArrayList<>();\n        for (int i = 0; i < matches.size(); i++) {\n            MatOfDMatch matOfDMatch = matches.get(i);\n            DMatch dmatch = matOfDMatch.toArray()[0];\n            \n            // Get the points in image 1 that correspond to each other\n            if (dmatch.queryIdx == i) {\n                for (int j = 0; j < keypointsMat.rows(); j++) {\n                    MatOfKeyPoint matOfKeyPoint = keypointsMat.row(j);\n                    KeyPoint keyPoint = matOfKeyPoint.toArray()[0];\n                    \n                    // Check if the points are the same as those in image 1\n                    if (keyPoint.queryIdx == dmatch.trainIdx) {\n                        image1Points.add(new Point((int) keyPoint.pt.x, (int) keyPoint.pt.y));\n                        break;\n                    }\n                }\n            } else if (dmatch.trainIdx == i) {\n            \n            // Get the points in image 2 that correspond to each other\n                for (int j = 0; j < keypointsMat.rows(); j++) {\n                    MatOfKeyPoint matOfKeyPoint = keypointsMat.row(j);\n                    KeyPoint keyPoint = matOfKeyPoint.toArray()[0];\n                    \n                    // Check if the points are the same as those in image 2\n                    if (keyPoint.queryIdx == dmatch.trainIdx) {\n                        image2Points.add(new Point((int) keyPoint.pt.x, (int) keyPoint.pt.y));\n                        break;\n                    }\n                }\n            }\n        }\n        \n        // Find the convex hull of all corresponding points\n        MatOfPoint matOfImage1Points = new MatOfPoint();\n        MatOfPoint matOfImage2Points = new MatOfPoint();\n        \n        // Create matrices for the points in both images\n        for (int i = 0; i < image1Points.size(); i++) {\n            Point point = image1Points.get(i);\n            matOfImage1Points.push_back(new Point((int) point.x, (int) point.y));\n        }\n        \n        // Create matrices for the points in both images\n        for (int i = 0; i < image2Points.size(); i++) {\n            Point point = image2Points.get(i);\n            matOfImage2Points.push_back(new Point((int) point.x, (int) point.y));\n        }\n        \n        // Create convex hulls for the points in both images\n        List<Point> image1ConvexHull = new ArrayList<>();\n        image1ConvexHull = opencv_imgproc.convexHull(matOfImage1Points, false);\n        List<Point> image2ConvexHull = new ArrayList<>();\n        image2ConvexHull = opencv_imgproc.convexHull(matOfImage2Points, false);\n        \n        // Draw the convex hulls on each image\n        Mat image1WithConvexHull = image1.clone();\n        opencv_imgproc.drawContours(image1WithConvexHull, matOfImage1Points, Scalar.RED_COLOR);\n        \n        // Draw the convex hulls on each image\n        Mat image2WithConvexHull = image2.clone();\n        opencv_imgproc.drawContours(image2WithConvexHull, matOfImage2Points, Scalar.RED_COLOR);\n        \n        // Show the images with convex hulls drawn on them\n        Highgui.imshow(\"image1WithConvexHull\", image1WithConvexHull);\n        Highgui.imshow(\"image2WithConvexHull\", image2WithConvexHull);\n    }\n}\n"
    ]
}