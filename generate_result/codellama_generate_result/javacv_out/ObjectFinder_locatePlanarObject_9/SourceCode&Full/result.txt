Source code: 


double[] locatePlanarObject(KeyPointVector objectKeypoints, Mat objectDescriptors,
        KeyPointVector imageKeypoints, Mat imageDescriptors, double[] srcCorners) {
    ptpairs.clear();
    if (settings.useFLANN) {
        flannFindPairs(objectDescriptors, imageDescriptors);
    } else {
        findPairs(objectDescriptors, imageDescriptors);
    }
    int n = ptpairs.size()/2;
    logger.info(n + " matching pairs found");
    if (n < settings.matchesMin) {
        return null;
    }

    pt1 .resize(n);
    pt2 .resize(n);
    mask.resize(n);
    FloatBuffer pt1Idx = pt1.createBuffer();
    FloatBuffer pt2Idx = pt2.createBuffer();
    for (int i = 0; i < n; i++) {
        Point2f p1 = objectKeypoints.get(ptpairs.get(2*i)).pt();
        pt1Idx.put(2*i, p1.x()); pt1Idx.put(2*i+1, p1.y());
        Point2f p2 = imageKeypoints.get(ptpairs.get(2*i+1)).pt();
        pt2Idx.put(2*i, p2.x()); pt2Idx.put(2*i+1, p2.y());
    }

    H = findHomography(pt1, pt2, CV_RANSAC, settings.ransacReprojThreshold, mask, 2000, 0.995);
    if (H.empty() || countNonZero(mask) < settings.matchesMin) {
        return null;
    }

    double[] h = (double[])H.createIndexer(false).array();
    double[] dstCorners = new double[srcCorners.length];
    for(int i = 0; i < srcCorners.length/2; i++) {
        double x = srcCorners[2*i], y = srcCorners[2*i + 1];
        double Z = 1/(h[6]*x + h[7]*y + h[8]);
        double X = (h[0]*x + h[1]*y + h[2])*Z;
        double Y = (h[3]*x + h[4]*y + h[5])*Z;
        dstCorners[2*i    ] = X;
        dstCorners[2*i + 1] = Y;
    }
    return dstCorners;
}



No.1 generated result --------------------------

@Disabled
@Test
public void locatePlanarObjectTest() {
    // Prepare the input data (the object to find and an image with that object)
    IplImage object = ...;
    IplImage image  = ...;
    
    // Set up the ObjectFinder parameters
    ObjectFinder.Settings settings = new ObjectFinder.Settings();
    settings.objectImage = object;
    settings.useFLANN = true;
    settings.ransacReprojThreshold = 5;
    
    // Create a new ObjectFinder instance with the given parameters
    ObjectFinder finder = new ObjectFinder(settings);
    
    // Find the object in the image and display the results
    double[] dst_corners = finder.find(image);
    if (dst_corners != null) {
        System.out.println("Object found!");
        
        IplImage correspond = ...;  // create an image to visualize the matching keypoints and their corresponding positions
        
        for (int i = 0; i < finder.ptpairs.size(); i += 2) {
            Point2f pt1 = finder.objectKeypoints.get(finder.ptpairs.get(i));
            Point2f pt2 = finder.imageKeypoints.get(finder.ptpairs.get(i + 1));
            line(cvarrToMat(correspond), new Point(Math.round(pt1.x()), Math.round(pt1.y())),
                    new Point(Math.round(pt2.x()), Math.round(pt2.y() + object.height())),
                    Scalar.WHITE, 1, 8, 0);
        }
        
        CanvasFrame objectFrame = ...; // create a canvas to display the detected object
        objectFrame.showImage(converter.convert(object));
        
        CanvasFrame correspondFrame = ...; // create a canvas to visualize the matching keypoints and their corresponding positions
        correspondFrame.showImage(converter.convert(correspond));
    } else {
        System.out.println("Object not found!");
    }
}


No.2 generated result --------------------------

<FILL>



No.3 generated result --------------------------

import org.bytedeco.javacv.*;
import static org.bytedeco.javacpp.opencv_core.*;
import static org.bytedeco.javacpp.opencv_imgproc.*;
import static org.bytedeco.javacpp.opencv_features2d.*;
import static org.bytedeco.javacpp.opencv_flann.*;
import java.util.*;

public class ObjectFinder {
    public static void main(String[] args) throws Exception {
        String objectFilename = "/path/to/object/image";
        String sceneFilename  = "/path/to/scene/image";
        
        IplImage object = cvLoadImage(objectFilename, CV_LOAD_IMAGE_GRAYSCALE);
        IplImage image  = cvLoadImage(sceneFilename,  CV_LOAD_IMAGE_GRAYSCALE);
        if (object == null || image == null) {
            System.err.println("Can not load " + objectFilename + " and/or " + sceneFilename);
            System.exit(-1);
        }
        
        // Extract keypoints from the object and scene images
        IplImageKeypoint objectKeypoints = cvCreateKeyPoint(NULL);
        CvExtractSURFastFeaturePoints(object, 0, NULL, objectKeypoints);
        int nObjectKeypoints = cvSeqPush(objectKeypoints);
        
        IplImageKeypoint imageKeypoints = cvCreateKeyPoint(NULL);
        CvExtractSURFastFeaturePoints(image, 0, NULL, imageKeypoints);
        int nImageKeypoints = cvSeqPush(imageKeypoints);
        
        // Find object keypoints in the scene
        IplImageMatch match = cvCreateImageMatch(NULL);
        CvFlannBasedFeatureMatch(objectKeypoints, nObjectKeypoints,
            imageKeypoints, nImageKeypoints, match);
        
        // Get matches with distance less than 20 pixels
        int nGoodMatches;
        float minDistance = 20.f;
        IplImageMatch goodMatch = cvCreateImageMatch(NULL);
        CvGetMinDistMatch(match, minDistance, nGoodMatches, goodMatch);
        
        // Draw the lines between matches and the object in the scene
        IplImage correspondence = cvCreateImage(CV_8U, 1, NULL);
        cvCvtColor(correspondence, CV_RGB(255, 0, 0));
        for (int i = 0; i < nGoodMatches; ++i) {
            CvDrawLine(object, objectKeypoints[i], image, imageKeypoints[i + 1]);
            CvDrawMarker(image, imageKeypoints[i], CV_RGB(255, 0, 0), 3);
        }
        
        // Save the correspondence image to disk
        cvSaveImage("correspondence.png", correspondence);
    }
}


No.4 generated result --------------------------


public class ObjectFinder {
    private static final Logger logger = Logger.getLogger(ObjectFinder.class.getName());
    
    public static class Settings extends Object {
        Mat objectImage; // the image to be detected
        boolean useFLANN; // use FLANN-based matcher (true) or BruteForce matcher (false)
        int matchesMin; // the minimal number of good matches required for homography estimation
        double ransacReprojThreshold; // RANSAC reprojection error threshold
        
        Settings() {}
    }
    
    private List<KeyPoint> objectKeypoints, imageKeypoints;
    private Mat ptpairs = new Mat();
    
    public ObjectFinder(Settings settings) {
        Mat mask = new Mat();
        FeatureDetector detector = ORB.create(500);
        
        // extract keypoints from object and image images
        detector.detect(settings.objectImage, new MatOfKeyPoint(), mask);
        objectKeypoints = detector.describe(settings.objectImage, new Mat(), mask);
        logger.info("Object: " + objectKeypoints.size() + " key points");
        
        detector = ORB.create();
        MatOfKeyPoint imageKeypoints = new MatOfKeyPoint();
        
        // extract keypoints from the image and their descriptors
        mask = new Mat(image);
        detector.detect(image, imageKeypoints, mask);
        imageKeypoints = detector.describe(image, null, mask);
        logger.info("Image: " + imageKeypoints.size() + " key points");
        
        // match object and image keypoints
        if (settings.useFLANN) {
            logger.info("Matching using FLANN");
            
            FlannBasedMatcher matcher = new FlannBasedMatcher();
            MatOfDMatch matches = new MatOfDMatch(1);
            
            // find the k closest key points to object keypoints
            matcher.match(imageKeypoints, objectKeypoints, matches);
            
            
            // filter out best matches using Lowe's ratio test
            mask = new Mat(matches);
            double minDistRatio = 0.6;
            for (int i = 0; i < matches.rows(); i++) {
                if (matches.get(i, 0) > settings.matchesMin) {
                    continue;
                }
                // keep the key points which have distance ratio smaller than minDistRatio
                mask.put((int) matches.get(i, 1), (byte) 255);
            }
            
            // select only pairs of keypoints that satisfy Lowe's ratio test
            mask = new Mat(mask);
            MatOfByte goodMatchesMask = new MatOfByte();
            Core.inRange(mask, new Scalar(0), new Scalar(1), goodMatchesMask);
            
            // select only pairs of key points that satisfy distance ratio test
            ptpairs = new MatOfInt(goodMatchesMask.rows(), 2);
            int index = 0;
            for (int i = 0; i < goodMatchesMask.rows(); i++) {
                if (goodMatchesMask.get(i, 0) != (byte) 255) {
                    continue;
                }
                ptpairs.put((int) index++, (int) matches.get(i, 0));
                ptpairs.put((int) index++, (int) matches.get(i, 1));
            }
        } else {
            logger.info("Matching using BruteForce");
            
            // match object and image keypoints using brute force matching algorithm
            BFMatcher matcher = new BFMatcher();
            MatOfDMatch matches = new MatOfDMatch(1);
            
            matcher.match(imageKeypoints, objectKeypoints, matches);
            ptpairs = new MatOfInt(matches.size(), 2);
            for (int i = 0; i < matches.rows(); i++) {
                ptpairs.put((int) i * 2 + 0, (int) matches.get(i, 0));
                ptpairs.put((int) i * 2 + 1, (int) matches.get(i, 1));
            }
        }
        
        // draw only inliers
        MatOfByte drawMatchesMask = new MatOfByte();
        Core.inRange(drawMatchesMask, new Scalar(0), new Scalar(1), drawMatchesMask);
        Imgproc.putText(image, "matches: " + ptpairs.size(), new Point(5, 20), Core.FONT_HERSHEY_SIMPLEX, new Scalar(1), 1, false);
        
        // draw only good matches
        MatOfByte inliersMask = new MatOfByte();
        Core.inRange(inliersMask, new Scalar(0), new Scalar(1), inliersMask);
        for (int i = 0; i < ptpairs.rows(); i++) {
            int queryIdx = (int) ptpairs.get(i, 0);
            int trainIdx = (int) ptpairs.get(i, 1);
            inliersMask.put((int) queryIdx, (byte) 255);
            inliersMask.put((int) trainIdx, (byte) 255);
        }
        
        // draw only inliers
        Imgproc.putText(image, "inliers: " + ptpairs.size(), new Point(5, 30), Core.FONT_HERSHEY_SIMPLEX, new Scalar(1), 1, false);
        
        // show image with inliers and matches
        Imgproc.putText(image, "src: " + objectKeypoints.size() + ", dst: " + imageKeypoints.size(), new Point(5, 40), Core.FONT_HERSHEY_SIMPLEX, new Scalar(1), 1, false);
        Imgproc.putText(image, "good matches: " + ptpairs.rows() + ", k=2", new Point(5, 50), Core.FONT_HERSHEY_SIMPLEX, new Scalar(1), 1, false);
        Imgproc.putText(image, "draw matches: " + drawMatchesMask.rows(), new Point(5, 60), Core.FONT_HERSHEY_SIMPLEX, new Scalar(1), 1, false);
        
        // show image with inliers and matches
        Imgcodec imgEncoder = Imgcodec.createImgCodec();
        String encodedImageString;
        if (imgEncoder != null) {
            encodedImageString = imgEncoder.encodeBitmap(image, Imgcodec.JPEG, 85).toString();
            
            // save image with inliers and matches to file
            FileOutputStream outputStream = new FileOutputStream("matched_keypoints" + System.currentTimeMillis() + ".jpg");
            if (outputStream != null) {
                outputStream.write(encodedImageString.getBytes());
                
                outputStream.close();
            }
        } else {
            logger.info("Failed to load imgEncoder");
            
            // draw matches on the image itself
            MatOfByte drawMatchesMask = new MatOfByte();
            Core.inRange(drawMatchesMask, new Scalar(0), new Scalar(1), drawMatchesMask);
            Imgproc.cvtDrawMatches(imageKeypoints, objectDescriptors, imageDescriptors, matches, 2, new Scalar(50));
            
            // show image with inliers and matches
            MatOfByte inliersMask = new MatOfByte();
            Core.inRange(inliersMask, new Scalar(0), new Scalar(1), inliersMask);
            Imgproc.cvtDrawMatches(imageKeypoints, objectDescriptors, imageDescriptors, ptpairs, 2, new Scalar(50));
        }
        
        // free resources
        if (inliersMask != null) {
            inliersMask.release();
            
            logger.info("Released resources");
        }
    }
    
    /**
     * 
     */
    @Test
    public void testLocatePlanarObject() throws Exception {
        
        // debug mode: set debug to true, false otherwise
        boolean debug = false;
        
        
        
        // Setup test
        logger.info("Setup test");
        Mat imgRgba = Imgcodec.imread(new File(filePath + "palm.jpg"));
        Imgproc.cvtColor(imgRgba, imgRgba, Core.CV_BGR2RGB);
        
        
        // detect object in the image
        MatOfKeyPoint keypoints = new MatOfKeyPoint();
        Mat descriptors = new Mat();
        Features2d.drawKeypoints(imgRgba, keypoints, imgRgba, new Scalar(-1), 4);
        
        
        // show detected object in the image
        Imgproc.putText(imgRgba, "Detected objects: " + keypoints.size(), new Point(5, 20), Core.FONT_HERSHEY_SIMPLEX, new Scalar(-1), 2);
        
        
        // draw detected object in the image
        MatOfByte drawKeypoints = new MatOfByte();
        Core.inRange(drawKeypoints, new Scalar(0), new Scalar(1), drawKeypoints);
        Features2d.drawKeypoints(imgRgba, keypoints, imgRgba, new Scalar(-1), 4);
        
        
        // show image with drawn detected object in the image
        Imgproc.putText(imgRgba, "Draw keypoints: " + drawKeypoints.rows(), new Point(5, 30), Core.FONT_HERSHEY_SIMPLEX, new Scalar(-1), 2);
        
        
        // create a list of points to be used for the detection
        List<MatOfPoint> pointList = new ArrayList<>();
        for (int i = 0; i < keypoints.size().height; i++) {
            MatOfPoint matOfPoint = keypoints.row(i);
            
            
            // add the points to the list of points to be used for the detection
            pointList.add(matOfPoint);
        }
        
        
        
        // free resources
        if (keypoints != null) {
            keypoints.release();
            
            logger.info("Released resources");
        }
        
        
        // Setup planar object detection test
        logger.info("Setup planar object detection test");
        Mat imgPlanar = Imgcodec.imread(new File(filePath + "palm.jpg"));
        
        
        // detect planar objects in the image
        keypoints = new MatOfKeyPoint();
        descriptors = new Mat();
        Features2d.detectPlanarObject(imgPlanar, keypoints, descriptors);
        
        
        // show detected object in the image
        Imgproc.cvtColor(imgPlanar, imgPlanar, Core.CV_BGR2RGB);
        Features2d.drawKeyPoints(imgPlanar, keypoints, imgPlanar, new Scalar(-1), 4);
        
        
        // draw detected object in the image
        MatOfByte drawPlanarObject = new MatOfByte();
        Core.inRange(drawPlanarObject, new Scalar(0), new Scalar(1), drawPlanarObject);
        Features2d.drawPlanarObjects(imgPlanar, keypoints, descriptors, imgPlanar, new Scalar(-1), 4);
        
        
        // show image with drawn detected object in the image
        Imgproc.putText(imgPlanar, "Draw planar objects: " + drawPlanarObject.rows(), new Point(5, 30), Core.FONT_HERSHEY_SIMPLEX, new Scalar(-1), 2);
        
        
        // create a list of points to be used for the detection
        pointList = new ArrayList<>();
        for (int i = 0; i < keypoints.size().height; i++) {
            MatOfPoint matOfPoint = keypoints.row(i);
            
            
            // add the points to the list of points to be used for the detection
            pointList.add(matOfPoint);
        }
        
        
        
        // free resources
        if (keypoints != null) {
            keypoints.release();
            
            logger.info("Released resources");
        }
    }
    
}


No.5 generated result --------------------------


<FILL>



No.6 generated result --------------------------


@Test
public void locatePlanarObjectTest() {
    String objectFilename = "/usr/local/share/OpenCV/samples/c/box.png";
    String sceneFilename  = "/usr/local/share/OpenCV/samples/c/box_in_scene.png";

    IplImage object = cvLoadImage(objectFilename, IMREAD_GRAYSCALE);
    IplImage image  = cvLoadImage(sceneFilename,  IMREAD_GRAYSCALE);
    if (object == null || image == null) {
        System.err.println("Can not load " + objectFilename + " and/or " + sceneFilename);
        System.exit(-1);
    }

    IplImage correspond = IplImage.create(image.width(), object.height()+ image.height(), 8, 1);
    cvSetImageROI(correspond, cvRect(0, 0, object.width(), object.height()));
    cvCopy(object, correspond);
    cvSetImageROI(correspond, cvRect(0, object.height(), correspond.width(), correspond.height()));
    cvCopy(image,
    if (dst_corners != null) {
        for (int i = 0; i < 4; i++) {
            int j = (i+1)%4;
            int x1 = Math.round(dst_corners[2*i]);
            int y1 = Math.round(dst_corners[2*i + 1]) + object.height();
            int x2 = Math.round(dst_corners[2*j]);
            int y2 = Math.round(dst_corners[2*j + 1]) + object.height();
            line(cvarrToMat(correspond), new Point(x1, y1),
                    new Point(x2, y2),
                    Scalar.WHITE, 1, 8, 0);
        }
        for (int i = 0; i < finder.ptpairs.size(); i += 2) {
            Point2f pt1 = finder.objectKeypoints.get(finder.ptpairs.get(i));
            Point2f pt2 = finder.imageKeypoints.get(finder.ptpairs.get(i + 1));
            line(cvarrToMat(correspond), new Point(Math.round(pt1.x()), Math.round(pt1.y())),
                    new Point(Math.round(pt2.x()), Math.round(pt2.y()) + object.height()),
                    Scalar.WHITE, 1, 8, 0);
        }
    }
}


No.7 generated result --------------------------

<FILL>



No.8 generated result --------------------------

public static void main(String[] args) throws Exception {
    // Load the images
    Mat objectImage = imread("object.jpg", IMREAD_GRAYSCALE);
    Mat imageScene = imread("image.jpg", IMREAD_GRAYSCALE);
    
    // Create the ObjectFinder instance with the default settings
    ObjectFinder finder = new ObjectFinder();
    
    // Set up the customized settings
    ObjectFinder.Settings settings = finder.getSettings();
    settings.objectImage = objectImage;
    settings.useFLANN = true;
    settings.ransacReprojThreshold = 5;
    
    double[] dst_corners = finder.find(imageScene);
}


No.9 generated result --------------------------


import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.helper.*;
import org.bytedeco.opencv.global.opencv_core.*;
import static org.bytedeco.opencv.global.opencv_highgui.*;
import static org.bytedeco.opencv.global.opencv_imgcodecs.*;
import static org.bytedeco.opencv.global.opencv_imgproc.*;
import static org.bytedeco.opencv.global.opencv_calib3d.*;

public class ObjectFinder {
    // ...
    
    public void find() throws Exception {
        // ...
        
        // Find homography
        double[] srcCorners = new double[] { 0, 0, object.height(), 0, 0, object.width(), object.height(), object.width() };
        Mat H = findHomography(srcCorners, dstCorners, CV_RANSAC);
        
    }
}



No.10 generated result --------------------------


import org.bytedeco.javacpp.*;
import org.bytedeco.opencv.global.opencv_core;
import org.bytedeco.opencv.global.opencv_imgcodecs;
import org.bytedeco.opencv.global.opencv_features2d;
import org.bytedeco.opencv.global.opencv_flann;
import org.bytedeco.opencv.opencv_core.*;
import org.bytedeco.opencv.opencv_features2d.*;
import org.bytedeco.opencv.opencv_flann.*;
import static org.bytedeco.opencv.global.opencv_imgcodecs.*;
import java.util.List;

public class ObjectFinder {
    public static class Settings {
        public int fastThreshold = 20;
        public IplImage objectImage;
        public float ratio = 0.6f;
        public boolean useFLANN = true;
        public double ransacReprojThreshold = 5.;
        public int matchesMin = 10;
    }
    
    private Settings settings;
    private List<KeyPoint> objectKeypoints, imageKeypoints;
    private List<Integer> ptpairs;
    private Mat objectDescriptorsMat, imageDescriptorsMat;
    private FlannParameters flannParams = new FlannParameters();
    
    public ObjectFinder(Settings settings) {
        this.settings = settings;
        findObjectKeypointsInImage();
    }
    
    public void findObjectKeyPointsInImage() {
        // Convert object image to grayscale and detect keypoints
        IplImage imgGray = opencv_imgcodecs.cvCreateImage(
                settings.objectImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);
        
        Mat descriptorsMat = new Mat();
        MatOfKeyPoint keypointsMat = opencv_features2d.detectAndComputeKeyPoints(
                    imgGray, null, settings.fastThreshold, true);
        opencv_imgcodecs.cvReleaseImage(imgGray);
        
        // Convert image to grayscale and detect keypoints
        IplImage imgGray = opencv_imgcodecs.cvCreateImage(
                settings.imageImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);
        Mat descriptorsMat = new Mat();
        MatOfKeyPoint keypointsMat = opencv_features2d.detectAndComputeKeyPoints(
                    imgGray, null, settings.fastThreshold, true);
        
        // Convert object and image descriptors to Mat
        if (keypointsMat != null) {
            List<Mat> keypointsMats = new ArrayList<>();
            opencv_core.IplImage imgKeypoint;
            for (int i = 0; i < keypointsMat.rows(); i++) {
                imgKeypoint = keypointsMat.row(i);
                
                // Convert IplImage to Mat and add to list of descriptors mats
                keypointsMats.add(opencv_core.IplImageWrapper.toMat(imgKeypoint));
            }
            
            // Use keypoints to compute descriptors for object and image
            objectDescriptorsMat = opencv_features2d.computeDescriptors(
                    opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, keypointsMats);
            imageDescriptorsMat = opencv_features2d.computeDescriptors(
                    opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, keypointsMats);
        } else {
            
            // Convert object and image images to grayscale and detect keypoints
            IplImage imgGray = opencv_imgcodecs.cvCreateImage(
                    settings.objectImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);
            Mat descriptorsMat = new Mat();
            MatOfKeyPoint keypointsMat = opencv_features2d.detectAndComputeKeyPoints(
                        imgGray, null, settings.fastThreshold, true);
            
            IplImage imgGray = opencv_imgcodecs.cvCreateImage(
                    settings.imageImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);
            descriptorsMat = opencv_features2d.computeDescriptors(
                        opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, imgGray, null, settings.fastThreshold, true);
            
            // Convert keypoints to compute descriptors for object and image
            objectDescriptorsMat = opencv_features2d.computeDescriptors(
                        opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, imgGray, null, settings.fastThreshold, true);
            imageDescriptorsMat = descriptorsMat;
        }
        
        
        // Convert object and image descriptors to Mat
        if (keypointsMat != null) {
            List<Mat> keypointsMats = new ArrayList<>();
            opencv_core.IplImage imgKeypoint;
            for (int i = 0; i < keypointsMat.rows(); i++) {
                imgKeypoint = keypointsMat.row(i);
                
                // Convert IplImage to Mat and add to list of descriptors mats
                keypointsMats.add(opencv_core.IplImageWrapper.toMat(imgKeypoint));
            }
            
            // Use keypoints to compute descriptors for object and image
            objectDescriptorsMat = opencv_features2d.computeDescriptors(
                    opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, keypointsMats);
            imageDescriptorsMat = opencv_features2d.computeDescriptors(
                    opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, keypointsMats);
        } else {
            
            // Convert object and image images to grayscale and detect key points
            IplImage imgGray = opencv_imgcodecs.cvCreateImage(
                    settings.objectImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);
            Mat descriptorsMat = new Mat();
            MatOfKeyPoint keypointsMat = opencv_features2d.detectAndComputeKeyPoints(
                        imgGray, null, settings.fastThreshold, true);
            
            IplImage imgGray = opencv_imgcodecs.cvCreateImage(
                    settings.imageImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);
            descriptorsMat = opencv_features2d.computeDescriptors(
                        opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, imgGray, null, settings.fastThreshold, true);
            
            // Convert keypoints to compute descriptors for object and image
            objectDescriptorsMat = opencv_features2d.computeDescriptors(
                        opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, imgGray, null, settings.fastThreshold, true);
            imageDescriptorsMat = descriptorsMat;
        }
        
        
        // Convert object and image descriptors to Mat
        if (keypointsMat != null) {
            
            // Use keypoints to compute descriptors for object and image
            objectDescriptorsMat = opencv_features2d.computeDescriptors(
                    opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, keypointsMats);
            imageDescriptorsMat = opencv_features2d.computeDescriptors(
                    opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, keypointsMats);
        } else {
            
            // Convert object and image images to grayscale and detect key points
            IplImage imgGray = opencv_imgcodecs.cvCreateImage(
                    settings.objectImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);
            Mat descriptorsMat = new Mat();
            MatOfKeyPoint keypointsMat = opencv_features2d.detectAndComputeKeyPoints(
                        imgGray, null, settings.fastThreshold, true);
            
            IplImage imgGray = opencv_imgcodecs.cvCreateImage(
                    settings.imageImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);
            descriptorsMat = opencv_features2d.computeDescriptors(
                        opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, imgGray, null, settings.fastThreshold, true);
            
            // Convert keypoints to compute descriptors for object and image
            objectDescriptorsMat = opencv_features2d.computeDescriptors(
                        opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, imgGray, null, settings.fastThreshold, true);
            imageDescriptorsMat = descriptorsMat;
        }
    }
    
    public List<KeyPoint> findObjectKeyPointsInImage() {
        
        // Convert object and image images to grayscale and detect key points
        IplImage imgGray = opencv_imgcodecs.cvCreateImage(
                settings.objectImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);
        Mat descriptorsMat = new Mat();
        MatOfKeyPoint keypointsMat = opencv_features2d.detectAndComputeKeyPoints(
                    imgGray, null, settings.fastThreshold, true);
        
        // Convert image images to grayscale and detect key points
        IplImage imgGray = opencv_imgcodecs.cvCreateImage(
                settings.imageImage, opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE);
        descriptorsMat = opencv_features2d.computeDescriptors(
                    opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, imgGray, null, settings.fastThreshold, true);
        
        // Use keypoints to compute descriptors for object and image
        List<KeyPoint> objectKeyPoints = new ArrayList<>();
        objectKeyPoints = opencv_features2d.detectAndComputeKeyPoints(imgGray, null, settings.fastThreshold, true);
        
        // Compute descriptors for both images
        MatOfKeyPoint image1KeyPoints = new MatOfKeyPoint();
        MatOfKeyPoint image2KeyPoints = new MatOfKeyPoint();
        Mat objectDescriptors = opencv_features2d.computeDescriptors(opencv_features2d.DescriptorExtractorAlgorithmType.DAISY, imgGray, objectKeyPoints);
        
        // Use keypoints to compute descriptors for object and image
        List<MatOfDMatch> matches = new ArrayList<>();
        
        // Compute matches between both images
        opencv_features2d.match(objectDescriptors, descriptorsMat, matches);
        
        // Filter matches using the ratio test
        for (int i = 0; i < matches.size(); i++) {
            DMatch match = matches.get(i).toArray()[0];
            if ((double) match.distance / (double) match.queryIdx == 1)) {
                objectKeyPoints = new ArrayList<>();
                for (int j = 0; j < keypointsMat.rows(); j++) {
                    MatOfDMatch matOfDMatch = matches.get(j);
                    DMatch dmatch = matOfDMatch.toArray()[0];
                    if (dmatch.queryIdx == match.queryIdx) {
                        objectKeyPoints.add(keypointsMat.row(j));
                        break;
                    }
                }
            }
        
        // Find the points in both images that correspond to each other
        List<Point> image1Points = new ArrayList<>();
        List<Point> image2Points = new ArrayList<>();
        for (int i = 0; i < matches.size(); i++) {
            MatOfDMatch matOfDMatch = matches.get(i);
            DMatch dmatch = matOfDMatch.toArray()[0];
            
            // Get the points in image 1 that correspond to each other
            if (dmatch.queryIdx == i) {
                for (int j = 0; j < keypointsMat.rows(); j++) {
                    MatOfKeyPoint matOfKeyPoint = keypointsMat.row(j);
                    KeyPoint keyPoint = matOfKeyPoint.toArray()[0];
                    
                    // Check if the points are the same as those in image 1
                    if (keyPoint.queryIdx == dmatch.trainIdx) {
                        image1Points.add(new Point((int) keyPoint.pt.x, (int) keyPoint.pt.y));
                        break;
                    }
                }
            } else if (dmatch.trainIdx == i) {
            
            // Get the points in image 2 that correspond to each other
                for (int j = 0; j < keypointsMat.rows(); j++) {
                    MatOfKeyPoint matOfKeyPoint = keypointsMat.row(j);
                    KeyPoint keyPoint = matOfKeyPoint.toArray()[0];
                    
                    // Check if the points are the same as those in image 2
                    if (keyPoint.queryIdx == dmatch.trainIdx) {
                        image2Points.add(new Point((int) keyPoint.pt.x, (int) keyPoint.pt.y));
                        break;
                    }
                }
            }
        }
        
        // Find the convex hull of all corresponding points
        MatOfPoint matOfImage1Points = new MatOfPoint();
        MatOfPoint matOfImage2Points = new MatOfPoint();
        
        // Create matrices for the points in both images
        for (int i = 0; i < image1Points.size(); i++) {
            Point point = image1Points.get(i);
            matOfImage1Points.push_back(new Point((int) point.x, (int) point.y));
        }
        
        // Create matrices for the points in both images
        for (int i = 0; i < image2Points.size(); i++) {
            Point point = image2Points.get(i);
            matOfImage2Points.push_back(new Point((int) point.x, (int) point.y));
        }
        
        // Create convex hulls for the points in both images
        List<Point> image1ConvexHull = new ArrayList<>();
        image1ConvexHull = opencv_imgproc.convexHull(matOfImage1Points, false);
        List<Point> image2ConvexHull = new ArrayList<>();
        image2ConvexHull = opencv_imgproc.convexHull(matOfImage2Points, false);
        
        // Draw the convex hulls on each image
        Mat image1WithConvexHull = image1.clone();
        opencv_imgproc.drawContours(image1WithConvexHull, matOfImage1Points, Scalar.RED_COLOR);
        
        // Draw the convex hulls on each image
        Mat image2WithConvexHull = image2.clone();
        opencv_imgproc.drawContours(image2WithConvexHull, matOfImage2Points, Scalar.RED_COLOR);
        
        // Show the images with convex hulls drawn on them
        Highgui.imshow("image1WithConvexHull", image1WithConvexHull);
        Highgui.imshow("image2WithConvexHull", image2WithConvexHull);
    }
}



