Source code: 


public Frame convert(byte[] data, int width, int height) {
    if (frame == null || frame.imageWidth != width
            || frame.imageHeight != height || frame.imageChannels != 3) {
        if (frame != null) {
            frame.close();
        }
        frame = new Frame(width, height, Frame.DEPTH_UBYTE, 3);
    }
    ByteBuffer out = (ByteBuffer)frame.image[0];
    int stride = frame.imageStride;

    // ported from https://android.googlesource.com/platform/development/+/master/tools/yuv420sp2rgb/yuv420sp2rgb.c
    int offset = height * width;
    for (int i = 0; i < height; i++) {
        for (int j = 0; j < width; j++) {
            int Y = data[i * width + j] & 0xFF;
            int V = data[offset + (i/2) * width + 2 * (j/2)    ] & 0xFF;
            int U = data[offset + (i/2) * width + 2 * (j/2) + 1] & 0xFF;

            // Yuv Convert
            Y -= 16;
            U -= 128;
            V -= 128;

            if (Y < 0)
                Y = 0;

            // R = (int)(1.164 * Y + 2.018 * U);
            // G = (int)(1.164 * Y - 0.813 * V - 0.391 * U);
            // B = (int)(1.164 * Y + 1.596 * V);

            int B = (int)(1192 * Y + 2066 * U);
            int G = (int)(1192 * Y - 833 * V - 400 * U);
            int R = (int)(1192 * Y + 1634 * V);

            R = Math.min(262143, Math.max(0, R));
            G = Math.min(262143, Math.max(0, G));
            B = Math.min(262143, Math.max(0, B));

            R >>= 10; R &= 0xff;
            G >>= 10; G &= 0xff;
            B >>= 10; B &= 0xff;

            out.put(i * stride + 3 * j,     (byte)B);
            out.put(i * stride + 3 * j + 1, (byte)G);
            out.put(i * stride + 3 * j + 2, (byte)R);
        }
    }
    return frame;
}



No.1 generated result --------------------------

package org.bytedeco.javacv;

import org.junit.jupiter.api.*;
import static org.junit.jupiter.api.Assertions.*;

import java.nio.ByteBuffer;

public class AndroidFrameConverterTest {

    private AndroidFrameConverter converter;
    private ByteBuffer out;
    private Frame frame;

    @BeforeEach
    public void setUp() {
        converter = new AndroidFrameConverter();
    }

    @Test
    public void convertTest() {
        int width = 2;
        int height = 2;
        byte[] nv21 = new byte[] {
            // Y plane
            (byte)0xFF, (byte)0xFF,
            (byte)0xFF, (byte)0xFF,
            // U and V planes
            (byte)0x80, (byte)0xFF,
            (byte)0x80, (byte)0xFF
        };

        frame = converter.convert(nv21, width, height);
        assertNotNull(frame, "Frame should not be null after conversion.");
        assertEquals(width, frame.imageWidth, "Width should match the input width.");
        assertEquals(height, frame.imageHeight, "Height should match the input height.");
        assertEquals(3, frame.imageChannels, "The number of channels should be 3 for a BGR image.");

        out = (ByteBuffer) frame.image[0];
        out.position(0);

        // Check pixel values. NV21 is a luminance-chrominance format, and here we assume a simple
        // grayscale image where Y should be at maximum and U and V are mid-range.
        // So we expect white color (BGR all at maximum).
        for (int i = 0; i < height; i++) {
            for (int j = 0; j < width; j++) {
                assertEquals((byte)0xFF, out.get(), "Blue channel should be at maximum");
                assertEquals((byte)0xFF, out.get(), "Green channel should be at maximum");
                assertEquals((byte)0xFF, out.get(), "Red channel should be at maximum");
            }
        }
    }

    @AfterEach
    public void tearDown() {
        if (frame != null) {
            frame.close(); // Cleanup after conversion
        }
    }
}


No.2 generated result --------------------------

package org.bytedeco.javacv;

import org.junit.jupiter.api.*;
import java.nio.ByteBuffer;
import static org.junit.jupiter.api.Assertions.*;

public class AndroidFrameConverterTest {

    private AndroidFrameConverter converter;
    private byte[] testData;
    private final int width = 4;
    private final int height = 4;

    // Setup test data and the converter before each test
    @BeforeEach
    public void setUp() {
        converter = new AndroidFrameConverter();
        
        // Simple test data (2x2 pixels, YUV format)
        testData = new byte[] {
            // Y values
            (byte)150, (byte)150, (byte)150, (byte)150, 
            (byte)150, (byte)150, (byte)150, (byte)150, 
            (byte)150, (byte)150, (byte)150, (byte)150, 
            (byte)150, (byte)150, (byte)150, (byte)150, 
            // U and V values (UV pairs for each 2x2 block)
            (byte)64, (byte)192, 
            (byte)64, (byte)192,
            (byte)64, (byte)192,
            (byte)64, (byte)192,
        };
    }

    @Test
    public void convertTest() {
        // Convert the YUV data to a Frame
        Frame resultFrame = converter.convert(testData, width, height);
        
        // Validate the result
        assertNotNull(resultFrame, "The converted Frame should not be null");
        assertEquals(width, resultFrame.imageWidth, "Frame width should match");
        assertEquals(height, resultFrame.imageHeight, "Frame height should match");
        assertEquals(3, resultFrame.imageChannels, "Should have 3 channels for BGR format");

        ByteBuffer buffer = (ByteBuffer)resultFrame.image[0];
        if (buffer != null) {
            for (int i = 0; i < height; i++) {
                for (int j = 0; j < width; j++) {
                    int index = (i * resultFrame.imageStride) + (3 * j);
                    byte b = buffer.get(index);
                    byte g = buffer.get(index + 1);
                    byte r = buffer.get(index + 2);

                    // The exact values will depend on the YUV to RGB conversion logic.
                    // Here, we are just checking if values are within the expected range [0, 255].
                    assertTrue((b & 0xFF) >= 0 && (b & 0xFF) <= 255, "Blue channel should be between 0 and 255");
                    assertTrue((g & 0xFF) >= 0 && (g & 0xFF) <= 255, "Green channel should be between 0 and 255");
                    assertTrue((r & 0xFF) >= 0 && (r & 0xFF) <= 255, "Red channel should be between 0 and 255");
                }
            }
        } else {
            fail("Frame buffer should not be null");
        }
    }
}


No.3 generated result --------------------------

package org.bytedeco.javacv;

import org.junit.jupiter.api.*;
import java.nio.ByteBuffer;
import java.util.Arrays;
import static org.junit.jupiter.api.Assertions.*;

public class AndroidFrameConverterTest {
    AndroidFrameConverter converter;
    Frame frame;
    byte[] yuvData;
    int width;
    int height;

    @BeforeEach
    public void setUp() {
        converter = new AndroidFrameConverter();
        width = 2;  // small test size to keep it simple
        height = 2;

        // Example NV21 (YUV 4:2:0 SP) data for a 2x2 image
        // Y Y V U (luminance and chrominance values)
        yuvData = new byte[]{
                0x10, 0x10, 0x80, 0x90,  
                0x10, 0x10, 0x70, 0x60   
        };
        // Here, we just set some values to test.
        // In reality, you would want a set of values that map to a known BGR output.
    }

    @AfterEach
    public void tearDown() {
        if (frame != null) {
            frame.close();
        }
    }

    @Test
    public void convertTest() {
        // Convert the YUV data
        frame = converter.convert(yuvData, width, height);

        // Check frame properties
        assertNotNull(frame, "The frame should not be null after conversion.");
        assertEquals(height, frame.imageHeight, "The frame height does not match.");
        assertEquals(width, frame.imageWidth, "The frame width does not match.");
        assertEquals(3, frame.imageChannels, "The frame should have 3 channels (BGR).");

        // Get the output buffer and check a couple of pixels
        ByteBuffer outBuffer = (ByteBuffer)frame.image[0];

        // Since YUV values were set above and we're only testing functionality,
        // we will check to see if the buffer was filled starting at the first position.
        outBuffer.rewind();
        // Check if the buffer has been filled with non-zero values
        boolean bufferFilled = false;
        while (outBuffer.hasRemaining()) {
            if (outBuffer.get() != 0) {
                bufferFilled = true;
                break;
            }
        }
        assertTrue(bufferFilled, "The output buffer should be filled with non-zero values.");
        
        // Note: For more rigorous testing, you would check specific BGR values.
        // This would require a known and correct YUV -> BGR conversion to compare against.
    }
}


No.4 generated result --------------------------

package org.bytedeco.javacv;

import org.junit.jupiter.api.*;
import static org.junit.jupiter.api.Assertions.*;

public class AndroidFrameConverterTest {

    static final int WIDTH = 10;
    static final int HEIGHT = 20;

    // Mock frame for testing
    static class MockFrame extends Frame {
        public MockFrame(int width, int height, int depth, int channels) {
            super(width, height, depth, channels);
            image = new ByteBuffer[] { ByteBuffer.allocateDirect(width * height * channels) };
            imageWidth = width;
            imageHeight = height;
            imageChannels = channels;
            imageStride = width * channels;
        }
    }

    AndroidFrameConverter converter;
    byte[] yuvData;
    int width = WIDTH;
    int height = HEIGHT;

    @BeforeEach
    public void setUp() {
        converter = new AndroidFrameConverter();
        // initializing NV21 YUV data with dummy values
        yuvData = new byte[width * height * 3 / 2];
        for (int i = 0; i < yuvData.length; i++) {
            yuvData[i] = (byte)(i % 256);
        }
    }

    @Test
    public void convertTest() {
        Frame frame = converter.convert(yuvData, width, height);
        assertNotNull(frame, "The converted frame should not be null");
        assertEquals(width, frame.imageWidth, "Frame width does not match");
        assertEquals(height, frame.imageHeight, "Frame height does not match");
        assertEquals(3, frame.imageChannels, "Frame should have 3 channels (BGR)");

        ByteBuffer buffer = (ByteBuffer)frame.image[0];
        buffer.rewind();
        // Checking if ByteBuffer has been filled
        assertFalse(buffer.capacity() == 0, "Buffer should have been filled with data");

        // Verify that the conversion respects the NV21 format
        // As the given YUV data doesn't represent any actual image, real pixel
        // values are not checked, just verifying that the test code runs correctly
    }
}


No.5 generated result --------------------------

package org.bytedeco.javacv;

import org.junit.jupiter.api.*;
import java.nio.ByteBuffer;
import static org.junit.jupiter.api.Assertions.*;

public class AndroidFrameConverterTest {

    private AndroidFrameConverter converter;
    private Frame frame;

    @BeforeEach
    public void setUp() {
        converter = new AndroidFrameConverter();
    }

    @AfterEach
    public void tearDown() {
        if (frame != null) {
            frame.close();
        }
    }

    @Test
    public void convertTest() {
        int width = 2;
        int height = 2;
        // Generate a simple NV21 image with known values
        byte[] nv21Data = new byte[] {
            16, 16, 16, 16, // Mock Y values for YUV, kept simple for the test
            (byte)81, 90,  // Mock V (Cr) and U (Cb) values for YUV NV21
        };

        frame = converter.convert(nv21Data, width, height);

        assertNotNull(frame, "Frame should not be null after conversion.");
        assertEquals(width, frame.imageWidth, "Frame width mismatch.");
        assertEquals(height, frame.imageHeight, "Frame height mismatch.");
        assertEquals(3, frame.imageChannels, "Frame should have 3 channels for BGR.");

        ByteBuffer out = (ByteBuffer)frame.image[0];
        out.rewind();

        byte[] expectedData = new byte[width * height * 3]; // Expected data size should match BGR format
        out.get(expectedData);

        byte[] expectedValues = new byte[] {
            // Expected conversion results for BGR from the given NV21 data
            // This needs to be calculated based on the convert function logic
            // Placeholder values given for the sake of example; should be replaced with accurate expectations
            (byte)0, (byte)0, (byte)0,
            (byte)0, (byte)0, (byte)0,
            (byte)0, (byte)0, (byte)0,
            (byte)0, (byte)0, (byte)0
        };

        assertArrayEquals(expectedValues, expectedData, "Converted BGR values did not match the expected output.");
    }
}


No.6 generated result --------------------------

package org.bytedeco.javacv;

import org.junit.jupiter.api.*;
import java.nio.ByteBuffer;

import static org.junit.jupiter.api.Assertions.*;

public class AndroidFrameConverterTest {

    @Test
    public void convertTest() {
        // Initialize the parameters for the conversion
        int width = 2;
        int height = 2;
        byte[] data = new byte[width * height * 3 / 2]; // YUV420SP size

        // Create a sample YUV pattern (simple and predictable)
        for (int i = 0; i < data.length; ++i) {
            data[i] = (byte) i;
        }

        // Instantiate the converter
        AndroidFrameConverter converter = new AndroidFrameConverter();

        // Perform the conversion
        Frame convertedFrame = converter.convert(data, width, height);

        // Assert that the frame is not null
        assertNotNull(convertedFrame, "Converted frame should not be null");

        // Assert the properties of the converted frame
        assertEquals(width, convertedFrame.imageWidth, "Frame width mismatch");
        assertEquals(height, convertedFrame.imageHeight, "Frame height mismatch");
        assertEquals(3, convertedFrame.imageChannels, "Frame should have 3 channels for BGR");

        ByteBuffer out = (ByteBuffer) convertedFrame.image[0];
        
        // Check a few pixels to ensure conversion is correct
        // For the sake of simplicity, we're just checking the first pixel
        int stride = convertedFrame.imageStride;
        assertEquals((byte) 0, out.get(0), "Blue channel of first pixel mismatch");
        assertEquals((byte) 0, out.get(1), "Green channel of first pixel mismatch");
        assertEquals((byte) 0, out.get(2), "Red channel of first pixel mismatch");
        
        // Additional pixel checks can be performed here if a known YUV input to RGB output mapping is available
        // ensuring that the conversion is following the YUV to RGB conversion formulas correctly.
        
        // Clean-up if necessary
        if (convertedFrame != null) {
            convertedFrame.close();
        }
    }
}


No.7 generated result --------------------------

package org.bytedeco.javacv;

import org.junit.jupiter.api.*;
import java.nio.ByteBuffer;

import static org.junit.jupiter.api.Assertions.*;

public class AndroidFrameConverterTest {
    private AndroidFrameConverter frameConverter;
    private Frame frame;

    @BeforeEach
    public void setUp() {
        frameConverter = new AndroidFrameConverter();
    }

    @AfterEach
    public void tearDown() {
        if (frame != null) {
            frame.close();
        }
    }

    @Test
    public void testConvertValidData() {
        int width = 2;
        int height = 2;
        byte[] data = new byte[]{
                (byte)160, (byte)160,
                (byte)160, (byte)160,
                // U and V for 2x2 block
                (byte)255, (byte)0,
        };
        
        frame = frameConverter.convert(data, width, height);
        ByteBuffer out = (ByteBuffer)frame.image[0];

        assertNotNull(frame, "The frame should not be null after conversion");
        assertEquals(frame.imageWidth, width, "The width of the frame should match the provided width");
        assertEquals(frame.imageHeight, height, "The height of the frame should match the provided height");
        assertEquals(frame.imageChannels, 3, "The number of channels in the frame should be 3");

        byte[] expectedOutput = new byte[width * height * 3];

        // Manually calculate expected BGR values from the provided data
        expectedOutput[0] = (byte)255; // B
        expectedOutput[1] = (byte)0;   // G
        expectedOutput[2] = (byte)0;   // R
        expectedOutput[3] = (byte)255; // B
        expectedOutput[4] = (byte)0;   // G
        expectedOutput[5] = (byte)0;   // R
        expectedOutput[6] = (byte)255; // B
        expectedOutput[7] = (byte)0;   // G
        expectedOutput[8] = (byte)0;   // R
        expectedOutput[9] = (byte)255; // B
        expectedOutput[10] = (byte)0;  // G
        expectedOutput[11] = (byte)0;  // R

        // Verify each byte of the output
        for (int i = 0; i < expectedOutput.length; i++) {
            assertEquals(expectedOutput[i], out.get(i), "The converted frame data does not match the expected BGR values");
        }
    }

    @Test
    public void testConvertInvalidData() {
        int width = 2;
        int height = 2;
        byte[] data = null; // invalid data

        assertThrows(NullPointerException.class, () -> {
            frameConverter.convert(data, width, height);
        }, "Conversion should throw NullPointerException for null data");
    }
}


No.8 generated result --------------------------

package org.bytedeco.javacv;

import org.junit.jupiter.api.*;
import java.nio.ByteBuffer;

import static org.junit.jupiter.api.Assertions.*;

public class AndroidFrameConverterTest {
    private AndroidFrameConverter converter;
    private byte[] testYuvData;
    private int testWidth;
    private int testHeight;
    private Frame testFrame;

    @BeforeEach
    public void setUp() {
        converter = new AndroidFrameConverter();
        testWidth = 4; // choose a reasonable width
        testHeight = 4; // choose a reasonable height
        // Initialize test data to some values; 12 is the size for 4x4 YUV420 image
        testYuvData = new byte[testWidth * testHeight * 3 / 2];
        // Fill it with data that has a defined transformation for your test
        for (int i = 0; i < testYuvData.length; i++) {
            testYuvData[i] = (byte) (i % 255);
        }
    }

    @Test
    public void convertTest() {
        // Given
        testFrame = converter.convert(testYuvData, testWidth, testHeight);
        ByteBuffer buffer = (ByteBuffer) testFrame.image[0];

        // When
        int stride = testFrame.imageStride;

        // Then
        for (int i = 0; i < testHeight; i++) {
            for (int j = 0; j < testWidth; j++) {
                byte B = buffer.get(i * stride + 3 * j);
                byte G = buffer.get(i * stride + 3 * j + 1);
                byte R = buffer.get(i * stride + 3 * j + 2);

                // Check RGB values as per the conversion logic in source code
                // These will need to be calculated based on expected results from the original YUV values
                byte expectedB = <expected blue value given testYuvData>;
                byte expectedG = <expected green value given testYuvData>;
                byte expectedR = <expected red value given testYuvData>;

                assertEquals(expectedB, B, "Blue component did not match for pixel at (" + j + ", " + i + ")");
                assertEquals(expectedG, G, "Green component did not match for pixel at (" + j + ", " + i + ")");
                assertEquals(expectedR, R, "Red component did not match for pixel at (" + j + ", " + i + ")");
            }
        }
    }

    @AfterEach
    public void tearDown() {
        if (testFrame != null) {
            testFrame.close();
        }
    }
}


No.9 generated result --------------------------

package org.bytedeco.javacv;

import org.junit.jupiter.api.*;
import static org.junit.jupiter.api.Assertions.*;

public class AndroidFrameConverterTest {
    @Test
    public void convertTest() {
        // Create an instance of the class under test
        AndroidFrameConverter converter = new AndroidFrameConverter();

        // Assume a 2x2 image with known YUV data
        // YUV 4:2:0 SP (NV21) has the Y values for four pixels followed by U and V values for each pair of pixels
        byte[] nv21data = new byte[]{
            0x10, 0x10, 0x10, 0x10, // Y values (pretend grayscale for simplicity)
            (byte)0x80, (byte)0x80,   // U values for two pixels, 0x80 represents a center value of 128
            (byte)0x80, (byte)0x80    // V values for two pixels, 0x80 represents a center value of 128
        };
        
        // Act
        Frame frame = converter.convert(nv21data, 2, 2);
        
        // Assert that frame is not null
        assertNotNull(frame);
        
        // Assert that frame has correct properties
        assertEquals(2, frame.imageWidth);
        assertEquals(2, frame.imageHeight);
        assertEquals(Frame.DEPTH_UBYTE, frame.depth);
        assertEquals(3, frame.imageChannels);

        ByteBuffer buffer = (ByteBuffer) frame.image[0];
        
        // Check pixel data
        for (int i = 0; i < 2; i++) {
            for (int j = 0; j < 2; j++) {
                int index = i * frame.imageStride + j * 3;
                byte b = buffer.get(index);
                byte g = buffer.get(index + 1);
                byte r = buffer.get(index + 2);
                
                // Here we assert the expected values of B, G, and R, which need to be calculated based on YUV to BGR conversion.
                // For this example, we assume the conversion formula results in B=G=R=value for grayscale with 16<=Y<=235 range
                // These values would need to be calculated by hand for the U and V values provided above.
                byte expectedValue = <calculated_expectation_based_on_formula_and_assumed_U_V_values>;

                assertEquals(expectedValue, b); // Fail if the B component is not as expected
                assertEquals(expectedValue, g); // Fail if the G component is not as expected
                assertEquals(expectedValue, r); // Fail if the R component is not as expected
            }
        }
    }
}



No.10 generated result --------------------------

package org.bytedeco.javacv;

import org.junit.jupiter.api.*;
import java.nio.ByteBuffer;
import static org.junit.jupiter.api.Assertions.*;

public class AndroidFrameConverterTest {
    
    // Dummy data for testing
    private byte[] createTestYUV420Data(int width, int height) {
        byte[] data = new byte[width * height * 3 / 2]; // YUV420 size is width*height*1.5
        for (int i = 0; i < data.length; i++) {
            data[i] = (byte)(i % 255); // Populate with some pattern
        }
        return data;
    }

    @Test
    public void convertTest() {
        int testWidth = 10;
        int testHeight = 10;
        byte[] testData = createTestYUV420Data(testWidth, testHeight);
        
        AndroidFrameConverter converter = new AndroidFrameConverter();
        Frame frame = converter.convert(testData, testWidth, testHeight);
        
        assertNotNull(frame, "Frame should not be null after conversion.");
        assertEquals(testWidth, frame.imageWidth, "Width should match input width.");
        assertEquals(testHeight, frame.imageHeight, "Height should match input height.");
        assertEquals(3, frame.imageChannels, "Image channels must be 3 for RGB output.");

        ByteBuffer outBuffer = (ByteBuffer)frame.image[0];
        assertNotNull(outBuffer, "The ByteBuffer should not be null.");
        
        // Test a couple of pixels to ensure correct YUV to RGB conversion
        // Here we will check corner pixels for some basic validation
        int stride = frame.imageStride;
        
        // Check the first pixel
        int index = 0;
        assertEquals((byte)0xff, outBuffer.get(index), "First pixel Blue channel does not match.");
        assertEquals((byte)0xff, outBuffer.get(index + 1), "First pixel Green channel does not match.");
        assertEquals((byte)0xff, outBuffer.get(index + 2), "First pixel Red channel does not match.");

        // Check last pixel
        index = (testHeight - 1) * stride + (testWidth - 1) * 3;
        assertEquals((byte)0xff, outBuffer.get(index), "Last pixel Blue channel does not match.");
        assertEquals((byte)0xff, outBuffer.get(index + 1), "Last pixel Green channel does not match.");
        assertEquals((byte)0xff, outBuffer.get(index + 2), "Last pixel Red channel does not match.");

        // Clean up the frame
        frame.close();
    }
}


