[
    {
        "project_name": "JCTools",
        "file_name": "FixedSizeStripedLongCounter.java",
        "relative_path": "JCTools/jctools-core/src/main/java/org/jctools/counters/FixedSizeStripedLongCounter.java",
        "execute_path": "JCTools",
        "package": "org.jctools.counters",
        "docstring": "/**\n     * Returns the probe value for the current thread.\n     * If target JDK version is 7 or higher, than ThreadLocalRandom-specific\n     * value will be used, xorshift with thread id otherwise.\n     */",
        "source_code": "\nprivate int probe() {\n    // Fast path for reliable well-distributed probe, available from JDK 7+.\n    // As long as PROBE is final static this branch will be constant folded\n    // (i.e removed).\n    if (PROBE != -1) {\n        int probe;\n        if ((probe = UNSAFE.getInt(Thread.currentThread(), PROBE)) == 0) {\n            ThreadLocalRandom.current(); // force initialization\n            probe = UNSAFE.getInt(Thread.currentThread(), PROBE);\n        }\n        return probe;\n    }\n\n    /*\n     * Else use much worse (for values distribution) method:\n     * Mix thread id with golden ratio and then xorshift it\n     * to spread consecutive ids (see Knuth multiplicative method as reference).\n     */\n    int probe = (int) ((Thread.currentThread().getId() * 0x9e3779b9) & Integer.MAX_VALUE);\n    // xorshift\n    probe ^= probe << 13;\n    probe ^= probe >>> 17;\n    probe ^= probe << 5;\n    return probe;\n}\n\n",
        "class_name": "FixedSizeStripedLongCounterPrePad",
        "method_name": "probe",
        "argument_name": [],
        "full_context": "package org.jctools.counters;\n\nimport static org.jctools.util.UnsafeAccess.UNSAFE;\n\nimport java.util.concurrent.ThreadLocalRandom;\n\nimport org.jctools.util.PortableJvmInfo;\nimport org.jctools.util.Pow2;\n\n/**\n * Basic class representing static striped long counter with\n * common mechanics for implementors.\n *\n * @author Tolstopyatov Vsevolod\n */\nabstract class FixedSizeStripedLongCounterPrePad {\n    byte b000,b001,b002,b003,b004,b005,b006,b007;//  8b\n    byte b010,b011,b012,b013,b014,b015,b016,b017;// 16b\n    byte b020,b021,b022,b023,b024,b025,b026,b027;// 24b\n    byte b030,b031,b032,b033,b034,b035,b036,b037;// 32b\n    byte b040,b041,b042,b043,b044,b045,b046,b047;// 40b\n    byte b050,b051,b052,b053,b054,b055,b056,b057;// 48b\n    byte b060,b061,b062,b063,b064,b065,b066,b067;// 56b\n    byte b070,b071,b072,b073,b074,b075,b076,b077;// 64b\n    byte b100,b101,b102,b103,b104,b105,b106,b107;// 72b\n    byte b110,b111,b112,b113,b114,b115,b116,b117;// 80b\n    byte b120,b121,b122,b123,b124,b125,b126,b127;// 88b\n    byte b130,b131,b132,b133,b134,b135,b136,b137;// 96b\n    byte b140,b141,b142,b143,b144,b145,b146,b147;//104b\n    byte b150,b151,b152,b153,b154,b155,b156,b157;//112b\n    byte b160,b161,b162,b163,b164,b165,b166,b167;//120b\n    // byte b170,b171,b172,b173,b174,b175,b176,b177;//128b\n}\nabstract class FixedSizeStripedLongCounterFields extends FixedSizeStripedLongCounterPrePad {\n    protected static final int CACHE_LINE_IN_LONGS = PortableJvmInfo.CACHE_LINE_SIZE / 8;\n    // place first element at the end of the cache line of the array object\n    protected static final long COUNTER_ARRAY_BASE = Math.max(UNSAFE.arrayBaseOffset(long[].class), PortableJvmInfo.CACHE_LINE_SIZE - 8);\n    // element shift is enlarged to include the padding, still aligned to long\n    protected static final long ELEMENT_SHIFT = Integer.numberOfTrailingZeros(PortableJvmInfo.CACHE_LINE_SIZE);\n\n    // we pad each element in the array to effectively write a counter in each cache line\n    protected final long[] cells;\n    protected final int mask;\n    protected FixedSizeStripedLongCounterFields(int stripesCount) {\n        if (stripesCount <= 0) {\n            throw new IllegalArgumentException(\"Expecting a stripesCount that is larger than 0\");\n        }\n        int size = Pow2.roundToPowerOfTwo(stripesCount);\n        cells = new long[CACHE_LINE_IN_LONGS * size];\n        mask = (size - 1);\n    }\n}\n\npublic abstract class FixedSizeStripedLongCounter extends FixedSizeStripedLongCounterFields implements Counter {\n    byte b000,b001,b002,b003,b004,b005,b006,b007;//  8b\n    byte b010,b011,b012,b013,b014,b015,b016,b017;// 16b\n    byte b020,b021,b022,b023,b024,b025,b026,b027;// 24b\n    byte b030,b031,b032,b033,b034,b035,b036,b037;// 32b\n    byte b040,b041,b042,b043,b044,b045,b046,b047;// 40b\n    byte b050,b051,b052,b053,b054,b055,b056,b057;// 48b\n    byte b060,b061,b062,b063,b064,b065,b066,b067;// 56b\n    byte b070,b071,b072,b073,b074,b075,b076,b077;// 64b\n    byte b100,b101,b102,b103,b104,b105,b106,b107;// 72b\n    byte b110,b111,b112,b113,b114,b115,b116,b117;// 80b\n    byte b120,b121,b122,b123,b124,b125,b126,b127;// 88b\n    byte b130,b131,b132,b133,b134,b135,b136,b137;// 96b\n    byte b140,b141,b142,b143,b144,b145,b146,b147;//104b\n    byte b150,b151,b152,b153,b154,b155,b156,b157;//112b\n    byte b160,b161,b162,b163,b164,b165,b166,b167;//120b\n    //byte b170,b171,b172,b173,b174,b175,b176,b177;//128b\n\n    private static final long PROBE = getProbeOffset();\n\n    private static long getProbeOffset() {\n        try {\n            return UNSAFE.objectFieldOffset(Thread.class.getDeclaredField(\"threadLocalRandomProbe\"));\n\n        } catch (NoSuchFieldException e) {\n            return -1L;\n        }\n    }\n\n    public FixedSizeStripedLongCounter(int stripesCount) {\n        super(stripesCount);\n    }\n\n    @Override\n    public void inc() {\n        inc(1L);\n    }\n\n    @Override\n    public void inc(long delta) {\n        inc(cells, counterOffset(index()), delta);\n    }\n\n    @Override\n    public long get() {\n        long result = 0L;\n        long[] cells = this.cells;\n        int length = mask + 1;\n        for (int i = 0; i < length; i++) {\n            result += UNSAFE.getLongVolatile(cells, counterOffset(i));\n        }\n        return result;\n    }\n\n    private long counterOffset(long i) {\n        return COUNTER_ARRAY_BASE + (i << ELEMENT_SHIFT);\n    }\n\n    @Override\n    public long getAndReset() {\n        long result = 0L;\n        long[] cells = this.cells;\n        int length = mask + 1;\n        for (int i = 0; i < length; i++) {\n            result += getAndReset(cells, counterOffset(i));\n        }\n        return result;\n    }\n\n    protected abstract void inc(long[] cells, long offset, long value);\n\n    protected abstract long getAndReset(long[] cells, long offset);\n\n    private int index() {\n        return probe() & mask;\n    }\n\n\n    /**\n     * Returns the probe value for the current thread.\n     * If target JDK version is 7 or higher, than ThreadLocalRandom-specific\n     * value will be used, xorshift with thread id otherwise.\n     */\n    private int probe() {\n        // Fast path for reliable well-distributed probe, available from JDK 7+.\n        // As long as PROBE is final static this branch will be constant folded\n        // (i.e removed).\n        if (PROBE != -1) {\n            int probe;\n            if ((probe = UNSAFE.getInt(Thread.currentThread(), PROBE)) == 0) {\n                ThreadLocalRandom.current(); // force initialization\n                probe = UNSAFE.getInt(Thread.currentThread(), PROBE);\n            }\n            return probe;\n        }\n\n        /*\n         * Else use much worse (for values distribution) method:\n         * Mix thread id with golden ratio and then xorshift it\n         * to spread consecutive ids (see Knuth multiplicative method as reference).\n         */\n        int probe = (int) ((Thread.currentThread().getId() * 0x9e3779b9) & Integer.MAX_VALUE);\n        // xorshift\n        probe ^= probe << 13;\n        probe ^= probe >>> 17;\n        probe ^= probe << 5;\n        return probe;\n    }\n}\n\n",
        "simple_context": "package org.jctools.counters;\n\nimport static org.jctools.util.UnsafeAccess.UNSAFE;\n\nimport java.util.concurrent.ThreadLocalRandom;\n\nimport org.jctools.util.PortableJvmInfo;\n\nimport org.jctools.util.Pow2;\n\nabstract class FixedSizeStripedLongCounterPrePad {\n    byte b000, b001, b002, b003, b004, b005, b006, b007;\n    byte b010, b011, b012, b013, b014, b015, b016, b017;\n    byte b020, b021, b022, b023, b024, b025, b026, b027;\n    byte b030, b031, b032, b033, b034, b035, b036, b037;\n    byte b040, b041, b042, b043, b044, b045, b046, b047;\n    byte b050, b051, b052, b053, b054, b055, b056, b057;\n    byte b060, b061, b062, b063, b064, b065, b066, b067;\n    byte b070, b071, b072, b073, b074, b075, b076, b077;\n    byte b100, b101, b102, b103, b104, b105, b106, b107;\n    byte b110, b111, b112, b113, b114, b115, b116, b117;\n    byte b120, b121, b122, b123, b124, b125, b126, b127;\n    byte b130, b131, b132, b133, b134, b135, b136, b137;\n    byte b140, b141, b142, b143, b144, b145, b146, b147;\n    byte b150, b151, b152, b153, b154, b155, b156, b157;\n    byte b160, b161, b162, b163, b164, b165, b166, b167;\n}\n\nabstract class FixedSizeStripedLongCounterFields extends FixedSizeStripedLongCounterPrePad {\n    protected static final int CACHE_LINE_IN_LONGS;\n    protected static final long COUNTER_ARRAY_BASE;\n    protected static final long ELEMENT_SHIFT;\n    protected final long[] cells;\n    protected final int mask;\n    protected FixedSizeStripedLongCounterFields(int stripesCount);\n}\n\nabstract public class FixedSizeStripedLongCounter extends FixedSizeStripedLongCounterFields implements Counter {\n    byte b000, b001, b002, b003, b004, b005, b006, b007;\n    byte b010, b011, b012, b013, b014, b015, b016, b017;\n    byte b020, b021, b022, b023, b024, b025, b026, b027;\n    byte b030, b031, b032, b033, b034, b035, b036, b037;\n    byte b040, b041, b042, b043, b044, b045, b046, b047;\n    byte b050, b051, b052, b053, b054, b055, b056, b057;\n    byte b060, b061, b062, b063, b064, b065, b066, b067;\n    byte b070, b071, b072, b073, b074, b075, b076, b077;\n    byte b100, b101, b102, b103, b104, b105, b106, b107;\n    byte b110, b111, b112, b113, b114, b115, b116, b117;\n    byte b120, b121, b122, b123, b124, b125, b126, b127;\n    byte b130, b131, b132, b133, b134, b135, b136, b137;\n    byte b140, b141, b142, b143, b144, b145, b146, b147;\n    byte b150, b151, b152, b153, b154, b155, b156, b157;\n    byte b160, b161, b162, b163, b164, b165, b166, b167;\n    static final private long PROBE;\n    static private long getProbeOffset();\n    public FixedSizeStripedLongCounter(int stripesCount);\n    public  inc();\n    public  inc(long delta);\n    public long get();\n    private long counterOffset(long i);\n    public long getAndReset();\n    protected abstract  inc(long[] cells, long offset, long value);\n    protected abstract long getAndReset(long[] cells, long offset);\n    private int index();\n    private int probe();\n}\n\n"
    },
    {
        "project_name": "JCTools",
        "file_name": "ConcurrentAutoTable.java",
        "relative_path": "JCTools/jctools-core/src/main/java/org/jctools/maps/ConcurrentAutoTable.java",
        "execute_path": "JCTools",
        "package": "org.jctools.maps",
        "docstring": null,
        "source_code": "// Fast fuzzy version.  Used a cached value until it gets old, then re-up\n// the cache.\npublic long estimate_sum( ) {\n  // For short tables, just do the work\n  if( _t.length <= 64 ) return sum();\n  // For bigger tables, periodically freshen a cached value\n  long millis = System.currentTimeMillis();\n  if( _fuzzy_time != millis ) { // Time marches on?\n    _fuzzy_sum_cache = sum(); // Get sum the hard way\n    _fuzzy_time = millis;   // Indicate freshness of cached value\n  }\n  return _fuzzy_sum_cache;  // Return cached sum\n}\n",
        "class_name": "ConcurrentAutoTable",
        "method_name": "estimate_sum",
        "argument_name": [],
        "full_context": "/*\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.jctools.maps;\nimport static org.jctools.util.UnsafeAccess.UNSAFE;\n\nimport java.io.Serializable;\nimport java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n\n\n/**\n * An auto-resizing table of {@code longs}, supporting low-contention CAS\n * operations.  Updates are done with CAS's to no particular table element.\n * The intent is to support highly scalable counters, r/w locks, and other\n * structures where the updates are associative, loss-free (no-brainer), and\n * otherwise happen at such a high volume that the cache contention for\n * CAS'ing a single word is unacceptable.\n *\n * @since 1.5\n * @author Cliff Click\n */\npublic class ConcurrentAutoTable implements Serializable {\n\n  // --- public interface ---\n\n  /**\n   * Add the given value to current counter value.  Concurrent updates will\n   * not be lost, but addAndGet or getAndAdd are not implemented because the\n   * total counter value (i.e., {@link #get}) is not atomically updated.\n   * Updates are striped across an array of counters to avoid cache contention\n   * and has been tested with performance scaling linearly up to 768 CPUs.\n   */\n  public void add( long x ) { add_if(  x); }\n  /** {@link #add} with -1 */\n  public void decrement()   { add_if(-1L); }\n  /** {@link #add} with +1 */\n  public void increment()   { add_if( 1L); }\n\n  /** Atomically set the sum of the striped counters to specified value.\n   *  Rather more expensive than a simple store, in order to remain atomic.\n   */\n  public void set( long x ) {\n    CAT newcat = new CAT(null,4,x);\n    // Spin until CAS works\n    while( !CAS_cat(_cat,newcat) ) {/*empty*/}\n  }\n\n  /**\n   * Current value of the counter.  Since other threads are updating furiously\n   * the value is only approximate, but it includes all counts made by the\n   * current thread.  Requires a pass over the internally striped counters.\n   */\n  public long get()       { return      _cat.sum(); }\n  /** Same as {@link #get}, included for completeness. */\n  public int  intValue()  { return (int)_cat.sum(); }\n  /** Same as {@link #get}, included for completeness. */\n  public long longValue() { return      _cat.sum(); }\n\n  /**\n   * A cheaper {@link #get}.  Updated only once/millisecond, but as fast as a\n   * simple load instruction when not updating.\n   */\n  public long estimate_get( ) { return _cat.estimate_sum(); }\n\n  /**\n   * Return the counter's {@code long} value converted to a string.\n   */\n  public String toString() { return _cat.toString(); }\n\n  /**\n   * A more verbose print than {@link #toString}, showing internal structure.\n   * Useful for debugging.\n   */\n  public void print() { _cat.print(); }\n\n  /**\n   * Return the internal counter striping factor.  Useful for diagnosing\n   * performance problems.\n   */\n  public int internal_size() { return _cat._t.length; }\n\n  // Only add 'x' to some slot in table, hinted at by 'hash'.  The sum can\n  // overflow.  Value is CAS'd so no counts are lost.  The CAS is retried until\n  // it succeeds.  Returned value is the old value.\n  private long add_if( long x ) { return _cat.add_if(x,hash(),this); }\n\n  // The underlying array of concurrently updated long counters\n  private volatile CAT _cat = new CAT(null,16/*Start Small, Think Big!*/,0L);\n  private static AtomicReferenceFieldUpdater<ConcurrentAutoTable,CAT> _catUpdater =\n    AtomicReferenceFieldUpdater.newUpdater(ConcurrentAutoTable.class,CAT.class, \"_cat\");\n  private boolean CAS_cat( CAT oldcat, CAT newcat ) { return _catUpdater.compareAndSet(this,oldcat,newcat); }\n\n  // Hash spreader\n  private static int hash() {\n    //int h = (int)Thread.currentThread().getId();\n    int h = System.identityHashCode(Thread.currentThread());\n    return h<<3;                // Pad out cache lines.  The goal is to avoid cache-line contention\n  }\n\n  // --- CAT -----------------------------------------------------------------\n  private static class CAT implements Serializable {\n\n    // Unsafe crud: get a function which will CAS arrays\n    private static final int _Lbase  = UNSAFE.arrayBaseOffset(long[].class);\n    private static final int _Lscale = UNSAFE.arrayIndexScale(long[].class);\n    private static long rawIndex(long[] ary, int i) {\n      assert i >= 0 && i < ary.length;\n      return _Lbase + (i * (long)_Lscale);\n    }\n    private static boolean CAS( long[] A, int idx, long old, long nnn ) {\n      return UNSAFE.compareAndSwapLong( A, rawIndex(A,idx), old, nnn );\n    }\n\n    //volatile long _resizers;    // count of threads attempting a resize\n    //static private final AtomicLongFieldUpdater<CAT> _resizerUpdater =\n    //  AtomicLongFieldUpdater.newUpdater(CAT.class, \"_resizers\");\n\n    private final CAT _next;\n    private volatile long _fuzzy_sum_cache;\n    private volatile long _fuzzy_time;\n    private static final int MAX_SPIN=1;\n    private final long[] _t;     // Power-of-2 array of longs\n\n    CAT( CAT next, int sz, long init ) {\n      _next = next;\n      _t = new long[sz];\n      _t[0] = init;\n    }\n\n    // Only add 'x' to some slot in table, hinted at by 'hash'.  The sum can\n    // overflow.  Value is CAS'd so no counts are lost.  The CAS is attempted\n    // ONCE.\n    public long add_if( long x, int hash, ConcurrentAutoTable master ) {\n      final long[] t = _t;\n      final int idx = hash & (t.length-1);\n      // Peel loop; try once fast\n      long old = t[idx];\n      final boolean ok = CAS( t, idx, old, old+x );\n      if( ok ) return old;      // Got it\n      // Try harder\n      int cnt=0;\n      while( true ) {\n        old = t[idx];\n        if( CAS( t, idx, old, old+x ) ) break; // Got it!\n        cnt++;\n      }\n      if( cnt < MAX_SPIN ) return old; // Allowable spin loop count\n      if( t.length >= 1024*1024 ) return old; // too big already\n\n      // Too much contention; double array size in an effort to reduce contention\n      //long r = _resizers;\n      //final int newbytes = (t.length<<1)<<3/*word to bytes*/;\n      //while( !_resizerUpdater.compareAndSet(this,r,r+newbytes) )\n      //  r = _resizers;\n      //r += newbytes;\n      if( master._cat != this ) return old; // Already doubled, don't bother\n      //if( (r>>17) != 0 ) {      // Already too much allocation attempts?\n      //  // We could use a wait with timeout, so we'll wakeup as soon as the new\n      //  // table is ready, or after the timeout in any case.  Annoyingly, this\n      //  // breaks the non-blocking property - so for now we just briefly sleep.\n      //  //synchronized( this ) { wait(8*megs); }         // Timeout - we always wakeup\n      //  try { Thread.sleep(r>>17); } catch( InterruptedException e ) { }\n      //  if( master._cat != this ) return old;\n      //}\n\n      CAT newcat = new CAT(this,t.length*2,0);\n      // Take 1 stab at updating the CAT with the new larger size.  If this\n      // fails, we assume some other thread already expanded the CAT - so we\n      // do not need to retry until it succeeds.\n      while( master._cat == this && !master.CAS_cat(this,newcat) ) {/*empty*/}\n      return old;\n    }\n\n\n    // Return the current sum of all things in the table.  Writers can be\n    // updating the table furiously, so the sum is only locally accurate.\n    public long sum( ) {\n      long sum = _next == null ? 0 : _next.sum(); // Recursively get cached sum\n      final long[] t = _t;\n      for( long cnt : t ) sum += cnt;\n      return sum;\n    }\n\n    // Fast fuzzy version.  Used a cached value until it gets old, then re-up\n    // the cache.\n    public long estimate_sum( ) {\n      // For short tables, just do the work\n      if( _t.length <= 64 ) return sum();\n      // For bigger tables, periodically freshen a cached value\n      long millis = System.currentTimeMillis();\n      if( _fuzzy_time != millis ) { // Time marches on?\n        _fuzzy_sum_cache = sum(); // Get sum the hard way\n        _fuzzy_time = millis;   // Indicate freshness of cached value\n      }\n      return _fuzzy_sum_cache;  // Return cached sum\n    }\n\n    public String toString( ) { return Long.toString(sum()); }\n\n    public void print() {\n      long[] t = _t;\n      System.out.print(\"[\"+t[0]);\n      for( int i=1; i<t.length; i++ )\n        System.out.print(\",\"+t[i]);\n      System.out.print(\"]\");\n      if( _next != null ) _next.print();\n    }\n  }\n}\n",
        "simple_context": "package org.jctools.maps;\n\nimport static org.jctools.util.UnsafeAccess.UNSAFE;\n\nimport java.io.Serializable;\n\nimport java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n\npublic class ConcurrentAutoTable implements Serializable {\n    public  add(long x);\n    public  decrement();\n    public  increment();\n    public  set(long x);\n    public long get();\n    public int intValue();\n    public long longValue();\n    public long estimate_get();\n    public String toString();\n    public  print();\n    public int internal_size();\n    private long add_if(long x);\n    volatile private CAT _cat;\n    static private AtomicReferenceFieldUpdater<ConcurrentAutoTable, CAT> _catUpdater;\n    private boolean CAS_cat(CAT oldcat, CAT newcat);\n    static private int hash();\n    static private class CAT implements Serializable {\n        static final private int _Lbase;\n        static final private int _Lscale;\n        static private long rawIndex(long[] ary, int i);\n        static private boolean CAS(long[] A, int idx, long old, long nnn);\n        final private CAT _next;\n        volatile private long _fuzzy_sum_cache;\n        volatile private long _fuzzy_time;\n        static final private int MAX_SPIN;\n        final private long[] _t;\n        CAT(CAT next, int sz, long init);\n        public long add_if(long x, int hash, ConcurrentAutoTable master);\n        public long sum();\n        public long estimate_sum();\n        public String toString();\n        public  print();\n    }\n}\n\n"
    },
    {
        "project_name": "JCTools",
        "file_name": "NonBlockingHashMap.java",
        "relative_path": "JCTools/jctools-core/src/main/java/org/jctools/maps/NonBlockingHashMap.java",
        "execute_path": "JCTools",
        "package": "org.jctools.maps",
        "docstring": "/**\n   * Returns a string representation of this map.  The string representation\n   * consists of a list of key-value mappings in the order returned by the\n   * map's <tt>entrySet</tt> view's iterator, enclosed in braces\n   * (<tt>\"{}\"</tt>).  Adjacent mappings are separated by the characters\n   * <tt>\", \"</tt> (comma and space).  Each key-value mapping is rendered as\n   * the key followed by an equals sign (<tt>\"=\"</tt>) followed by the\n   * associated value.  Keys and values are converted to strings as by\n   * {@link String#valueOf(Object)}.\n   *\n   * @return a string representation of this map\n   */",
        "source_code": "\n@Override\npublic String toString() {\n  Iterator<Entry<TypeK,TypeV>> i = entrySet().iterator();\n  if( !i.hasNext())\n    return \"{}\";\n\n  StringBuilder sb = new StringBuilder();\n  sb.append('{');\n  for (;;) {\n    Entry<TypeK,TypeV> e = i.next();\n    TypeK key = e.getKey();\n    TypeV value = e.getValue();\n    sb.append(key   == this ? \"(this Map)\" : key);\n    sb.append('=');\n    sb.append(value == this ? \"(this Map)\" : value);\n    if( !i.hasNext())\n      return sb.append('}').toString();\n    sb.append(\", \");\n  }\n}\n",
        "class_name": "NonBlockingHashMap",
        "method_name": "toString",
        "argument_name": [],
        "full_context": "/*\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.jctools.maps;\n\nimport java.io.IOException;\nimport java.io.Serializable;\nimport java.util.*;\nimport java.util.concurrent.ConcurrentMap;\nimport java.util.concurrent.atomic.AtomicLongFieldUpdater;\nimport java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n\nimport org.jctools.util.RangeUtil;\n\nimport static org.jctools.util.UnsafeAccess.UNSAFE;\nimport static org.jctools.util.UnsafeAccess.fieldOffset;\n\n/**\n * A lock-free alternate implementation of {@link java.util.concurrent.ConcurrentHashMap}\n * with better scaling properties and generally lower costs to mutate the Map.\n * It provides identical correctness properties as ConcurrentHashMap.  All\n * operations are non-blocking and multi-thread safe, including all update\n * operations.  {@link NonBlockingHashMap} scales substantially better than\n * {@link java.util.concurrent.ConcurrentHashMap} for high update rates, even with a\n * large concurrency factor.  Scaling is linear up to 768 CPUs on a 768-CPU\n * Azul box, even with 100% updates or 100% reads or any fraction in-between.\n * Linear scaling up to all cpus has been observed on a 32-way Sun US2 box,\n * 32-way Sun Niagara box, 8-way Intel box and a 4-way Power box.\n *\n * This class obeys the same functional specification as {@link\n * java.util.Hashtable}, and includes versions of methods corresponding to\n * each method of <tt>Hashtable</tt>. However, even though all operations are\n * thread-safe, operations do <em>not</em> entail locking and there is\n * <em>not</em> any support for locking the entire table in a way that\n * prevents all access.  This class is fully interoperable with\n * <tt>Hashtable</tt> in programs that rely on its thread safety but not on\n * its synchronization details.\n *\n * <p> Operations (including <tt>put</tt>) generally do not block, so may\n * overlap with other update operations (including other <tt>puts</tt> and\n * <tt>removes</tt>).  Retrievals reflect the results of the most recently\n * <em>completed</em> update operations holding upon their onset.  For\n * aggregate operations such as <tt>putAll</tt>, concurrent retrievals may\n * reflect insertion or removal of only some entries.  Similarly, Iterators\n * and Enumerations return elements reflecting the state of the hash table at\n * some point at or since the creation of the iterator/enumeration.  They do\n * <em>not</em> throw {@link ConcurrentModificationException}.  However,\n * iterators are designed to be used by only one thread at a time.\n *\n * <p> Very full tables, or tables with high re-probe rates may trigger an\n * internal resize operation to move into a larger table.  Resizing is not\n * terribly expensive, but it is not free either; during resize operations\n * table throughput may drop somewhat.  All threads that visit the table\n * during a resize will 'help' the resizing but will still be allowed to\n * complete their operation before the resize is finished (i.e., a simple\n * 'get' operation on a million-entry table undergoing resizing will not need\n * to block until the entire million entries are copied).\n *\n * <p>This class and its views and iterators implement all of the\n * <em>optional</em> methods of the {@link Map} and {@link Iterator}\n * interfaces.\n *\n * <p> Like {@link Hashtable} but unlike {@link HashMap}, this class\n * does <em>not</em> allow <tt>null</tt> to be used as a key or value.\n *\n *\n * @since 1.5\n * @author Cliff Click\n * @param <TypeK> the type of keys maintained by this map\n * @param <TypeV> the type of mapped values\n */\n\npublic class NonBlockingHashMap<TypeK, TypeV>\n  extends AbstractMap<TypeK, TypeV>\n  implements ConcurrentMap<TypeK, TypeV>, Cloneable, Serializable {\n\n  private static final long serialVersionUID = 1234123412341234123L;\n\n  private static final int REPROBE_LIMIT=10; // Too many reprobes then force a table-resize\n\n  // --- Bits to allow Unsafe access to arrays\n  private static final int _Obase  = UNSAFE.arrayBaseOffset(Object[].class);\n  private static final int _Oscale = UNSAFE.arrayIndexScale(Object[].class);\n  private static final int _Olog   = _Oscale==4?2:(_Oscale==8?3:9999);\n  private static long rawIndex(final Object[] ary, final int idx) {\n    assert idx >= 0 && idx < ary.length;\n    // Note the long-math requirement, to handle arrays of more than 2^31 bytes\n    // - or 2^28 - or about 268M - 8-byte pointer elements.\n    return _Obase + ((long)idx << _Olog);\n  }\n\n  // --- Setup to use Unsafe\n  private static final long _kvs_offset = fieldOffset(NonBlockingHashMap.class, \"_kvs\");\n\n  private final boolean CAS_kvs( final Object[] oldkvs, final Object[] newkvs ) {\n    return UNSAFE.compareAndSwapObject(this, _kvs_offset, oldkvs, newkvs );\n  }\n\n  // --- Adding a 'prime' bit onto Values via wrapping with a junk wrapper class\n  private static final class Prime {\n    final Object _V;\n    Prime( Object V ) { _V = V; }\n    static Object unbox( Object V ) { return V instanceof Prime ? ((Prime)V)._V : V; }\n  }\n\n  // --- hash ----------------------------------------------------------------\n  // Helper function to spread lousy hashCodes.  Throws NPE for null Key, on\n  // purpose - as the first place to conveniently toss the required NPE for a\n  // null Key.\n  private static final int hash(final Object key) {\n    int h = key.hashCode();     // The real hashCode call\n    h ^= (h>>>20) ^ (h>>>12);\n    h ^= (h>>> 7) ^ (h>>> 4);\n\th += h<<7; // smear low bits up high, for hashcodes that only differ by 1\n    return h;\n  }\n\n  // --- The Hash Table --------------------\n  // Slot 0 is always used for a 'CHM' entry below to hold the interesting\n  // bits of the hash table.  Slot 1 holds full hashes as an array of ints.\n  // Slots {2,3}, {4,5}, etc hold {Key,Value} pairs.  The entire hash table\n  // can be atomically replaced by CASing the _kvs field.\n  //\n  // Why is CHM buried inside the _kvs Object array, instead of the other way\n  // around?  The CHM info is used during resize events and updates, but not\n  // during standard 'get' operations.  I assume 'get' is much more frequent\n  // than 'put'.  'get' can skip the extra indirection of skipping through the\n  // CHM to reach the _kvs array.\n  private transient Object[] _kvs;\n  private static final CHM   chm   (Object[] kvs) { return (CHM  )kvs[0]; }\n  private static final int[] hashes(Object[] kvs) { return (int[])kvs[1]; }\n  // Number of K,V pairs in the table\n  private static final int len(Object[] kvs) { return (kvs.length-2)>>1; }\n\n  // Time since last resize\n  private transient long _last_resize_milli;\n\n  // --- Minimum table size ----------------\n  // Pick size 8 K/V pairs, which turns into (8*2+2)*4+12 = 84 bytes on a\n  // standard 32-bit HotSpot, and (8*2+2)*8+12 = 156 bytes on 64-bit Azul.\n  private static final int MIN_SIZE_LOG=3;             //\n  private static final int MIN_SIZE=(1<<MIN_SIZE_LOG); // Must be power of 2\n\n  // --- Sentinels -------------------------\n  // No-Match-Old - putIfMatch does updates only if it matches the old value,\n  // and NO_MATCH_OLD basically counts as a wildcard match.\n  private static final Object NO_MATCH_OLD = new Object(); // Sentinel\n  // Match-Any-not-null - putIfMatch does updates only if it find a real old\n  // value.\n  private static final Object MATCH_ANY = new Object(); // Sentinel\n  // This K/V pair has been deleted (but the Key slot is forever claimed).\n  // The same Key can be reinserted with a new value later.\n  public static final Object TOMBSTONE = new Object();\n  // Prime'd or box'd version of TOMBSTONE.  This K/V pair was deleted, then a\n  // table resize started.  The K/V pair has been marked so that no new\n  // updates can happen to the old table (and since the K/V pair was deleted\n  // nothing was copied to the new table).\n  private static final Prime TOMBPRIME = new Prime(TOMBSTONE);\n\n  // --- key,val -------------------------------------------------------------\n  // Access K,V for a given idx\n  //\n  // Note that these are static, so that the caller is forced to read the _kvs\n  // field only once, and share that read across all key/val calls - lest the\n  // _kvs field move out from under us and back-to-back key & val calls refer\n  // to different _kvs arrays.\n  private static final Object key(Object[] kvs,int idx) { return kvs[(idx<<1)+2]; }\n  private static final Object val(Object[] kvs,int idx) { return kvs[(idx<<1)+3]; }\n  private static final boolean CAS_key( Object[] kvs, int idx, Object old, Object key ) {\n    return UNSAFE.compareAndSwapObject( kvs, rawIndex(kvs,(idx<<1)+2), old, key );\n  }\n  private static final boolean CAS_val( Object[] kvs, int idx, Object old, Object val ) {\n    return UNSAFE.compareAndSwapObject( kvs, rawIndex(kvs,(idx<<1)+3), old, val );\n  }\n\n\n  // --- dump ----------------------------------------------------------------\n  /** Verbose printout of table internals, useful for debugging.  */\n  public final void print() {\n    System.out.println(\"=========\");\n    print2(_kvs);\n    System.out.println(\"=========\");\n  }\n  // print the entire state of the table\n  private final void print( Object[] kvs ) {\n    for( int i=0; i<len(kvs); i++ ) {\n      Object K = key(kvs,i);\n      if( K != null ) {\n        String KS = (K == TOMBSTONE) ? \"XXX\" : K.toString();\n        Object V = val(kvs,i);\n        Object U = Prime.unbox(V);\n        String p = (V==U) ? \"\" : \"prime_\";\n        String US = (U == TOMBSTONE) ? \"tombstone\" : U.toString();\n        System.out.println(\"\"+i+\" (\"+KS+\",\"+p+US+\")\");\n      }\n    }\n    Object[] newkvs = chm(kvs)._newkvs; // New table, if any\n    if( newkvs != null ) {\n      System.out.println(\"----\");\n      print(newkvs);\n    }\n  }\n  // print only the live values, broken down by the table they are in\n  private final void print2( Object[] kvs) {\n    for( int i=0; i<len(kvs); i++ ) {\n      Object key = key(kvs,i);\n      Object val = val(kvs,i);\n      Object U = Prime.unbox(val);\n      if( key != null && key != TOMBSTONE &&  // key is sane\n          val != null && U   != TOMBSTONE ) { // val is sane\n        String p = (val==U) ? \"\" : \"prime_\";\n        System.out.println(\"\"+i+\" (\"+key+\",\"+p+val+\")\");\n      }\n    }\n    Object[] newkvs = chm(kvs)._newkvs; // New table, if any\n    if( newkvs != null ) {\n      System.out.println(\"----\");\n      print2(newkvs);\n    }\n  }\n\n  // Count of reprobes\n  private transient ConcurrentAutoTable _reprobes = new ConcurrentAutoTable();\n  /** Get and clear the current count of reprobes.  Reprobes happen on key\n   *  collisions, and a high reprobe rate may indicate a poor hash function or\n   *  weaknesses in the table resizing function.\n   *  @return the count of reprobes since the last call to {@link #reprobes}\n   *  or since the table was created.   */\n  public long reprobes() { long r = _reprobes.get(); _reprobes = new ConcurrentAutoTable(); return r; }\n\n\n  // --- reprobe_limit -----------------------------------------------------\n  // Heuristic to decide if we have reprobed toooo many times.  Running over\n  // the reprobe limit on a 'get' call acts as a 'miss'; on a 'put' call it\n  // can trigger a table resize.  Several places must have exact agreement on\n  // what the reprobe_limit is, so we share it here.\n  private static int reprobe_limit( int len ) {\n    return REPROBE_LIMIT + (len>>4);\n  }\n\n  // --- NonBlockingHashMap --------------------------------------------------\n  // Constructors\n\n  /** Create a new NonBlockingHashMap with default minimum size (currently set\n   *  to 8 K/V pairs or roughly 84 bytes on a standard 32-bit JVM). */\n  public NonBlockingHashMap( ) { this(MIN_SIZE); }\n\n  /** Create a new NonBlockingHashMap with initial room for the given number of\n   *  elements, thus avoiding internal resizing operations to reach an\n   *  appropriate size.  Large numbers here when used with a small count of\n   *  elements will sacrifice space for a small amount of time gained.  The\n   *  initial size will be rounded up internally to the next larger power of 2. */\n  public NonBlockingHashMap( final int initial_sz ) { initialize(initial_sz); }\n  private final void initialize( int initial_sz ) {\n    RangeUtil.checkPositiveOrZero(initial_sz, \"initial_sz\");\n    int i;                      // Convert to next largest power-of-2\n    if( initial_sz > 1024*1024 ) initial_sz = 1024*1024;\n    for( i=MIN_SIZE_LOG; (1<<i) < (initial_sz<<2); i++ ) ;\n    // Double size for K,V pairs, add 1 for CHM and 1 for hashes\n    _kvs = new Object[((1<<i)<<1)+2];\n    _kvs[0] = new CHM(new ConcurrentAutoTable()); // CHM in slot 0\n    _kvs[1] = new int[1<<i];          // Matching hash entries\n    _last_resize_milli = System.currentTimeMillis();\n  }\n  // Version for subclassed readObject calls, to be called after the defaultReadObject\n  protected final void initialize() { initialize(MIN_SIZE); }\n\n  // --- wrappers ------------------------------------------------------------\n\n  /** Returns the number of key-value mappings in this map.\n   *  @return the number of key-value mappings in this map */\n  @Override\n  public int     size       ( )                       { return chm(_kvs).size(); }\n  /** Returns <tt>size() == 0</tt>.\n   *  @return <tt>size() == 0</tt> */\n  @Override\n  public boolean isEmpty    ( )                       { return size() == 0;      }\n\n  /** Tests if the key in the table using the <tt>equals</tt> method.\n   * @return <tt>true</tt> if the key is in the table using the <tt>equals</tt> method\n   * @throws NullPointerException if the specified key is null  */\n  @Override\n  public boolean containsKey( Object key )            { return get(key) != null; }\n\n  /** Legacy method testing if some key maps into the specified value in this\n   *  table.  This method is identical in functionality to {@link\n   *  #containsValue}, and exists solely to ensure full compatibility with\n   *  class {@link java.util.Hashtable}, which supported this method prior to\n   *  introduction of the Java Collections framework.\n   *  @param  val a value to search for\n   *  @return <tt>true</tt> if this map maps one or more keys to the specified value\n   *  @throws NullPointerException if the specified value is null */\n  public boolean contains   ( Object val )            { return containsValue(val); }\n\n  /** Maps the specified key to the specified value in the table.  Neither key\n   *  nor value can be null.\n   *  <p> The value can be retrieved by calling {@link #get} with a key that is\n   *  equal to the original key.\n   *  @param key key with which the specified value is to be associated\n   *  @param val value to be associated with the specified key\n   *  @return the previous value associated with <tt>key</tt>, or\n   *          <tt>null</tt> if there was no mapping for <tt>key</tt>\n   *  @throws NullPointerException if the specified key or value is null  */\n  @Override\n  public TypeV   put        ( TypeK  key, TypeV val ) { return putIfMatch( key,      val, NO_MATCH_OLD); }\n\n  /** Atomically, do a {@link #put} if-and-only-if the key is not mapped.\n   *  Useful to ensure that only a single mapping for the key exists, even if\n   *  many threads are trying to create the mapping in parallel.\n   *  @return the previous value associated with the specified key,\n   *         or <tt>null</tt> if there was no mapping for the key\n   *  @throws NullPointerException if the specified key or value is null  */\n  @Override\n  public TypeV   putIfAbsent( TypeK  key, TypeV val ) { return putIfMatch( key,      val, TOMBSTONE   ); }\n\n  /** Removes the key (and its corresponding value) from this map.\n   *  This method does nothing if the key is not in the map.\n   *  @return the previous value associated with <tt>key</tt>, or\n   *         <tt>null</tt> if there was no mapping for <tt>key</tt>\n   *  @throws NullPointerException if the specified key is null */\n  @Override\n  public TypeV   remove     ( Object key )            { return putIfMatch( key,TOMBSTONE, NO_MATCH_OLD); }\n\n  /** Atomically do a {@link #remove(Object)} if-and-only-if the key is mapped\n   *  to a value which is <code>equals</code> to the given value.\n   *  @throws NullPointerException if the specified key or value is null */\n  public boolean remove     ( Object key,Object val ) {\n    return objectsEquals(putIfMatch( key,TOMBSTONE, val ), val);\n  }\n\n  /** Atomically do a <code>put(key,val)</code> if-and-only-if the key is\n   *  mapped to some value already.\n   *  @throws NullPointerException if the specified key or value is null */\n  @Override\n  public TypeV   replace    ( TypeK  key, TypeV val ) { return putIfMatch( key,      val,MATCH_ANY   ); }\n\n  /** Atomically do a <code>put(key,newValue)</code> if-and-only-if the key is\n   *  mapped a value which is <code>equals</code> to <code>oldValue</code>.\n   *  @throws NullPointerException if the specified key or value is null */\n  @Override\n  public boolean replace    ( TypeK  key, TypeV  oldValue, TypeV newValue ) {\n    return objectsEquals(putIfMatch( key, newValue, oldValue ), oldValue);\n  }\n  private static boolean objectsEquals(Object a, Object b) {\n    return (a == b) || (a != null && a.equals(b));\n  }\n\n  // Atomically replace newVal for oldVal, returning the value that existed\n  // there before.  If the oldVal matches the returned value, then newVal was\n  // inserted, otherwise not.  A null oldVal means the key does not exist (only\n  // insert if missing); a null newVal means to remove the key.\n  public final TypeV putIfMatchAllowNull( Object key, Object newVal, Object oldVal ) {\n    if( oldVal == null ) oldVal = TOMBSTONE;\n    if( newVal == null ) newVal = TOMBSTONE;\n    final TypeV res = (TypeV) putIfMatch0(this, _kvs, key, newVal, oldVal );\n    assert !(res instanceof Prime);\n    //assert res != null;\n    return res == TOMBSTONE ? null : res;\n  }\n\n  /** Atomically replace newVal for oldVal, returning the value that existed\n   *  there before.  If the oldVal matches the returned value, then newVal was\n   *  inserted, otherwise not.\n   *  @return the previous value associated with the specified key,\n   *         or <tt>null</tt> if there was no mapping for the key\n   *  @throws NullPointerException if the key or either value is null\n   */\n  public final TypeV putIfMatch( Object key, Object newVal, Object oldVal ) {\n    if (oldVal == null || newVal == null) throw new NullPointerException();\n    final Object res = putIfMatch0(this, _kvs, key, newVal, oldVal );\n    assert !(res instanceof Prime);\n    assert res != null;\n    return res == TOMBSTONE ? null : (TypeV)res;\n  }\n\n\n  /** Copies all of the mappings from the specified map to this one, replacing\n   *  any existing mappings.\n   *  @param m mappings to be stored in this map */\n  @Override\n  public void putAll(Map<? extends TypeK, ? extends TypeV> m) {\n    for (Map.Entry<? extends TypeK, ? extends TypeV> e : m.entrySet())\n      put(e.getKey(), e.getValue());\n  }\n\n  /** Removes all of the mappings from this map. */\n  @Override\n  public void clear() {         // Smack a new empty table down\n    Object[] newkvs = new NonBlockingHashMap(MIN_SIZE)._kvs;\n    while( !CAS_kvs(_kvs,newkvs) ) // Spin until the clear works\n      ;\n  }\n\n  /** Returns <tt>true</tt> if this Map maps one or more keys to the specified\n   *  value.  <em>Note</em>: This method requires a full internal traversal of the\n   *  hash table and is much slower than {@link #containsKey}.\n   *  @param val value whose presence in this map is to be tested\n   *  @return <tt>true</tt> if this map maps one or more keys to the specified value\n   *  @throws NullPointerException if the specified value is null */\n  @Override\n  public boolean containsValue( final Object val ) {\n    if( val == null ) throw new NullPointerException();\n    for( TypeV V : values() )\n      if( V == val || V.equals(val) )\n        return true;\n    return false;\n  }\n\n  // This function is supposed to do something for Hashtable, and the JCK\n  // tests hang until it gets called... by somebody ... for some reason,\n  // any reason....\n  protected void rehash() {\n  }\n\n  /**\n   * Creates a shallow copy of this hashtable. All the structure of the\n   * hashtable itself is copied, but the keys and values are not cloned.\n   * This is a relatively expensive operation.\n   *\n   * @return  a clone of the hashtable.\n   */\n  @Override\n  public Object clone() {\n    try {\n      // Must clone, to get the class right; NBHM might have been\n      // extended so it would be wrong to just make a new NBHM.\n      NonBlockingHashMap<TypeK,TypeV> t = (NonBlockingHashMap<TypeK,TypeV>) super.clone();\n      // But I don't have an atomic clone operation - the underlying _kvs\n      // structure is undergoing rapid change.  If I just clone the _kvs\n      // field, the CHM in _kvs[0] won't be in sync.\n      //\n      // Wipe out the cloned array (it was shallow anyways).\n      t.clear();\n      // Now copy sanely\n      for( TypeK K : keySet() ) {\n        final TypeV V = get(K);  // Do an official 'get'\n        t.put(K,V);\n      }\n      return t;\n    } catch (CloneNotSupportedException e) {\n      // this shouldn't happen, since we are Cloneable\n      throw new InternalError();\n    }\n  }\n\n  /**\n   * Returns a string representation of this map.  The string representation\n   * consists of a list of key-value mappings in the order returned by the\n   * map's <tt>entrySet</tt> view's iterator, enclosed in braces\n   * (<tt>\"{}\"</tt>).  Adjacent mappings are separated by the characters\n   * <tt>\", \"</tt> (comma and space).  Each key-value mapping is rendered as\n   * the key followed by an equals sign (<tt>\"=\"</tt>) followed by the\n   * associated value.  Keys and values are converted to strings as by\n   * {@link String#valueOf(Object)}.\n   *\n   * @return a string representation of this map\n   */\n  @Override\n  public String toString() {\n    Iterator<Entry<TypeK,TypeV>> i = entrySet().iterator();\n    if( !i.hasNext())\n      return \"{}\";\n\n    StringBuilder sb = new StringBuilder();\n    sb.append('{');\n    for (;;) {\n      Entry<TypeK,TypeV> e = i.next();\n      TypeK key = e.getKey();\n      TypeV value = e.getValue();\n      sb.append(key   == this ? \"(this Map)\" : key);\n      sb.append('=');\n      sb.append(value == this ? \"(this Map)\" : value);\n      if( !i.hasNext())\n        return sb.append('}').toString();\n      sb.append(\", \");\n    }\n  }\n\n  // --- keyeq ---------------------------------------------------------------\n  // Check for key equality.  Try direct pointer compare first, then see if\n  // the hashes are unequal (fast negative test) and finally do the full-on\n  // 'equals' v-call.\n  private static boolean keyeq( Object K, Object key, int[] hashes, int hash, int fullhash ) {\n    return\n      K==key ||                 // Either keys match exactly OR\n      // hash exists and matches?  hash can be zero during the install of a\n      // new key/value pair.\n      ((hashes[hash] == 0 || hashes[hash] == fullhash) &&\n       // Do not call the users' \"equals()\" call with a Tombstone, as this can\n       // surprise poorly written \"equals()\" calls that throw exceptions\n       // instead of simply returning false.\n       K != TOMBSTONE &&        // Do not call users' equals call with a Tombstone\n       // Do the match the hard way - with the users' key being the loop-\n       // invariant \"this\" pointer.  I could have flipped the order of\n       // operands (since equals is commutative), but I'm making mega-morphic\n       // v-calls in a re-probing loop and nailing down the 'this' argument\n       // gives both the JIT and the hardware a chance to prefetch the call target.\n       key.equals(K));          // Finally do the hard match\n  }\n\n  // --- get -----------------------------------------------------------------\n  /** Returns the value to which the specified key is mapped, or {@code null}\n   *  if this map contains no mapping for the key.\n   *  <p>More formally, if this map contains a mapping from a key {@code k} to\n   *  a value {@code v} such that {@code key.equals(k)}, then this method\n   *  returns {@code v}; otherwise it returns {@code null}.  (There can be at\n   *  most one such mapping.)\n   * @throws NullPointerException if the specified key is null */\n  // Never returns a Prime nor a Tombstone.\n  @Override\n  public TypeV get( Object key ) {\n    final Object V = get_impl(this,_kvs,key);\n    assert !(V instanceof Prime); // Never return a Prime\n    assert V != TOMBSTONE;\n    return (TypeV)V;\n  }\n\n  private static final Object get_impl( final NonBlockingHashMap topmap, final Object[] kvs, final Object key ) {\n    final int fullhash= hash (key); // throws NullPointerException if key is null\n    final int len     = len  (kvs); // Count of key/value pairs, reads kvs.length\n    final CHM chm     = chm  (kvs); // The CHM, for a volatile read below; reads slot 0 of kvs\n    final int[] hashes=hashes(kvs); // The memoized hashes; reads slot 1 of kvs\n\n    int idx = fullhash & (len-1); // First key hash\n\n    // Main spin/reprobe loop, looking for a Key hit\n    int reprobe_cnt=0;\n    while( true ) {\n      // Probe table.  Each read of 'val' probably misses in cache in a big\n      // table; hopefully the read of 'key' then hits in cache.\n      final Object K = key(kvs,idx); // Get key   before volatile read, could be null\n      final Object V = val(kvs,idx); // Get value before volatile read, could be null or Tombstone or Prime\n      if( K == null ) return null;   // A clear miss\n\n      // We need a volatile-read here to preserve happens-before semantics on\n      // newly inserted Keys.  If the Key body was written just before inserting\n      // into the table a Key-compare here might read the uninitialized Key body.\n      // Annoyingly this means we have to volatile-read before EACH key compare.\n      // .\n      // We also need a volatile-read between reading a newly inserted Value\n      // and returning the Value (so the user might end up reading the stale\n      // Value contents).  Same problem as with keys - and the one volatile\n      // read covers both.\n      final Object[] newkvs = chm._newkvs; // VOLATILE READ before key compare\n\n      // Key-compare\n      if( keyeq(K,key,hashes,idx,fullhash) ) {\n        // Key hit!  Check for no table-copy-in-progress\n        if( !(V instanceof Prime) ) // No copy?\n          return (V == TOMBSTONE) ? null : V; // Return the value\n        // Key hit - but slot is (possibly partially) copied to the new table.\n        // Finish the copy & retry in the new table.\n        return get_impl(topmap,chm.copy_slot_and_check(topmap,kvs,idx,key),key); // Retry in the new table\n      }\n      // get and put must have the same key lookup logic!  But only 'put'\n      // needs to force a table-resize for a too-long key-reprobe sequence.\n      // Check for too-many-reprobes on get - and flip to the new table.\n      if( ++reprobe_cnt >= reprobe_limit(len) || // too many probes\n          K == TOMBSTONE ) // found a TOMBSTONE key, means no more keys in this table\n        return newkvs == null ? null : get_impl(topmap,topmap.help_copy(newkvs),key); // Retry in the new table\n\n      idx = (idx+1)&(len-1);    // Reprobe by 1!  (could now prefetch)\n    }\n  }\n\n  // --- getk -----------------------------------------------------------------\n  /** Returns the Key to which the specified key is mapped, or {@code null}\n   *  if this map contains no mapping for the key.\n   * @throws NullPointerException if the specified key is null */\n  // Never returns a Prime nor a Tombstone.\n  public TypeK getk( TypeK key ) {\n    return (TypeK)getk_impl(this,_kvs,key);\n  }\n\n  private static final Object getk_impl( final NonBlockingHashMap topmap, final Object[] kvs, final Object key ) {\n    final int fullhash= hash (key); // throws NullPointerException if key is null\n    final int len     = len  (kvs); // Count of key/value pairs, reads kvs.length\n    final CHM chm     = chm  (kvs); // The CHM, for a volatile read below; reads slot 0 of kvs\n    final int[] hashes=hashes(kvs); // The memoized hashes; reads slot 1 of kvs\n\n    int idx = fullhash & (len-1); // First key hash\n\n    // Main spin/reprobe loop, looking for a Key hit\n    int reprobe_cnt=0;\n    while( true ) {\n      // Probe table.\n      final Object K = key(kvs,idx); // Get key before volatile read, could be null\n      if( K == null ) return null;   // A clear miss\n\n      // We need a volatile-read here to preserve happens-before semantics on\n      // newly inserted Keys.  If the Key body was written just before inserting\n      // into the table a Key-compare here might read the uninitialized Key body.\n      // Annoyingly this means we have to volatile-read before EACH key compare.\n      // .\n      // We also need a volatile-read between reading a newly inserted Value\n      // and returning the Value (so the user might end up reading the stale\n      // Value contents).  Same problem as with keys - and the one volatile\n      // read covers both.\n      final Object[] newkvs = chm._newkvs; // VOLATILE READ before key compare\n\n      // Key-compare\n      if( keyeq(K,key,hashes,idx,fullhash) )\n        return K;              // Return existing Key!\n\n      // get and put must have the same key lookup logic!  But only 'put'\n      // needs to force a table-resize for a too-long key-reprobe sequence.\n      // Check for too-many-reprobes on get - and flip to the new table.\n      if( ++reprobe_cnt >= reprobe_limit(len) || // too many probes\n          K == TOMBSTONE ) { // found a TOMBSTONE key, means no more keys in this table\n        return newkvs == null ? null : getk_impl(topmap,topmap.help_copy(newkvs),key); // Retry in the new table\n      }\n\n      idx = (idx+1)&(len-1);    // Reprobe by 1!  (could now prefetch)\n    }\n  }\n\n  static volatile int DUMMY_VOLATILE;\n  /**\n   * Put, Remove, PutIfAbsent, etc.  Return the old value.  If the returned value is equal to expVal (or expVal is\n   * {@link #NO_MATCH_OLD}) then the put can be assumed to work (although might have been immediately overwritten).\n   * Only the path through copy_slot passes in an expected value of null, and putIfMatch only returns a null if passed\n   * in an expected null.\n   *\n   * @param topmap the map to act on\n   * @param kvs the KV table snapshot we act on\n   * @param key not null (will result in {@link NullPointerException})\n   * @param putval the new value to use. Not null. {@link #TOMBSTONE} will result in deleting the entry.\n   * @param expVal expected old value. Can be null. {@link #NO_MATCH_OLD} for an unconditional put/remove.\n   *              {@link #TOMBSTONE} if we expect old entry to not exist(null/{@link #TOMBSTONE} value).\n   *              {@link #MATCH_ANY} will ignore the current value, but only if an entry exists. A null expVal is used\n   *               internally to perform a strict insert-if-never-been-seen-before operation.\n   * @return {@link #TOMBSTONE} if key does not exist or match has failed. null if expVal is\n   * null AND old value was null. Otherwise the old entry value (not null).\n   */\n  private static final Object putIfMatch0(\n      final NonBlockingHashMap topmap,\n      final Object[] kvs,\n      final Object key,\n      final Object putval,\n      final Object expVal)\n  {\n    assert putval != null;\n    assert !(putval instanceof Prime);\n    assert !(expVal instanceof Prime);\n    final int fullhash = hash  (key); // throws NullPointerException if key null\n    final int len      = len   (kvs); // Count of key/value pairs, reads kvs.length\n    final CHM chm      = chm   (kvs); // Reads kvs[0]\n    final int[] hashes = hashes(kvs); // Reads kvs[1], read before kvs[0]\n    int idx = fullhash & (len-1);\n\n    // ---\n    // Key-Claim stanza: spin till we can claim a Key (or force a resizing).\n    int reprobe_cnt=0;\n    Object K=null, V=null;\n    Object[] newkvs=null;\n    while( true ) {             // Spin till we get a Key slot\n      V = val(kvs,idx);         // Get old value (before volatile read below!)\n      K = key(kvs,idx);         // Get current key\n      if( K == null ) {         // Slot is free?\n        // Found an empty Key slot - which means this Key has never been in\n        // this table.  No need to put a Tombstone - the Key is not here!\n        if( putval == TOMBSTONE ) return TOMBSTONE; // Not-now & never-been in this table\n        if( expVal == MATCH_ANY ) return TOMBSTONE; // Will not match, even after K inserts\n        // Claim the null key-slot\n        if( CAS_key(kvs,idx, null, key ) ) { // Claim slot for Key\n          chm._slots.add(1);      // Raise key-slots-used count\n          hashes[idx] = fullhash; // Memoize fullhash\n          break;                  // Got it!\n        }\n        // CAS to claim the key-slot failed.\n        //\n        // This re-read of the Key points out an annoying short-coming of Java\n        // CAS.  Most hardware CAS's report back the existing value - so that\n        // if you fail you have a *witness* - the value which caused the CAS to\n        // fail.  The Java API turns this into a boolean destroying the\n        // witness.  Re-reading does not recover the witness because another\n        // thread can write over the memory after the CAS.  Hence we can be in\n        // the unfortunate situation of having a CAS fail *for cause* but\n        // having that cause removed by a later store.  This turns a\n        // non-spurious-failure CAS (such as Azul has) into one that can\n        // apparently spuriously fail - and we avoid apparent spurious failure\n        // by not allowing Keys to ever change.\n\n        // Volatile read, to force loads of K to retry despite JIT, otherwise\n        // it is legal to e.g. haul the load of \"K = key(kvs,idx);\" outside of\n        // this loop (since failed CAS ops have no memory ordering semantics).\n        int dummy = DUMMY_VOLATILE;\n        continue;\n      }\n      // Key slot was not null, there exists a Key here\n\n      // We need a volatile-read here to preserve happens-before semantics on\n      // newly inserted Keys.  If the Key body was written just before inserting\n      // into the table a Key-compare here might read the uninitialized Key body.\n      // Annoyingly this means we have to volatile-read before EACH key compare.\n      newkvs = chm._newkvs;     // VOLATILE READ before key compare\n\n      if( keyeq(K,key,hashes,idx,fullhash) )\n        break;                  // Got it!\n\n      // get and put must have the same key lookup logic!  Lest 'get' give\n      // up looking too soon.\n      //topmap._reprobes.add(1);\n      if( ++reprobe_cnt >= reprobe_limit(len) || // too many probes or\n          K == TOMBSTONE ) { // found a TOMBSTONE key, means no more keys\n        // We simply must have a new table to do a 'put'.  At this point a\n        // 'get' will also go to the new table (if any).  We do not need\n        // to claim a key slot (indeed, we cannot find a free one to claim!).\n        newkvs = chm.resize(topmap,kvs);\n        if( expVal != null ) topmap.help_copy(newkvs); // help along an existing copy\n        return putIfMatch0(topmap, newkvs, key, putval, expVal);\n      }\n\n      idx = (idx+1)&(len-1); // Reprobe!\n    } // End of spinning till we get a Key slot\n\n    while ( true ) {              // Spin till we insert a value\n      // ---\n      // Found the proper Key slot, now update the matching Value slot.  We\n      // never put a null, so Value slots monotonically move from null to\n      // not-null (deleted Values use Tombstone).  Thus if 'V' is null we\n      // fail this fast cutout and fall into the check for table-full.\n      if( putval == V ) return V; // Fast cutout for no-change\n\n      // See if we want to move to a new table (to avoid high average re-probe\n      // counts).  We only check on the initial set of a Value from null to\n      // not-null (i.e., once per key-insert).  Of course we got a 'free' check\n      // of newkvs once per key-compare (not really free, but paid-for by the\n      // time we get here).\n      if( newkvs == null &&       // New table-copy already spotted?\n          // Once per fresh key-insert check the hard way\n          ((V == null && chm.tableFull(reprobe_cnt,len)) ||\n           // Or we found a Prime, but the JMM allowed reordering such that we\n           // did not spot the new table (very rare race here: the writing\n           // thread did a CAS of _newkvs then a store of a Prime.  This thread\n           // reads the Prime, then reads _newkvs - but the read of Prime was so\n           // delayed (or the read of _newkvs was so accelerated) that they\n           // swapped and we still read a null _newkvs.  The resize call below\n           // will do a CAS on _newkvs forcing the read.\n           V instanceof Prime) ) {\n        newkvs = chm.resize(topmap, kvs); // Force the new table copy to start\n      }\n      // See if we are moving to a new table.\n      // If so, copy our slot and retry in the new table.\n      if( newkvs != null ) {\n        return putIfMatch0(topmap, chm.copy_slot_and_check(topmap, kvs, idx, expVal), key, putval, expVal);\n      }\n      // ---\n      // We are finally prepared to update the existing table\n      assert !(V instanceof Prime);\n\n      // Must match old, and we do not?  Then bail out now.  Note that either V\n      // or expVal might be TOMBSTONE.  Also V can be null, if we've never\n      // inserted a value before.  expVal can be null if we are called from\n      // copy_slot.\n      if( expVal != NO_MATCH_OLD && // Do we care about expected-Value at all?\n          V != expVal &&            // No instant match already?\n          (expVal != MATCH_ANY || V == TOMBSTONE || V == null) &&\n          !(V==null && expVal == TOMBSTONE) &&    // Match on null/TOMBSTONE combo\n          (expVal == null || !expVal.equals(V)) ) { // Expensive equals check at the last\n        return (V == null) ? TOMBSTONE : V;         // Do not update!\n      }\n\n      // Actually change the Value in the Key,Value pair\n      if( CAS_val(kvs, idx, V, putval ) ) break;\n\n      // CAS failed\n      // Because we have no witness, we do not know why it failed.\n      // Indeed, by the time we look again the value under test might have flipped\n      // a thousand times and now be the expected value (despite the CAS failing).\n      // Check for the never-succeed condition of a Prime value and jump to any\n      // nested table, or else just re-run.\n\n      // We would not need this load at all if CAS returned the value on which\n      // the CAS failed (AKA witness). The new CAS semantics are supported via\n      // VarHandle in JDK9.\n      V = val(kvs,idx);         // Get new value\n\n      // If a Prime'd value got installed, we need to re-run the put on the\n      // new table.  Otherwise we lost the CAS to another racing put.\n      if( V instanceof Prime )\n        return putIfMatch0(topmap, chm.copy_slot_and_check(topmap, kvs, idx, expVal), key, putval, expVal);\n\n      // Simply retry from the start.\n      // NOTE: need the fence, since otherwise 'val(kvs,idx)' load could be hoisted\n      // out of loop.\n      int dummy = DUMMY_VOLATILE;\n    }\n\n    // CAS succeeded - we did the update!\n    // Both normal put's and table-copy calls putIfMatch, but table-copy\n    // does not (effectively) increase the number of live k/v pairs.\n    if( expVal != null ) {\n      // Adjust sizes - a striped counter\n      if(  (V == null || V == TOMBSTONE) && putval != TOMBSTONE ) chm._size.add( 1);\n      if( !(V == null || V == TOMBSTONE) && putval == TOMBSTONE ) chm._size.add(-1);\n    }\n\n    // We won; we know the update happened as expected.\n    return (V==null && expVal!=null) ? TOMBSTONE : V;\n  }\n\n  // --- help_copy ---------------------------------------------------------\n  // Help along an existing resize operation.  This is just a fast cut-out\n  // wrapper, to encourage inlining for the fast no-copy-in-progress case.  We\n  // always help the top-most table copy, even if there are nested table\n  // copies in progress.\n  private final Object[] help_copy( Object[] helper ) {\n    // Read the top-level KVS only once.  We'll try to help this copy along,\n    // even if it gets promoted out from under us (i.e., the copy completes\n    // and another KVS becomes the top-level copy).\n    Object[] topkvs = _kvs;\n    CHM topchm = chm(topkvs);\n    if( topchm._newkvs == null ) return helper; // No copy in-progress\n    topchm.help_copy_impl(this,topkvs,false);\n    return helper;\n  }\n\n\n  // --- CHM -----------------------------------------------------------------\n  // The control structure for the NonBlockingHashMap\n  private static final class CHM<TypeK,TypeV> {\n    // Size in active K,V pairs\n    private final ConcurrentAutoTable _size;\n    public int size () { return (int)_size.get(); }\n\n    // ---\n    // These next 2 fields are used in the resizing heuristics, to judge when\n    // it is time to resize or copy the table.  Slots is a count of used-up\n    // key slots, and when it nears a large fraction of the table we probably\n    // end up reprobing too much.  Last-resize-milli is the time since the\n    // last resize; if we are running back-to-back resizes without growing\n    // (because there are only a few live keys but many slots full of dead\n    // keys) then we need a larger table to cut down on the churn.\n\n    // Count of used slots, to tell when table is full of dead unusable slots\n    private final ConcurrentAutoTable _slots;\n    public int slots() { return (int)_slots.get(); }\n\n    // ---\n    // New mappings, used during resizing.\n    // The 'new KVs' array - created during a resize operation.  This\n    // represents the new table being copied from the old one.  It's the\n    // volatile variable that is read as we cross from one table to the next,\n    // to get the required memory orderings.  It monotonically transits from\n    // null to set (once).\n    volatile Object[] _newkvs;\n    private static final AtomicReferenceFieldUpdater<CHM,Object[]> _newkvsUpdater =\n      AtomicReferenceFieldUpdater.newUpdater(CHM.class,Object[].class, \"_newkvs\");\n    // Set the _next field if we can.\n    boolean CAS_newkvs( Object[] newkvs ) {\n      while( _newkvs == null )\n        if( _newkvsUpdater.compareAndSet(this,null,newkvs) )\n          return true;\n      return false;\n    }\n\n    // Sometimes many threads race to create a new very large table.  Only 1\n    // wins the race, but the losers all allocate a junk large table with\n    // hefty allocation costs.  Attempt to control the overkill here by\n    // throttling attempts to create a new table.  I cannot really block here\n    // (lest I lose the non-blocking property) but late-arriving threads can\n    // give the initial resizing thread a little time to allocate the initial\n    // new table.  The Right Long Term Fix here is to use array-lets and\n    // incrementally create the new very large array.  In C I'd make the array\n    // with malloc (which would mmap under the hood) which would only eat\n    // virtual-address and not real memory - and after Somebody wins then we\n    // could in parallel initialize the array.  Java does not allow\n    // un-initialized array creation (especially of ref arrays!).\n    volatile long _resizers; // count of threads attempting an initial resize\n    private static final AtomicLongFieldUpdater<CHM> _resizerUpdater =\n      AtomicLongFieldUpdater.newUpdater(CHM.class, \"_resizers\");\n\n    // ---\n    // Simple constructor\n    CHM( ConcurrentAutoTable size ) {\n      _size = size;\n      _slots= new ConcurrentAutoTable();\n    }\n\n    // --- tableFull ---------------------------------------------------------\n    // Heuristic to decide if this table is too full, and we should start a\n    // new table.  Note that if a 'get' call has reprobed too many times and\n    // decided the table must be full, then always the estimate_sum must be\n    // high and we must report the table is full.  If we do not, then we might\n    // end up deciding that the table is not full and inserting into the\n    // current table, while a 'get' has decided the same key cannot be in this\n    // table because of too many reprobes.  The invariant is:\n    //   slots.estimate_sum >= max_reprobe_cnt >= reprobe_limit(len)\n    private final boolean tableFull( int reprobe_cnt, int len ) {\n      return\n        // Do the cheap check first: we allow some number of reprobes always\n        reprobe_cnt >= REPROBE_LIMIT &&\n        (reprobe_cnt >= reprobe_limit(len) ||\n         // More expensive check: see if the table is > 1/2 full.\n         _slots.estimate_get() >= (len>>1));\n    }\n\n    // --- resize ------------------------------------------------------------\n    // Resizing after too many probes.  \"How Big???\" heuristics are here.\n    // Callers will (not this routine) will 'help_copy' any in-progress copy.\n    // Since this routine has a fast cutout for copy-already-started, callers\n    // MUST 'help_copy' lest we have a path which forever runs through\n    // 'resize' only to discover a copy-in-progress which never progresses.\n    private final Object[] resize( NonBlockingHashMap topmap, Object[] kvs) {\n      assert chm(kvs) == this;\n\n      // Check for resize already in progress, probably triggered by another thread\n      Object[] newkvs = _newkvs; // VOLATILE READ\n      if( newkvs != null )       // See if resize is already in progress\n        return newkvs;           // Use the new table already\n\n      // No copy in-progress, so start one.  First up: compute new table size.\n      int oldlen = len(kvs);    // Old count of K,V pairs allowed\n      int sz = size();          // Get current table count of active K,V pairs\n      int newsz = sz;           // First size estimate\n\n      // Heuristic to determine new size.  We expect plenty of dead-slots-with-keys\n      // and we need some decent padding to avoid endless reprobing.\n      if( sz >= (oldlen>>2) ) { // If we are >25% full of keys then...\n        newsz = oldlen<<1;      // Double size, so new table will be between 12.5% and 25% full\n        // For tables less than 1M entries, if >50% full of keys then...\n        // For tables more than 1M entries, if >75% full of keys then...\n        if( 4L*sz >= ((oldlen>>20)!=0?3L:2L)*oldlen )\n          newsz = oldlen<<2;    // Double double size, so new table will be between %12.5 (18.75%) and 25% (25%)\n      }\n      // This heuristic in the next 2 lines leads to a much denser table\n      // with a higher reprobe rate\n      //if( sz >= (oldlen>>1) ) // If we are >50% full of keys then...\n      //  newsz = oldlen<<1;    // Double size\n\n      // Last (re)size operation was very recent?  Then double again\n      // despite having few live keys; slows down resize operations\n      // for tables subject to a high key churn rate - but do not\n      // forever grow the table.  If there is a high key churn rate\n      // the table needs a steady state of rare same-size resize\n      // operations to clean out the dead keys.\n      long tm = System.currentTimeMillis();\n      if( newsz <= oldlen && // New table would shrink or hold steady?\n          tm <= topmap._last_resize_milli+10000)  // Recent resize (less than 10 sec ago)\n        newsz = oldlen<<1;      // Double the existing size\n\n      // Do not shrink, ever.  If we hit this size once, assume we\n      // will again.\n      if( newsz < oldlen ) newsz = oldlen;\n\n      // Convert to power-of-2\n      int log2;\n      for( log2=MIN_SIZE_LOG; (1<<log2) < newsz; log2++ ) ; // Compute log2 of size\n      long len = ((1L << log2) << 1) + 2;\n      // prevent integer overflow - limit of 2^31 elements in a Java array\n      // so here, 2^30 + 2 is the largest number of elements in the hash table\n      if ((int)len!=len) {\n        log2 = 30;\n        len = (1L << log2) + 2;\n        if (sz > ((len >> 2) + (len >> 1))) throw new RuntimeException(\"Table is full.\");\n      }\n\n      // Now limit the number of threads actually allocating memory to a\n      // handful - lest we have 750 threads all trying to allocate a giant\n      // resized array.\n      long r = _resizers;\n      while( !_resizerUpdater.compareAndSet(this,r,r+1) )\n        r = _resizers;\n      // Size calculation: 2 words (K+V) per table entry, plus a handful.  We\n      // guess at 64-bit pointers; 32-bit pointers screws up the size calc by\n      // 2x but does not screw up the heuristic very much.\n      long megs = ((((1L<<log2)<<1)+8)<<3/*word to bytes*/)>>20/*megs*/;\n      if( r >= 2 && megs > 0 ) { // Already 2 guys trying; wait and see\n        newkvs = _newkvs;        // Between dorking around, another thread did it\n        if( newkvs != null )     // See if resize is already in progress\n          return newkvs;         // Use the new table already\n        // TODO - use a wait with timeout, so we'll wakeup as soon as the new table\n        // is ready, or after the timeout in any case.\n        //synchronized( this ) { wait(8*megs); }         // Timeout - we always wakeup\n        // For now, sleep a tad and see if the 2 guys already trying to make\n        // the table actually get around to making it happen.\n        try { Thread.sleep(megs); } catch( Exception e ) { }\n      }\n      // Last check, since the 'new' below is expensive and there is a chance\n      // that another thread slipped in a new thread while we ran the heuristic.\n      newkvs = _newkvs;\n      if( newkvs != null )      // See if resize is already in progress\n        return newkvs;          // Use the new table already\n\n      // Double size for K,V pairs, add 1 for CHM\n      newkvs = new Object[(int)len]; // This can get expensive for big arrays\n      newkvs[0] = new CHM(_size); // CHM in slot 0\n      newkvs[1] = new int[1<<log2]; // hashes in slot 1\n\n      // Another check after the slow allocation\n      if( _newkvs != null )     // See if resize is already in progress\n        return _newkvs;         // Use the new table already\n\n      // The new table must be CAS'd in so only 1 winner amongst duplicate\n      // racing resizing threads.  Extra CHM's will be GC'd.\n      if( CAS_newkvs( newkvs ) ) { // NOW a resize-is-in-progress!\n        //notifyAll();            // Wake up any sleepers\n        //long nano = System.nanoTime();\n        //System.out.println(\" \"+nano+\" Resize from \"+oldlen+\" to \"+(1<<log2)+\" and had \"+(_resizers-1)+\" extras\" );\n        //if( System.out != null ) System.out.print(\"[\"+log2);\n        topmap.rehash();        // Call for Hashtable's benefit\n      } else                    // CAS failed?\n        newkvs = _newkvs;       // Reread new table\n      return newkvs;\n    }\n\n\n    // The next part of the table to copy.  It monotonically transits from zero\n    // to _kvs.length.  Visitors to the table can claim 'work chunks' by\n    // CAS'ing this field up, then copying the indicated indices from the old\n    // table to the new table.  Workers are not required to finish any chunk;\n    // the counter simply wraps and work is copied duplicately until somebody\n    // somewhere completes the count.\n    volatile long _copyIdx = 0;\n    static private final AtomicLongFieldUpdater<CHM> _copyIdxUpdater =\n      AtomicLongFieldUpdater.newUpdater(CHM.class, \"_copyIdx\");\n\n    // Work-done reporting.  Used to efficiently signal when we can move to\n    // the new table.  From 0 to len(oldkvs) refers to copying from the old\n    // table to the new.\n    volatile long _copyDone= 0;\n    static private final AtomicLongFieldUpdater<CHM> _copyDoneUpdater =\n      AtomicLongFieldUpdater.newUpdater(CHM.class, \"_copyDone\");\n\n    // --- help_copy_impl ----------------------------------------------------\n    // Help along an existing resize operation.  We hope its the top-level\n    // copy (it was when we started) but this CHM might have been promoted out\n    // of the top position.\n    private final void help_copy_impl( NonBlockingHashMap topmap, Object[] oldkvs, boolean copy_all ) {\n      assert chm(oldkvs) == this;\n      Object[] newkvs = _newkvs;\n      assert newkvs != null;    // Already checked by caller\n      int oldlen = len(oldkvs); // Total amount to copy\n      final int MIN_COPY_WORK = Math.min(oldlen,1024); // Limit per-thread work\n\n      // ---\n      int panic_start = -1;\n      int copyidx=-9999;            // Fool javac to think it's initialized\n      while( _copyDone < oldlen ) { // Still needing to copy?\n        // Carve out a chunk of work.  The counter wraps around so every\n        // thread eventually tries to copy every slot repeatedly.\n\n        // We \"panic\" if we have tried TWICE to copy every slot - and it still\n        // has not happened.  i.e., twice some thread somewhere claimed they\n        // would copy 'slot X' (by bumping _copyIdx) but they never claimed to\n        // have finished (by bumping _copyDone).  Our choices become limited:\n        // we can wait for the work-claimers to finish (and become a blocking\n        // algorithm) or do the copy work ourselves.  Tiny tables with huge\n        // thread counts trying to copy the table often 'panic'.\n        if( panic_start == -1 ) { // No panic?\n          copyidx = (int)_copyIdx;\n          while( !_copyIdxUpdater.compareAndSet(this,copyidx,copyidx+MIN_COPY_WORK) )\n            copyidx = (int)_copyIdx;      // Re-read\n          if( !(copyidx < (oldlen<<1)) )  // Panic!\n            panic_start = copyidx;        // Record where we started to panic-copy\n        }\n\n        // We now know what to copy.  Try to copy.\n        int workdone = 0;\n        for( int i=0; i<MIN_COPY_WORK; i++ )\n          if( copy_slot(topmap,(copyidx+i)&(oldlen-1),oldkvs,newkvs) ) // Made an oldtable slot go dead?\n            workdone++;         // Yes!\n        if( workdone > 0 )      // Report work-done occasionally\n          copy_check_and_promote( topmap, oldkvs, workdone );// See if we can promote\n        //for( int i=0; i<MIN_COPY_WORK; i++ )\n        //  if( copy_slot(topmap,(copyidx+i)&(oldlen-1),oldkvs,newkvs) ) // Made an oldtable slot go dead?\n        //    copy_check_and_promote( topmap, oldkvs, 1 );// See if we can promote\n\n        copyidx += MIN_COPY_WORK;\n        // Uncomment these next 2 lines to turn on incremental table-copy.\n        // Otherwise this thread continues to copy until it is all done.\n        if( !copy_all && panic_start == -1 ) // No panic?\n          return;       // Then done copying after doing MIN_COPY_WORK\n      }\n      // Extra promotion check, in case another thread finished all copying\n      // then got stalled before promoting.\n      copy_check_and_promote( topmap, oldkvs, 0 );// See if we can promote\n    }\n\n\n    // --- copy_slot_and_check -----------------------------------------------\n    // Copy slot 'idx' from the old table to the new table.  If this thread\n    // confirmed the copy, update the counters and check for promotion.\n    //\n    // Returns the result of reading the volatile _newkvs, mostly as a\n    // convenience to callers.  We come here with 1-shot copy requests\n    // typically because the caller has found a Prime, and has not yet read\n    // the _newkvs volatile - which must have changed from null-to-not-null\n    // before any Prime appears.  So the caller needs to read the _newkvs\n    // field to retry his operation in the new table, but probably has not\n    // read it yet.\n    private final Object[] copy_slot_and_check( NonBlockingHashMap topmap, Object[] oldkvs, int idx, Object should_help ) {\n      assert chm(oldkvs) == this;\n      Object[] newkvs = _newkvs; // VOLATILE READ\n      // We're only here because the caller saw a Prime, which implies a\n      // table-copy is in progress.\n      assert newkvs != null;\n      if( copy_slot(topmap,idx,oldkvs,_newkvs) )   // Copy the desired slot\n        copy_check_and_promote(topmap, oldkvs, 1); // Record the slot copied\n      // Generically help along any copy (except if called recursively from a helper)\n      return (should_help == null) ? newkvs : topmap.help_copy(newkvs);\n    }\n\n    // --- copy_check_and_promote --------------------------------------------\n    private final void copy_check_and_promote( NonBlockingHashMap topmap, Object[] oldkvs, int workdone ) {\n      assert chm(oldkvs) == this;\n      int oldlen = len(oldkvs);\n      // We made a slot unusable and so did some of the needed copy work\n      long copyDone = _copyDone;\n      assert (copyDone+workdone) <= oldlen;\n      if( workdone > 0 ) {\n        while( !_copyDoneUpdater.compareAndSet(this,copyDone,copyDone+workdone) ) {\n          copyDone = _copyDone; // Reload, retry\n          assert (copyDone+workdone) <= oldlen;\n        }\n      }\n\n      // Check for copy being ALL done, and promote.  Note that we might have\n      // nested in-progress copies and manage to finish a nested copy before\n      // finishing the top-level copy.  We only promote top-level copies.\n      if( copyDone+workdone == oldlen && // Ready to promote this table?\n          topmap._kvs == oldkvs &&       // Looking at the top-level table?\n          // Attempt to promote\n          topmap.CAS_kvs(oldkvs,_newkvs) ) {\n        topmap._last_resize_milli = System.currentTimeMillis(); // Record resize time for next check\n      }\n    }\n\n    // --- copy_slot ---------------------------------------------------------\n    // Copy one K/V pair from oldkvs[i] to newkvs.  Returns true if we can\n    // confirm that we set an old-table slot to TOMBPRIME, and only returns after\n    // updating the new table.  We need an accurate confirmed-copy count so\n    // that we know when we can promote (if we promote the new table too soon,\n    // other threads may 'miss' on values not-yet-copied from the old table).\n    // We don't allow any direct updates on the new table, unless they first\n    // happened to the old table - so that any transition in the new table from\n    // null to not-null must have been from a copy_slot (or other old-table\n    // overwrite) and not from a thread directly writing in the new table.\n    private boolean copy_slot( NonBlockingHashMap topmap, int idx, Object[] oldkvs, Object[] newkvs ) {\n      // Blindly set the key slot from null to TOMBSTONE, to eagerly stop\n      // fresh put's from inserting new values in the old table when the old\n      // table is mid-resize.  We don't need to act on the results here,\n      // because our correctness stems from box'ing the Value field.  Slamming\n      // the Key field is a minor speed optimization.\n      Object key;\n      while( (key=key(oldkvs,idx)) == null )\n        CAS_key(oldkvs,idx, null, TOMBSTONE);\n\n      // ---\n      // Prevent new values from appearing in the old table.\n      // Box what we see in the old table, to prevent further updates.\n      Object oldval = val(oldkvs,idx); // Read OLD table\n      while( !(oldval instanceof Prime) ) {\n        final Prime box = (oldval == null || oldval == TOMBSTONE) ? TOMBPRIME : new Prime(oldval);\n        if( CAS_val(oldkvs,idx,oldval,box) ) { // CAS down a box'd version of oldval\n          // If we made the Value slot hold a TOMBPRIME, then we both\n          // prevented further updates here but also the (absent)\n          // oldval is vacuously available in the new table.  We\n          // return with true here: any thread looking for a value for\n          // this key can correctly go straight to the new table and\n          // skip looking in the old table.\n          if( box == TOMBPRIME )\n            return true;\n          // Otherwise we boxed something, but it still needs to be\n          // copied into the new table.\n          oldval = box;         // Record updated oldval\n          break;                // Break loop; oldval is now boxed by us\n        }\n        oldval = val(oldkvs,idx); // Else try, try again\n      }\n      if( oldval == TOMBPRIME ) return false; // Copy already complete here!\n\n      // ---\n      // Copy the value into the new table, but only if we overwrite a null.\n      // If another value is already in the new table, then somebody else\n      // wrote something there and that write is happens-after any value that\n      // appears in the old table.\n      Object old_unboxed = ((Prime)oldval)._V;\n      assert old_unboxed != TOMBSTONE;\n      putIfMatch0(topmap, newkvs, key, old_unboxed, null);\n\n      // ---\n      // Finally, now that any old value is exposed in the new table, we can\n      // forever hide the old-table value by slapping a TOMBPRIME down.  This\n      // will stop other threads from uselessly attempting to copy this slot\n      // (i.e., it's a speed optimization not a correctness issue).\n      while( oldval != TOMBPRIME && !CAS_val(oldkvs,idx,oldval,TOMBPRIME) )\n        oldval = val(oldkvs,idx);\n\n      return oldval != TOMBPRIME; // True if we slammed the TOMBPRIME down\n    } // end copy_slot\n  } // End of CHM\n\n\n  // --- Snapshot ------------------------------------------------------------\n  // The main class for iterating over the NBHM.  It \"snapshots\" a clean\n  // view of the K/V array.\n  private class SnapshotV implements Iterator<TypeV>, Enumeration<TypeV> {\n    final Object[] _sskvs;\n    public SnapshotV() {\n      while( true ) {           // Verify no table-copy-in-progress\n        Object[] topkvs = _kvs;\n        CHM topchm = chm(topkvs);\n        if( topchm._newkvs == null ) { // No table-copy-in-progress\n          // The \"linearization point\" for the iteration.  Every key in this\n          // table will be visited, but keys added later might be skipped or\n          // even be added to a following table (also not iterated over).\n          _sskvs = topkvs;\n          break;\n        }\n        // Table copy in-progress - so we cannot get a clean iteration.  We\n        // must help finish the table copy before we can start iterating.\n        topchm.help_copy_impl(NonBlockingHashMap.this,topkvs,true);\n      }\n      // Warm-up the iterator\n      next();\n    }\n    int length() { return len(_sskvs); }\n    Object key(int idx) { return NonBlockingHashMap.key(_sskvs,idx); }\n    private int _idx;              // Varies from 0-keys.length\n    private Object _nextK, _prevK; // Last 2 keys found\n    private TypeV  _nextV, _prevV; // Last 2 values found\n    public boolean hasNext() { return _nextV != null; }\n    public TypeV next() {\n      // 'next' actually knows what the next value will be - it had to\n      // figure that out last go-around lest 'hasNext' report true and\n      // some other thread deleted the last value.  Instead, 'next'\n      // spends all its effort finding the key that comes after the\n      // 'next' key.\n      if( _idx != 0 && _nextV == null ) throw new NoSuchElementException();\n      _prevK = _nextK;          // This will become the previous key\n      _prevV = _nextV;          // This will become the previous value\n      _nextV = null;            // We have no more next-key\n      // Attempt to set <_nextK,_nextV> to the next K,V pair.\n      // _nextV is the trigger: stop searching when it is != null\n      while( _idx<length() ) {  // Scan array\n        _nextK = key(_idx++); // Get a key that definitely is in the set (for the moment!)\n        if( _nextK != null && // Found something?\n            _nextK != TOMBSTONE &&\n            (_nextV=get(_nextK)) != null )\n          break;                // Got it!  _nextK is a valid Key\n      }                         // Else keep scanning\n      return _prevV;            // Return current value.\n    }\n\n    public void removeKey() {\n      if( _prevV == null ) throw new IllegalStateException();\n      NonBlockingHashMap.this.putIfMatch(_prevK, TOMBSTONE, NO_MATCH_OLD);\n      _prevV = null;\n    }\n\n    @Override\n    public void remove() {\n      // NOTE: it would seem logical that value removal will semantically mean removing the matching value for the\n      // mapping <k,v>, but the JDK always removes by key, even when the value has changed.\n      removeKey();\n    }\n\n    public TypeV nextElement() { return next(); }\n    public boolean hasMoreElements() { return hasNext(); }\n  }\n  public Object[] raw_array() { return new SnapshotV()._sskvs; }\n\n  /** Returns an enumeration of the values in this table.\n   *  @return an enumeration of the values in this table\n   *  @see #values()  */\n  public Enumeration<TypeV> elements() { return new SnapshotV(); }\n\n  // --- values --------------------------------------------------------------\n  /** Returns a {@link Collection} view of the values contained in this map.\n   *  The collection is backed by the map, so changes to the map are reflected\n   *  in the collection, and vice-versa.  The collection supports element\n   *  removal, which removes the corresponding mapping from this map, via the\n   *  <tt>Iterator.remove</tt>, <tt>Collection.remove</tt>,\n   *  <tt>removeAll</tt>, <tt>retainAll</tt>, and <tt>clear</tt> operations.\n   *  It does not support the <tt>add</tt> or <tt>addAll</tt> operations.\n   *\n   *  <p>The view's <tt>iterator</tt> is a \"weakly consistent\" iterator that\n   *  will never throw {@link ConcurrentModificationException}, and guarantees\n   *  to traverse elements as they existed upon construction of the iterator,\n   *  and may (but is not guaranteed to) reflect any modifications subsequent\n   *  to construction. */\n  @Override\n  public Collection<TypeV> values() {\n    return new AbstractCollection<TypeV>() {\n      @Override public void    clear   (          ) {        NonBlockingHashMap.this.clear        ( ); }\n      @Override public int     size    (          ) { return NonBlockingHashMap.this.size         ( ); }\n      @Override public boolean contains( Object v ) { return NonBlockingHashMap.this.containsValue(v); }\n      @Override public Iterator<TypeV> iterator()   { return new SnapshotV(); }\n    };\n  }\n\n  // --- keySet --------------------------------------------------------------\n  private class SnapshotK implements Iterator<TypeK>, Enumeration<TypeK> {\n    final SnapshotV _ss;\n    public SnapshotK() { _ss = new SnapshotV(); }\n    public void remove() { _ss.removeKey(); }\n    public TypeK next() { _ss.next(); return (TypeK)_ss._prevK; }\n    public boolean hasNext() { return _ss.hasNext(); }\n    public TypeK nextElement() { return next(); }\n    public boolean hasMoreElements() { return hasNext(); }\n  }\n\n  /** Returns an enumeration of the keys in this table.\n   *  @return an enumeration of the keys in this table\n   *  @see #keySet()  */\n  public Enumeration<TypeK> keys() { return new SnapshotK(); }\n\n  /** Returns a {@link Set} view of the keys contained in this map.  The set\n   *  is backed by the map, so changes to the map are reflected in the set,\n   *  and vice-versa.  The set supports element removal, which removes the\n   *  corresponding mapping from this map, via the <tt>Iterator.remove</tt>,\n   *  <tt>Set.remove</tt>, <tt>removeAll</tt>, <tt>retainAll</tt>, and\n   *  <tt>clear</tt> operations.  It does not support the <tt>add</tt> or\n   *  <tt>addAll</tt> operations.\n   *\n   *  <p>The view's <tt>iterator</tt> is a \"weakly consistent\" iterator that\n   *  will never throw {@link ConcurrentModificationException}, and guarantees\n   *  to traverse elements as they existed upon construction of the iterator,\n   *  and may (but is not guaranteed to) reflect any modifications subsequent\n   *  to construction.  */\n  @Override\n  public Set<TypeK> keySet() {\n    return new AbstractSet<TypeK> () {\n      @Override public void    clear   (          ) {        NonBlockingHashMap.this.clear   ( ); }\n      @Override public int     size    (          ) { return NonBlockingHashMap.this.size    ( ); }\n      @Override public boolean contains( Object k ) { return NonBlockingHashMap.this.containsKey(k); }\n      @Override public boolean remove  ( Object k ) { return NonBlockingHashMap.this.remove  (k) != null; }\n      @Override public Iterator<TypeK> iterator()   { return new SnapshotK(); }\n      // This is an efficient implementation of toArray instead of the standard\n      // one.  In particular it uses a smart iteration over the NBHM.\n      @Override public <T> T[] toArray(T[] a) {\n        Object[] kvs = raw_array();\n        // Estimate size of array; be prepared to see more or fewer elements\n        int sz = size();\n        T[] r = a.length >= sz ? a :\n          (T[])java.lang.reflect.Array.newInstance(a.getClass().getComponentType(), sz);\n        // Fast efficient element walk.\n        int j=0;\n        for( int i=0; i<len(kvs); i++ ) {\n          Object K = key(kvs,i);\n          Object V = Prime.unbox(val(kvs,i));\n          if( K != null && K != TOMBSTONE && V != null && V != TOMBSTONE ) {\n            if( j >= r.length ) {\n              int sz2 = (int)Math.min(Integer.MAX_VALUE-8,((long)j)<<1);\n              if( sz2<=r.length ) throw new OutOfMemoryError(\"Required array size too large\");\n              r = Arrays.copyOf(r,sz2);\n            }\n            r[j++] = (T)K;\n          }\n        }\n        if( j <= a.length ) {   // Fit in the original array?\n          if( a!=r ) System.arraycopy(r,0,a,0,j);\n          if( j<a.length ) r[j++]=null; // One final null not in the spec but in the default impl\n          return a;             // Return the original\n        }\n        return Arrays.copyOf(r,j);\n      }\n    };\n  }\n\n\n  // --- entrySet ------------------------------------------------------------\n  // Warning: Each call to 'next' in this iterator constructs a new NBHMEntry.\n  private class NBHMEntry extends AbstractEntry<TypeK,TypeV> {\n    NBHMEntry( final TypeK k, final TypeV v ) { super(k,v); }\n    public TypeV setValue(final TypeV val) {\n      if( val == null ) throw new NullPointerException();\n      _val = val;\n      return put(_key, val);\n    }\n  }\n\n  private class SnapshotE implements Iterator<Map.Entry<TypeK,TypeV>> {\n    final SnapshotV _ss;\n    public SnapshotE() { _ss = new SnapshotV(); }\n    public void remove() {\n      // NOTE: it would seem logical that entry removal will semantically mean removing the matching pair <k,v>, but\n      // the JDK always removes by key, even when the value has changed.\n      _ss.removeKey();\n    }\n    public Map.Entry<TypeK,TypeV> next() { _ss.next(); return new NBHMEntry((TypeK)_ss._prevK,_ss._prevV); }\n    public boolean hasNext() { return _ss.hasNext(); }\n  }\n\n  /** Returns a {@link Set} view of the mappings contained in this map.  The\n   *  set is backed by the map, so changes to the map are reflected in the\n   *  set, and vice-versa.  The set supports element removal, which removes\n   *  the corresponding mapping from the map, via the\n   *  <tt>Iterator.remove</tt>, <tt>Set.remove</tt>, <tt>removeAll</tt>,\n   *  <tt>retainAll</tt>, and <tt>clear</tt> operations.  It does not support\n   *  the <tt>add</tt> or <tt>addAll</tt> operations.\n   *\n   *  <p>The view's <tt>iterator</tt> is a \"weakly consistent\" iterator\n   *  that will never throw {@link ConcurrentModificationException},\n   *  and guarantees to traverse elements as they existed upon\n   *  construction of the iterator, and may (but is not guaranteed to)\n   *  reflect any modifications subsequent to construction.\n   *\n   *  <p><strong>Warning:</strong> the iterator associated with this Set\n   *  requires the creation of {@link java.util.Map.Entry} objects with each\n   *  iteration.  The {@link NonBlockingHashMap} does not normally create or\n   *  using {@link java.util.Map.Entry} objects so they will be created soley\n   *  to support this iteration.  Iterating using {@link Map#keySet} or {@link\n   *  Map#values} will be more efficient.\n   */\n  @Override\n  public Set<Map.Entry<TypeK,TypeV>> entrySet() {\n    return new AbstractSet<Map.Entry<TypeK,TypeV>>() {\n      @Override public void    clear   (          ) {        NonBlockingHashMap.this.clear( ); }\n      @Override public int     size    (          ) { return NonBlockingHashMap.this.size ( ); }\n      @Override public boolean remove( final Object o ) {\n        if( !(o instanceof Map.Entry)) return false;\n        final Map.Entry<?,?> e = (Map.Entry<?,?>)o;\n        return NonBlockingHashMap.this.remove(e.getKey(), e.getValue());\n      }\n      @Override public boolean contains(final Object o) {\n        if( !(o instanceof Map.Entry)) return false;\n        final Map.Entry<?,?> e = (Map.Entry<?,?>)o;\n        TypeV v = get(e.getKey());\n        return v != null && v.equals(e.getValue());\n      }\n      @Override public Iterator<Map.Entry<TypeK,TypeV>> iterator() { return new SnapshotE(); }\n    };\n  }\n\n  // --- writeObject -------------------------------------------------------\n  // Write a NBHM to a stream\n  private void writeObject(java.io.ObjectOutputStream s) throws IOException  {\n    s.defaultWriteObject();     // Nothing to write\n    for( Object K : keySet() ) {\n      final Object V = get(K);  // Do an official 'get'\n      s.writeObject(K);         // Write the <TypeK,TypeV> pair\n      s.writeObject(V);\n    }\n    s.writeObject(null);        // Sentinel to indicate end-of-data\n    s.writeObject(null);\n  }\n\n  // --- readObject --------------------------------------------------------\n  // Read a NBHM from a stream\n  private void readObject(java.io.ObjectInputStream s) throws IOException, ClassNotFoundException {\n    s.defaultReadObject();      // Read nothing\n    initialize(MIN_SIZE);\n    for(;;) {\n      final TypeK K = (TypeK) s.readObject();\n      final TypeV V = (TypeV) s.readObject();\n      if( K == null ) break;\n      put(K,V);                 // Insert with an offical put\n    }\n  }\n\n} // End NonBlockingHashMap class\n",
        "simple_context": "package org.jctools.maps;\n\nimport java.io.IOException;\n\nimport java.io.Serializable;\n\nimport java.util;\n\nimport java.util.concurrent.ConcurrentMap;\n\nimport java.util.concurrent.atomic.AtomicLongFieldUpdater;\n\nimport java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n\nimport org.jctools.util.RangeUtil;\n\nimport static org.jctools.util.UnsafeAccess.UNSAFE;\n\nimport static org.jctools.util.UnsafeAccess.fieldOffset;\n\npublic class NonBlockingHashMap extends AbstractMap<TypeK, TypeV> implements ConcurrentMap<TypeK, TypeV>, Cloneable, Serializable {\n    static final private long serialVersionUID;\n    static final private int REPROBE_LIMIT;\n    static final private int _Obase;\n    static final private int _Oscale;\n    static final private int _Olog;\n    static private long rawIndex(Object ary, int idx);\n    static final private long _kvs_offset;\n    final private boolean CAS_kvs(Object oldkvs, Object newkvs);\n    static final private class Prime {\n        final Object _V;\n        Prime(Object V);\n        static Object unbox(Object V);\n    }\n    static final private int hash(Object key);\n    transient private Object _kvs;\n    static final private CHM chm(Object kvs);\n    static final private int[] hashes(Object kvs);\n    static final private int len(Object kvs);\n    transient private long _last_resize_milli;\n    static final private int MIN_SIZE_LOG;\n    static final private int MIN_SIZE;\n    static final private Object NO_MATCH_OLD;\n    static final private Object MATCH_ANY;\n    static public final Object TOMBSTONE;\n    static final private Prime TOMBPRIME;\n    static final private Object key(Object kvs, int idx);\n    static final private Object val(Object kvs, int idx);\n    static final private boolean CAS_key(Object kvs, int idx, Object old, Object key);\n    static final private boolean CAS_val(Object kvs, int idx, Object old, Object val);\n    final public  print();\n    final private  print(Object kvs);\n    final private  print2(Object kvs);\n    transient private ConcurrentAutoTable _reprobes;\n    public long reprobes();\n    static private int reprobe_limit(int len);\n    public NonBlockingHashMap();\n    public NonBlockingHashMap(int initial_sz);\n    final private  initialize(int initial_sz);\n    protected final  initialize();\n    public int size();\n    public boolean isEmpty();\n    public boolean containsKey(Object key);\n    public boolean contains(Object val);\n    public TypeV put(TypeK key, TypeV val);\n    public TypeV putIfAbsent(TypeK key, TypeV val);\n    public TypeV remove(Object key);\n    public boolean remove(Object key, Object val);\n    public TypeV replace(TypeK key, TypeV val);\n    public boolean replace(TypeK key, TypeV oldValue, TypeV newValue);\n    static private boolean objectsEquals(Object a, Object b);\n    final public TypeV putIfMatchAllowNull(Object key, Object newVal, Object oldVal);\n    final public TypeV putIfMatch(Object key, Object newVal, Object oldVal);\n    public  putAll(Map<TypeK, TypeV> m);\n    public  clear();\n    public boolean containsValue(Object val);\n    protected  rehash();\n    public Object clone();\n    public String toString();\n    static private boolean keyeq(Object K, Object key, int[] hashes, int hash, int fullhash);\n    public TypeV get(Object key);\n    static final private Object get_impl(NonBlockingHashMap topmap, Object kvs, Object key);\n    public TypeK getk(TypeK key);\n    static final private Object getk_impl(NonBlockingHashMap topmap, Object kvs, Object key);\n    volatile static int DUMMY_VOLATILE;\n    static final private Object putIfMatch0(NonBlockingHashMap topmap, Object kvs, Object key, Object putval, Object expVal);\n    final private Object help_copy(Object helper);\n    static final private class CHM {\n        final private ConcurrentAutoTable _size;\n        public int size();\n        final private ConcurrentAutoTable _slots;\n        public int slots();\n        volatile Object _newkvs;\n        static final private AtomicReferenceFieldUpdater<CHM, Object> _newkvsUpdater;\n        boolean CAS_newkvs(Object newkvs);\n        volatile long _resizers;\n        static final private AtomicLongFieldUpdater<CHM> _resizerUpdater;\n        CHM(ConcurrentAutoTable size);\n        final private boolean tableFull(int reprobe_cnt, int len);\n        final private Object resize(NonBlockingHashMap topmap, Object kvs);\n        volatile long _copyIdx;\n        static final private AtomicLongFieldUpdater<CHM> _copyIdxUpdater;\n        volatile long _copyDone;\n        static final private AtomicLongFieldUpdater<CHM> _copyDoneUpdater;\n        final private  help_copy_impl(NonBlockingHashMap topmap, Object oldkvs, boolean copy_all);\n        final private Object copy_slot_and_check(NonBlockingHashMap topmap, Object oldkvs, int idx, Object should_help);\n        final private  copy_check_and_promote(NonBlockingHashMap topmap, Object oldkvs, int workdone);\n        private boolean copy_slot(NonBlockingHashMap topmap, int idx, Object oldkvs, Object newkvs);\n    }\n    private class SnapshotV implements Iterator<TypeV>, Enumeration<TypeV> {\n        final Object _sskvs;\n        public SnapshotV();\n        int length();\n        Object key(int idx);\n        private int _idx;\n        private Object _nextK, _prevK;\n        private TypeV _nextV, _prevV;\n        public boolean hasNext();\n        public TypeV next();\n        public  removeKey();\n        public  remove();\n        public TypeV nextElement();\n        public boolean hasMoreElements();\n    }\n    public Object raw_array();\n    public Enumeration<TypeV> elements();\n    public Collection<TypeV> values();\n    private class SnapshotK implements Iterator<TypeK>, Enumeration<TypeK> {\n        final SnapshotV _ss;\n        public SnapshotK();\n        public  remove();\n        public TypeK next();\n        public boolean hasNext();\n        public TypeK nextElement();\n        public boolean hasMoreElements();\n    }\n    public Enumeration<TypeK> keys();\n    public Set<TypeK> keySet();\n    private class NBHMEntry extends AbstractEntry<TypeK, TypeV> {\n        NBHMEntry(TypeK k, TypeV v);\n        public TypeV setValue(TypeV val);\n    }\n    private class SnapshotE implements Iterator<Map> {\n        final SnapshotV _ss;\n        public SnapshotE();\n        public  remove();\n        public Map next();\n        public boolean hasNext();\n    }\n    public Set<Map> entrySet();\n    private  writeObject(java s)throws IOException;\n    private  readObject(java s)throws IOException, ClassNotFoundException;\n}\n\n"
    },
    {
        "project_name": "JCTools",
        "file_name": "NonBlockingSetInt.java",
        "relative_path": "JCTools/jctools-core/src/main/java/org/jctools/maps/NonBlockingSetInt.java",
        "execute_path": "JCTools",
        "package": "org.jctools.maps",
        "docstring": null,
        "source_code": "// Help any top-level NBSI to copy until completed.\n// Always return the _new version of *this* NBSI, in case we're nested.\nprivate NBSI help_copy() {\n  // Pick some words to help with - but only help copy the top-level NBSI.\n  // Nested NBSI waits until the top is done before we start helping.\n  NBSI top_nbsi = _non_blocking_set_int._nbsi;\n  final int HELP = 8;       // Tuning number: how much copy pain are we willing to inflict?\n  // We \"help\" by forcing individual bit indices to copy.  However, bits\n  // come in lumps of 64 per word, so we just advance the bit counter by 64's.\n  int idx = top_nbsi._copyIdx.getAndAdd(64*HELP);\n  for( int i=0; i<HELP; i++ ) {\n    int j = idx+i*64;\n    j %= (top_nbsi._bits.length<<6); // Limit, wrap to array size; means we retry indices\n    top_nbsi.help_copy_impl(j   );\n    top_nbsi.help_copy_impl(j+63); // Also force the nested-by-64 bit\n  }\n\n  // Top level guy ready to promote?\n  // Note: WE may not be the top-level guy!\n  if( top_nbsi._copyDone.get() == top_nbsi._sum_bits_length )\n    // One shot CAS to promote - it may fail since we are racing; others\n    // may promote as well\n    if( _non_blocking_set_int.CAS_nbsi( top_nbsi, top_nbsi._new ) ) {\n      //System.out.println(\"Promote at top level to size \"+(_non_blocking_set_int._nbsi._bits.length<<6));\n    }\n\n  // Return the new bitvector for 'fluid' programming style\n  return _new;\n}\n",
        "class_name": "NonBlockingSetInt",
        "method_name": "help_copy",
        "argument_name": [],
        "full_context": "/*\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.jctools.maps;\nimport static org.jctools.util.UnsafeAccess.UNSAFE;\nimport static org.jctools.util.UnsafeAccess.fieldOffset;\n\nimport java.io.IOException;\nimport java.io.Serializable;\nimport java.lang.reflect.Field;\nimport java.util.AbstractSet;\nimport java.util.Iterator;\nimport java.util.NoSuchElementException;\nimport java.util.concurrent.atomic.AtomicInteger;\nimport org.jctools.util.RangeUtil;\n\n/**\n * A multi-threaded bit-vector set, implemented as an array of primitive\n * {@code longs}.  All operations are non-blocking and multi-threaded safe.\n * {@link #contains(int)} calls are roughly the same speed as a {load, mask}\n * sequence.  {@link #add(int)} and {@link #remove(int)} calls are a tad more\n * expensive than a {load, mask, store} sequence because they must use a CAS.\n * The bit-vector is auto-sizing.\n *\n * <p><em>General note of caution:</em> The Set API allows the use of {@link Integer}\n * with silent autoboxing - which can be very expensive if many calls are\n * being made.  Since autoboxing is silent you may not be aware that this is\n * going on.  The built-in API takes lower-case {@code ints} and is much more\n * efficient.\n *\n * <p>Space: space is used in proportion to the largest element, as opposed to\n * the number of elements (as is the case with hash-table based Set\n * implementations).  Space is approximately (largest_element/8 + 64) bytes.\n *\n * The implementation is a simple bit-vector using CAS for update.\n *\n * @since 1.5\n * @author Cliff Click\n */\npublic class NonBlockingSetInt extends AbstractSet<Integer> implements Serializable {\n  private static final long serialVersionUID = 1234123412341234123L;\n\n  // --- Bits to allow atomic update of the NBSI\n  private static final long _nbsi_offset = fieldOffset(NonBlockingSetInt.class, \"_nbsi\");\n\n  private final boolean CAS_nbsi( NBSI old, NBSI nnn ) {\n    return UNSAFE.compareAndSwapObject(this, _nbsi_offset, old, nnn );\n  }\n\n  // The actual Set of Joy, which changes during a resize event.  The\n  // Only Field for this class, so I can atomically change the entire\n  // set implementation with a single CAS.\n  private transient NBSI _nbsi;\n\n  /** Create a new empty bit-vector */\n  public NonBlockingSetInt( ) {\n    _nbsi = new NBSI(63, new ConcurrentAutoTable(), this); // The initial 1-word set\n  }\n\n  /**\n   * Add {@code i} to the set.  Uppercase {@link Integer} version of add,\n   * requires auto-unboxing.  When possible use the {@code int} version of\n   * {@link #add(int)} for efficiency.\n   * @throws IllegalArgumentException if i is negative.\n   * @return <tt>true</tt> if i was added to the set.\n   */\n  public boolean add ( final Integer i ) {\n    return add(i.intValue());\n  }\n  /**\n   * Test if {@code o} is in the set.  This is the uppercase {@link Integer}\n   * version of contains, requires a type-check and auto-unboxing.  When\n   * possible use the {@code int} version of {@link #contains(int)} for\n   * efficiency.\n   * @return <tt>true</tt> if i was in the set.\n   */\n  public boolean contains( final Object  o ) {\n    return o instanceof Integer && contains(((Integer) o).intValue());\n  }\n  /**\n   * Remove {@code o} from the set.  This is the uppercase {@link Integer}\n   * version of remove, requires a type-check and auto-unboxing.  When\n   * possible use the {@code int} version of {@link #remove(int)} for\n   * efficiency.\n   * @return <tt>true</tt> if i was removed to the set.\n   */\n  public boolean remove( final Object  o ) {\n    return o instanceof Integer && remove(((Integer) o).intValue());\n  }\n\n  /**\n   * Add {@code i} to the set.  This is the lower-case '{@code int}' version\n   * of {@link #add} - no autoboxing.  Negative values throw\n   * IllegalArgumentException.\n   * @throws IllegalArgumentException if i is negative.\n   * @return <tt>true</tt> if i was added to the set.\n   */\n  public boolean add( final int i ) {\n    RangeUtil.checkPositiveOrZero(i, \"i\");\n    return _nbsi.add(i);\n  }\n  /**\n   * Test if {@code i} is in the set.  This is the lower-case '{@code int}'\n   * version of {@link #contains} - no autoboxing.\n   * @return <tt>true</tt> if i was int the set.\n   */\n  public boolean contains( final int i ) { return i >= 0 && _nbsi.contains(i); }\n  /**\n   * Remove {@code i} from the set.  This is the fast lower-case '{@code int}'\n   * version of {@link #remove} - no autoboxing.\n   * @return <tt>true</tt> if i was added to the set.\n   */\n  public boolean remove  ( final int i ) { return i >= 0 && _nbsi.remove(i); }\n\n  /**\n   * Current count of elements in the set.  Due to concurrent racing updates,\n   * the size is only ever approximate.  Updates due to the calling thread are\n   * immediately visible to calling thread.\n   * @return count of elements.\n   */\n  public int     size    (             ) { return _nbsi.size( );                   }\n  /** Approx largest element in set; at least as big (but max might be smaller).  */\n  public int length() { return _nbsi._bits.length<<6; }\n  /** Empty the bitvector. */\n  public void    clear   (             ) {\n    NBSI cleared = new NBSI(63, new ConcurrentAutoTable(), this); // An empty initial NBSI\n    while( !CAS_nbsi( _nbsi, cleared ) ) // Spin until clear works\n      ;\n  }\n\n  /** Verbose printout of internal structure for debugging. */\n  public void print() { _nbsi.print(0); }\n\n  /**\n   * Standard Java {@link Iterator}.  Not very efficient because it\n   * auto-boxes the returned values.\n   */\n  public Iterator<Integer> iterator( ) { return new iter(); }\n\n  private class iter implements Iterator<Integer> {\n    NBSI _nbsi2;\n    int _idx  = -1;\n    int _prev = -1;\n    iter() { _nbsi2 = _nbsi; advance(); }\n    public boolean hasNext() { return _idx != -2; }\n    private void advance() {\n      while( true ) {\n        _idx++;                 // Next index\n        while( (_idx>>6) >= _nbsi2._bits.length ) { // Index out of range?\n          if( _nbsi2._new == null ) { // New table?\n            _idx = -2;          // No, so must be all done\n            return;             //\n          }\n          _nbsi2 = _nbsi2._new; // Carry on, in the new table\n        }\n        if( _nbsi2.contains(_idx) ) return;\n      }\n    }\n    public Integer next() {\n      if( _idx == -1 ) throw new NoSuchElementException();\n      _prev = _idx;\n      advance();\n      return _prev;\n    }\n    public void remove() {\n      if( _prev == -1 ) throw new IllegalStateException();\n      _nbsi2.remove(_prev);\n      _prev = -1;\n    }\n  }\n\n  // --- writeObject -------------------------------------------------------\n  // Write a NBSI to a stream\n  private void writeObject(java.io.ObjectOutputStream s) throws IOException  {\n    s.defaultWriteObject();     // Nothing to write\n    final NBSI nbsi = _nbsi;    // The One Field is transient\n    final int len = _nbsi._bits.length<<6;\n    s.writeInt(len);            // Write max element\n    for( int i=0; i<len; i++ )\n      s.writeBoolean( _nbsi.contains(i) );\n  }\n\n  // --- readObject --------------------------------------------------------\n  // Read a NBSI from a stream\n  private void readObject(java.io.ObjectInputStream s) throws IOException, ClassNotFoundException  {\n    s.defaultReadObject();      // Read nothing\n    final int len = s.readInt(); // Read max element\n    _nbsi = new NBSI(len, new ConcurrentAutoTable(), this);\n    for( int i=0; i<len; i++ )  // Read all bits\n      if( s.readBoolean() )\n        _nbsi.add(i);\n  }\n\n  // --- NBSI ----------------------------------------------------------------\n  private static final class NBSI {\n    // Back pointer to the parent wrapper; sorta like make the class non-static\n    private transient final NonBlockingSetInt _non_blocking_set_int;\n\n    // Used to count elements: a high-performance counter.\n    private transient final ConcurrentAutoTable _size;\n\n    // The Bits\n    private final long _bits[];\n    // --- Bits to allow Unsafe access to arrays\n    private static final int _Lbase  = UNSAFE.arrayBaseOffset(long[].class);\n    private static final int _Lscale = UNSAFE.arrayIndexScale(long[].class);\n    private static long rawIndex(final long[] ary, final int idx) {\n      assert idx >= 0 && idx < ary.length;\n      return _Lbase + (idx * (long)_Lscale);\n    }\n    private final boolean CAS( int idx, long old, long nnn ) {\n      return UNSAFE.compareAndSwapLong( _bits, rawIndex(_bits, idx), old, nnn );\n    }\n\n    // --- Resize\n    // The New Table, only set once to non-zero during a resize.\n    // Must be atomically set.\n    private NBSI _new;\n    private static final long _new_offset = fieldOffset(NBSI.class, \"_new\");\n\n    private final boolean CAS_new( NBSI nnn ) {\n      return UNSAFE.compareAndSwapObject(this, _new_offset, null, nnn );\n    }\n\n    private transient final AtomicInteger _copyIdx;   // Used to count bits started copying\n    private transient final AtomicInteger _copyDone;  // Used to count words copied in a resize operation\n    private transient final int _sum_bits_length; // Sum of all nested _bits.lengths\n\n    private static final long mask( int i ) { return 1L<<(i&63); }\n\n    // I need 1 free bit out of 64 to allow for resize.  I do this by stealing\n    // the high order bit - but then I need to do something with adding element\n    // number 63 (and friends).  I could use a mod63 function but it's more\n    // efficient to handle the mod-64 case as an exception.\n    //\n    // Every 64th bit is put in it's own recursive bitvector.  If the low 6 bits\n    // are all set, we shift them off and recursively operate on the _nbsi64 set.\n    private final NBSI _nbsi64;\n\n    private NBSI( int max_elem, ConcurrentAutoTable ctr, NonBlockingSetInt nonb ) {\n      super();\n      _non_blocking_set_int = nonb;\n      _size = ctr;\n      _copyIdx  = ctr == null ? null : new AtomicInteger();\n      _copyDone = ctr == null ? null : new AtomicInteger();\n      // The main array of bits\n      _bits = new long[(int)(((long)max_elem+63)>>>6)];\n      // Every 64th bit is moved off to it's own subarray, so that the\n      // sign-bit is free for other purposes\n      _nbsi64 = ((max_elem+1)>>>6) == 0 ? null : new NBSI((max_elem+1)>>>6, null, null);\n      _sum_bits_length = _bits.length + (_nbsi64==null ? 0 : _nbsi64._sum_bits_length);\n    }\n\n    // Lower-case 'int' versions - no autoboxing, very fast.\n    // 'i' is known positive.\n    public boolean add( final int i ) {\n      // Check for out-of-range for the current size bit vector.\n      // If so we need to grow the bit vector.\n      if( (i>>6) >= _bits.length )\n        return install_larger_new_bits(i). // Install larger pile-o-bits (duh)\n          help_copy().add(i);              // Finally, add to the new table\n\n      // Handle every 64th bit via using a nested array\n      NBSI nbsi = this;         // The bit array being added into\n      int j = i;                // The bit index being added\n      while( (j&63) == 63 ) {   // Bit 64? (low 6 bits are all set)\n        nbsi = nbsi._nbsi64;    // Recurse\n        j = j>>6;               // Strip off low 6 bits (all set)\n      }\n\n      final long mask = mask(j);\n      long old;\n      do {\n        old = nbsi._bits[j>>6]; // Read old bits\n        if( old < 0 )           // Not mutable?\n          // Not mutable: finish copy of word, and retry on copied word\n          return help_copy_impl(i).help_copy().add(i);\n        if( (old & mask) != 0 ) return false; // Bit is already set?\n      } while( !nbsi.CAS( j>>6, old, old | mask ) );\n      _size.add(1);\n      return true;\n    }\n\n    public boolean remove( final int i ) {\n      if( (i>>6) >= _bits.length ) // Out of bounds?  Not in this array!\n        return _new != null && help_copy().remove(i);\n\n      // Handle every 64th bit via using a nested array\n      NBSI nbsi = this;         // The bit array being added into\n      int j = i;                // The bit index being added\n      while( (j&63) == 63 ) {   // Bit 64? (low 6 bits are all set)\n        nbsi = nbsi._nbsi64;    // Recurse\n        j = j>>6;               // Strip off low 6 bits (all set)\n      }\n\n      final long mask = mask(j);\n      long old;\n      do {\n        old = nbsi._bits[j>>6]; // Read old bits\n        if( old < 0 )           // Not mutable?\n          // Not mutable: finish copy of word, and retry on copied word\n          return help_copy_impl(i).help_copy().remove(i);\n        if( (old & mask) == 0 ) return false; // Bit is already clear?\n      } while( !nbsi.CAS( j>>6, old, old & ~mask ) );\n      _size.add(-1);\n      return true;\n    }\n\n    public boolean contains( final int i ) {\n      if( (i>>6) >= _bits.length ) // Out of bounds?  Not in this array!\n        return _new != null && help_copy().contains(i);\n\n      // Handle every 64th bit via using a nested array\n      NBSI nbsi = this;         // The bit array being added into\n      int j = i;                // The bit index being added\n      while( (j&63) == 63 ) {   // Bit 64? (low 6 bits are all set)\n        nbsi = nbsi._nbsi64;    // Recurse\n        j = j>>6;               // Strip off low 6 bits (all set)\n      }\n\n      final long mask = mask(j);\n      long old = nbsi._bits[j>>6]; // Read old bits\n      if( old < 0 )             // Not mutable?\n        // Not mutable: finish copy of word, and retry on copied word\n        return help_copy_impl(i).help_copy().contains(i);\n      // Yes mutable: test & return bit\n      return (old & mask) != 0;\n    }\n\n    public int size() { return (int)_size.get(); }\n\n    // Must grow the current array to hold an element of size i\n    private NBSI install_larger_new_bits( final int i ) {\n      if( _new == null ) {\n        // Grow by powers of 2, to avoid minor grow-by-1's.\n        // Note: must grow by exact powers-of-2 or the by-64-bit trick doesn't work right\n        int sz = (_bits.length<<6)<<1;\n        // CAS to install a new larger size.  Did it work?  Did it fail?  We\n        // don't know and don't care.  Only One can be installed, so if\n        // another thread installed a too-small size, we can't help it - we\n        // must simply install our new larger size as a nested-resize table.\n        CAS_new(new NBSI(sz, _size, _non_blocking_set_int));\n      }\n      // Return self for 'fluid' programming style\n      return this;\n    }\n\n    // Help any top-level NBSI to copy until completed.\n    // Always return the _new version of *this* NBSI, in case we're nested.\n    private NBSI help_copy() {\n      // Pick some words to help with - but only help copy the top-level NBSI.\n      // Nested NBSI waits until the top is done before we start helping.\n      NBSI top_nbsi = _non_blocking_set_int._nbsi;\n      final int HELP = 8;       // Tuning number: how much copy pain are we willing to inflict?\n      // We \"help\" by forcing individual bit indices to copy.  However, bits\n      // come in lumps of 64 per word, so we just advance the bit counter by 64's.\n      int idx = top_nbsi._copyIdx.getAndAdd(64*HELP);\n      for( int i=0; i<HELP; i++ ) {\n        int j = idx+i*64;\n        j %= (top_nbsi._bits.length<<6); // Limit, wrap to array size; means we retry indices\n        top_nbsi.help_copy_impl(j   );\n        top_nbsi.help_copy_impl(j+63); // Also force the nested-by-64 bit\n      }\n\n      // Top level guy ready to promote?\n      // Note: WE may not be the top-level guy!\n      if( top_nbsi._copyDone.get() == top_nbsi._sum_bits_length )\n        // One shot CAS to promote - it may fail since we are racing; others\n        // may promote as well\n        if( _non_blocking_set_int.CAS_nbsi( top_nbsi, top_nbsi._new ) ) {\n          //System.out.println(\"Promote at top level to size \"+(_non_blocking_set_int._nbsi._bits.length<<6));\n        }\n\n      // Return the new bitvector for 'fluid' programming style\n      return _new;\n    }\n\n    // Help copy this one word.  State Machine.\n    // (1) If not \"made immutable\" in the old array, set the sign bit to make\n    //     it immutable.\n    // (2) If non-zero in old array & zero in new, CAS new from 0 to copy-of-old\n    // (3) If non-zero in old array & non-zero in new, CAS old to zero\n    // (4) Zero in old, new is valid\n    // At this point, old should be immutable-zero & new has a copy of bits\n    private NBSI help_copy_impl( int i ) {\n      // Handle every 64th bit via using a nested array\n      NBSI old = this;          // The bit array being copied from\n      NBSI nnn = _new;          // The bit array being copied to\n      if( nnn == null ) return this; // Promoted already\n      int j = i;                // The bit index being added\n      while( (j&63) == 63 ) {   // Bit 64? (low 6 bits are all set)\n        old = old._nbsi64;      // Recurse\n        nnn = nnn._nbsi64;      // Recurse\n        j = j>>6;               // Strip off low 6 bits (all set)\n      }\n\n      // Transit from state 1: word is not immutable yet\n      // Immutable is in bit 63, the sign bit.\n      long bits = old._bits[j>>6];\n      while( bits >= 0 ) {      // Still in state (1)?\n        long oldbits = bits;\n        bits |= mask(63);       // Target state of bits: sign-bit means immutable\n        if( old.CAS( j>>6, oldbits, bits ) ) {\n          if( oldbits == 0 ) _copyDone.addAndGet(1);\n          break;                // Success - old array word is now immutable\n        }\n        bits = old._bits[j>>6]; // Retry if CAS failed\n      }\n\n      // Transit from state 2: non-zero in old and zero in new\n      if( bits != mask(63) ) {  // Non-zero in old?\n        long new_bits = nnn._bits[j>>6];\n        if( new_bits == 0 ) {   // New array is still zero\n          new_bits = bits & ~mask(63); // Desired new value: a mutable copy of bits\n          // One-shot CAS attempt, no loop, from 0 to non-zero.\n          // If it fails, somebody else did the copy for us\n          if( !nnn.CAS( j>>6, 0, new_bits ) )\n            new_bits = nnn._bits[j>>6]; // Since it failed, get the new value\n          assert new_bits != 0;\n        }\n\n        // Transit from state 3: non-zero in old and non-zero in new\n        // One-shot CAS attempt, no loop, from non-zero to 0 (but immutable)\n        if( old.CAS( j>>6, bits, mask(63) ) )\n          _copyDone.addAndGet(1); // One more word finished copying\n      }\n\n      // Now in state 4: zero (and immutable) in old\n\n      // Return the self bitvector for 'fluid' programming style\n      return this;\n    }\n\n    private void print( int d, String msg ) {\n      for( int i=0; i<d; i++ )\n        System.out.print(\"  \");\n      System.out.println(msg);\n    }\n\n    private void print(int d) {\n      StringBuilder buf = new StringBuilder();\n      buf.append(\"NBSI - _bits.len=\");\n      NBSI x = this;\n      while( x != null ) {\n        buf.append(\" \"+x._bits.length);\n        x = x._nbsi64;\n      }\n      print(d,buf.toString());\n\n      x = this;\n      while( x != null ) {\n        for( int i=0; i<x._bits.length; i++ )\n          System.out.print(Long.toHexString(x._bits[i])+\" \");\n        x = x._nbsi64;\n        System.out.println();\n      }\n\n      if( _copyIdx.get() != 0 || _copyDone.get() != 0 )\n        print(d,\"_copyIdx=\"+_copyIdx.get()+\" _copyDone=\"+_copyDone.get()+\" _words_to_cpy=\"+_sum_bits_length);\n      if( _new != null ) {\n        print(d,\"__has_new - \");\n        _new.print(d+1);\n      }\n    }\n  }\n}\n",
        "simple_context": "package org.jctools.maps;\n\nimport static org.jctools.util.UnsafeAccess.UNSAFE;\n\nimport static org.jctools.util.UnsafeAccess.fieldOffset;\n\nimport java.io.IOException;\n\nimport java.io.Serializable;\n\nimport java.lang.reflect.Field;\n\nimport java.util.AbstractSet;\n\nimport java.util.Iterator;\n\nimport java.util.NoSuchElementException;\n\nimport java.util.concurrent.atomic.AtomicInteger;\n\nimport org.jctools.util.RangeUtil;\n\npublic class NonBlockingSetInt extends AbstractSet<Integer> implements Serializable {\n    static final private long serialVersionUID;\n    static final private long _nbsi_offset;\n    final private boolean CAS_nbsi(NBSI old, NBSI nnn);\n    transient private NBSI _nbsi;\n    public NonBlockingSetInt();\n    public boolean add(Integer i);\n    public boolean contains(Object o);\n    public boolean remove(Object o);\n    public boolean add(int i);\n    public boolean contains(int i);\n    public boolean remove(int i);\n    public int size();\n    public int length();\n    public  clear();\n    public  print();\n    public Iterator<Integer> iterator();\n    private class iter implements Iterator<Integer> {\n        NBSI _nbsi2;\n        int _idx;\n        int _prev;\n        iter();\n        public boolean hasNext();\n        private  advance();\n        public Integer next();\n        public  remove();\n    }\n    private  writeObject(java s)throws IOException;\n    private  readObject(java s)throws IOException, ClassNotFoundException;\n    static final private class NBSI {\n        transient final private NonBlockingSetInt _non_blocking_set_int;\n        transient final private ConcurrentAutoTable _size;\n        final private long _bits;\n        static final private int _Lbase;\n        static final private int _Lscale;\n        static private long rawIndex(long[] ary, int idx);\n        final private boolean CAS(int idx, long old, long nnn);\n        private NBSI _new;\n        static final private long _new_offset;\n        final private boolean CAS_new(NBSI nnn);\n        transient final private AtomicInteger _copyIdx;\n        transient final private AtomicInteger _copyDone;\n        transient final private int _sum_bits_length;\n        static final private long mask(int i);\n        final private NBSI _nbsi64;\n        private NBSI(int max_elem, ConcurrentAutoTable ctr, NonBlockingSetInt nonb);\n        public boolean add(int i);\n        public boolean remove(int i);\n        public boolean contains(int i);\n        public int size();\n        private NBSI install_larger_new_bits(int i);\n        private NBSI help_copy();\n        private NBSI help_copy_impl(int i);\n        private  print(int d, String msg);\n        private  print(int d);\n    }\n}\n\n"
    },
    {
        "project_name": "JCTools",
        "file_name": "NonBlockingSetInt.java",
        "relative_path": "JCTools/jctools-core/src/main/java/org/jctools/maps/NonBlockingSetInt.java",
        "execute_path": "JCTools",
        "package": "org.jctools.maps",
        "docstring": null,
        "source_code": "// Help copy this one word.  State Machine.\n// (1) If not \"made immutable\" in the old array, set the sign bit to make\n//     it immutable.\n// (2) If non-zero in old array & zero in new, CAS new from 0 to copy-of-old\n// (3) If non-zero in old array & non-zero in new, CAS old to zero\n// (4) Zero in old, new is valid\n// At this point, old should be immutable-zero & new has a copy of bits\nprivate NBSI help_copy_impl( int i ) {\n  // Handle every 64th bit via using a nested array\n  NBSI old = this;          // The bit array being copied from\n  NBSI nnn = _new;          // The bit array being copied to\n  if( nnn == null ) return this; // Promoted already\n  int j = i;                // The bit index being added\n  while( (j&63) == 63 ) {   // Bit 64? (low 6 bits are all set)\n    old = old._nbsi64;      // Recurse\n    nnn = nnn._nbsi64;      // Recurse\n    j = j>>6;               // Strip off low 6 bits (all set)\n  }\n\n  // Transit from state 1: word is not immutable yet\n  // Immutable is in bit 63, the sign bit.\n  long bits = old._bits[j>>6];\n  while( bits >= 0 ) {      // Still in state (1)?\n    long oldbits = bits;\n    bits |= mask(63);       // Target state of bits: sign-bit means immutable\n    if( old.CAS( j>>6, oldbits, bits ) ) {\n      if( oldbits == 0 ) _copyDone.addAndGet(1);\n      break;                // Success - old array word is now immutable\n    }\n    bits = old._bits[j>>6]; // Retry if CAS failed\n  }\n\n  // Transit from state 2: non-zero in old and zero in new\n  if( bits != mask(63) ) {  // Non-zero in old?\n    long new_bits = nnn._bits[j>>6];\n    if( new_bits == 0 ) {   // New array is still zero\n      new_bits = bits & ~mask(63); // Desired new value: a mutable copy of bits\n      // One-shot CAS attempt, no loop, from 0 to non-zero.\n      // If it fails, somebody else did the copy for us\n      if( !nnn.CAS( j>>6, 0, new_bits ) )\n        new_bits = nnn._bits[j>>6]; // Since it failed, get the new value\n      assert new_bits != 0;\n    }\n\n    // Transit from state 3: non-zero in old and non-zero in new\n    // One-shot CAS attempt, no loop, from non-zero to 0 (but immutable)\n    if( old.CAS( j>>6, bits, mask(63) ) )\n      _copyDone.addAndGet(1); // One more word finished copying\n  }\n\n  // Now in state 4: zero (and immutable) in old\n\n  // Return the self bitvector for 'fluid' programming style\n  return this;\n}\n",
        "class_name": "NonBlockingSetInt",
        "method_name": "help_copy_impl",
        "argument_name": [
            "int i"
        ],
        "full_context": "/*\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.jctools.maps;\nimport static org.jctools.util.UnsafeAccess.UNSAFE;\nimport static org.jctools.util.UnsafeAccess.fieldOffset;\n\nimport java.io.IOException;\nimport java.io.Serializable;\nimport java.lang.reflect.Field;\nimport java.util.AbstractSet;\nimport java.util.Iterator;\nimport java.util.NoSuchElementException;\nimport java.util.concurrent.atomic.AtomicInteger;\nimport org.jctools.util.RangeUtil;\n\n/**\n * A multi-threaded bit-vector set, implemented as an array of primitive\n * {@code longs}.  All operations are non-blocking and multi-threaded safe.\n * {@link #contains(int)} calls are roughly the same speed as a {load, mask}\n * sequence.  {@link #add(int)} and {@link #remove(int)} calls are a tad more\n * expensive than a {load, mask, store} sequence because they must use a CAS.\n * The bit-vector is auto-sizing.\n *\n * <p><em>General note of caution:</em> The Set API allows the use of {@link Integer}\n * with silent autoboxing - which can be very expensive if many calls are\n * being made.  Since autoboxing is silent you may not be aware that this is\n * going on.  The built-in API takes lower-case {@code ints} and is much more\n * efficient.\n *\n * <p>Space: space is used in proportion to the largest element, as opposed to\n * the number of elements (as is the case with hash-table based Set\n * implementations).  Space is approximately (largest_element/8 + 64) bytes.\n *\n * The implementation is a simple bit-vector using CAS for update.\n *\n * @since 1.5\n * @author Cliff Click\n */\npublic class NonBlockingSetInt extends AbstractSet<Integer> implements Serializable {\n  private static final long serialVersionUID = 1234123412341234123L;\n\n  // --- Bits to allow atomic update of the NBSI\n  private static final long _nbsi_offset = fieldOffset(NonBlockingSetInt.class, \"_nbsi\");\n\n  private final boolean CAS_nbsi( NBSI old, NBSI nnn ) {\n    return UNSAFE.compareAndSwapObject(this, _nbsi_offset, old, nnn );\n  }\n\n  // The actual Set of Joy, which changes during a resize event.  The\n  // Only Field for this class, so I can atomically change the entire\n  // set implementation with a single CAS.\n  private transient NBSI _nbsi;\n\n  /** Create a new empty bit-vector */\n  public NonBlockingSetInt( ) {\n    _nbsi = new NBSI(63, new ConcurrentAutoTable(), this); // The initial 1-word set\n  }\n\n  /**\n   * Add {@code i} to the set.  Uppercase {@link Integer} version of add,\n   * requires auto-unboxing.  When possible use the {@code int} version of\n   * {@link #add(int)} for efficiency.\n   * @throws IllegalArgumentException if i is negative.\n   * @return <tt>true</tt> if i was added to the set.\n   */\n  public boolean add ( final Integer i ) {\n    return add(i.intValue());\n  }\n  /**\n   * Test if {@code o} is in the set.  This is the uppercase {@link Integer}\n   * version of contains, requires a type-check and auto-unboxing.  When\n   * possible use the {@code int} version of {@link #contains(int)} for\n   * efficiency.\n   * @return <tt>true</tt> if i was in the set.\n   */\n  public boolean contains( final Object  o ) {\n    return o instanceof Integer && contains(((Integer) o).intValue());\n  }\n  /**\n   * Remove {@code o} from the set.  This is the uppercase {@link Integer}\n   * version of remove, requires a type-check and auto-unboxing.  When\n   * possible use the {@code int} version of {@link #remove(int)} for\n   * efficiency.\n   * @return <tt>true</tt> if i was removed to the set.\n   */\n  public boolean remove( final Object  o ) {\n    return o instanceof Integer && remove(((Integer) o).intValue());\n  }\n\n  /**\n   * Add {@code i} to the set.  This is the lower-case '{@code int}' version\n   * of {@link #add} - no autoboxing.  Negative values throw\n   * IllegalArgumentException.\n   * @throws IllegalArgumentException if i is negative.\n   * @return <tt>true</tt> if i was added to the set.\n   */\n  public boolean add( final int i ) {\n    RangeUtil.checkPositiveOrZero(i, \"i\");\n    return _nbsi.add(i);\n  }\n  /**\n   * Test if {@code i} is in the set.  This is the lower-case '{@code int}'\n   * version of {@link #contains} - no autoboxing.\n   * @return <tt>true</tt> if i was int the set.\n   */\n  public boolean contains( final int i ) { return i >= 0 && _nbsi.contains(i); }\n  /**\n   * Remove {@code i} from the set.  This is the fast lower-case '{@code int}'\n   * version of {@link #remove} - no autoboxing.\n   * @return <tt>true</tt> if i was added to the set.\n   */\n  public boolean remove  ( final int i ) { return i >= 0 && _nbsi.remove(i); }\n\n  /**\n   * Current count of elements in the set.  Due to concurrent racing updates,\n   * the size is only ever approximate.  Updates due to the calling thread are\n   * immediately visible to calling thread.\n   * @return count of elements.\n   */\n  public int     size    (             ) { return _nbsi.size( );                   }\n  /** Approx largest element in set; at least as big (but max might be smaller).  */\n  public int length() { return _nbsi._bits.length<<6; }\n  /** Empty the bitvector. */\n  public void    clear   (             ) {\n    NBSI cleared = new NBSI(63, new ConcurrentAutoTable(), this); // An empty initial NBSI\n    while( !CAS_nbsi( _nbsi, cleared ) ) // Spin until clear works\n      ;\n  }\n\n  /** Verbose printout of internal structure for debugging. */\n  public void print() { _nbsi.print(0); }\n\n  /**\n   * Standard Java {@link Iterator}.  Not very efficient because it\n   * auto-boxes the returned values.\n   */\n  public Iterator<Integer> iterator( ) { return new iter(); }\n\n  private class iter implements Iterator<Integer> {\n    NBSI _nbsi2;\n    int _idx  = -1;\n    int _prev = -1;\n    iter() { _nbsi2 = _nbsi; advance(); }\n    public boolean hasNext() { return _idx != -2; }\n    private void advance() {\n      while( true ) {\n        _idx++;                 // Next index\n        while( (_idx>>6) >= _nbsi2._bits.length ) { // Index out of range?\n          if( _nbsi2._new == null ) { // New table?\n            _idx = -2;          // No, so must be all done\n            return;             //\n          }\n          _nbsi2 = _nbsi2._new; // Carry on, in the new table\n        }\n        if( _nbsi2.contains(_idx) ) return;\n      }\n    }\n    public Integer next() {\n      if( _idx == -1 ) throw new NoSuchElementException();\n      _prev = _idx;\n      advance();\n      return _prev;\n    }\n    public void remove() {\n      if( _prev == -1 ) throw new IllegalStateException();\n      _nbsi2.remove(_prev);\n      _prev = -1;\n    }\n  }\n\n  // --- writeObject -------------------------------------------------------\n  // Write a NBSI to a stream\n  private void writeObject(java.io.ObjectOutputStream s) throws IOException  {\n    s.defaultWriteObject();     // Nothing to write\n    final NBSI nbsi = _nbsi;    // The One Field is transient\n    final int len = _nbsi._bits.length<<6;\n    s.writeInt(len);            // Write max element\n    for( int i=0; i<len; i++ )\n      s.writeBoolean( _nbsi.contains(i) );\n  }\n\n  // --- readObject --------------------------------------------------------\n  // Read a NBSI from a stream\n  private void readObject(java.io.ObjectInputStream s) throws IOException, ClassNotFoundException  {\n    s.defaultReadObject();      // Read nothing\n    final int len = s.readInt(); // Read max element\n    _nbsi = new NBSI(len, new ConcurrentAutoTable(), this);\n    for( int i=0; i<len; i++ )  // Read all bits\n      if( s.readBoolean() )\n        _nbsi.add(i);\n  }\n\n  // --- NBSI ----------------------------------------------------------------\n  private static final class NBSI {\n    // Back pointer to the parent wrapper; sorta like make the class non-static\n    private transient final NonBlockingSetInt _non_blocking_set_int;\n\n    // Used to count elements: a high-performance counter.\n    private transient final ConcurrentAutoTable _size;\n\n    // The Bits\n    private final long _bits[];\n    // --- Bits to allow Unsafe access to arrays\n    private static final int _Lbase  = UNSAFE.arrayBaseOffset(long[].class);\n    private static final int _Lscale = UNSAFE.arrayIndexScale(long[].class);\n    private static long rawIndex(final long[] ary, final int idx) {\n      assert idx >= 0 && idx < ary.length;\n      return _Lbase + (idx * (long)_Lscale);\n    }\n    private final boolean CAS( int idx, long old, long nnn ) {\n      return UNSAFE.compareAndSwapLong( _bits, rawIndex(_bits, idx), old, nnn );\n    }\n\n    // --- Resize\n    // The New Table, only set once to non-zero during a resize.\n    // Must be atomically set.\n    private NBSI _new;\n    private static final long _new_offset = fieldOffset(NBSI.class, \"_new\");\n\n    private final boolean CAS_new( NBSI nnn ) {\n      return UNSAFE.compareAndSwapObject(this, _new_offset, null, nnn );\n    }\n\n    private transient final AtomicInteger _copyIdx;   // Used to count bits started copying\n    private transient final AtomicInteger _copyDone;  // Used to count words copied in a resize operation\n    private transient final int _sum_bits_length; // Sum of all nested _bits.lengths\n\n    private static final long mask( int i ) { return 1L<<(i&63); }\n\n    // I need 1 free bit out of 64 to allow for resize.  I do this by stealing\n    // the high order bit - but then I need to do something with adding element\n    // number 63 (and friends).  I could use a mod63 function but it's more\n    // efficient to handle the mod-64 case as an exception.\n    //\n    // Every 64th bit is put in it's own recursive bitvector.  If the low 6 bits\n    // are all set, we shift them off and recursively operate on the _nbsi64 set.\n    private final NBSI _nbsi64;\n\n    private NBSI( int max_elem, ConcurrentAutoTable ctr, NonBlockingSetInt nonb ) {\n      super();\n      _non_blocking_set_int = nonb;\n      _size = ctr;\n      _copyIdx  = ctr == null ? null : new AtomicInteger();\n      _copyDone = ctr == null ? null : new AtomicInteger();\n      // The main array of bits\n      _bits = new long[(int)(((long)max_elem+63)>>>6)];\n      // Every 64th bit is moved off to it's own subarray, so that the\n      // sign-bit is free for other purposes\n      _nbsi64 = ((max_elem+1)>>>6) == 0 ? null : new NBSI((max_elem+1)>>>6, null, null);\n      _sum_bits_length = _bits.length + (_nbsi64==null ? 0 : _nbsi64._sum_bits_length);\n    }\n\n    // Lower-case 'int' versions - no autoboxing, very fast.\n    // 'i' is known positive.\n    public boolean add( final int i ) {\n      // Check for out-of-range for the current size bit vector.\n      // If so we need to grow the bit vector.\n      if( (i>>6) >= _bits.length )\n        return install_larger_new_bits(i). // Install larger pile-o-bits (duh)\n          help_copy().add(i);              // Finally, add to the new table\n\n      // Handle every 64th bit via using a nested array\n      NBSI nbsi = this;         // The bit array being added into\n      int j = i;                // The bit index being added\n      while( (j&63) == 63 ) {   // Bit 64? (low 6 bits are all set)\n        nbsi = nbsi._nbsi64;    // Recurse\n        j = j>>6;               // Strip off low 6 bits (all set)\n      }\n\n      final long mask = mask(j);\n      long old;\n      do {\n        old = nbsi._bits[j>>6]; // Read old bits\n        if( old < 0 )           // Not mutable?\n          // Not mutable: finish copy of word, and retry on copied word\n          return help_copy_impl(i).help_copy().add(i);\n        if( (old & mask) != 0 ) return false; // Bit is already set?\n      } while( !nbsi.CAS( j>>6, old, old | mask ) );\n      _size.add(1);\n      return true;\n    }\n\n    public boolean remove( final int i ) {\n      if( (i>>6) >= _bits.length ) // Out of bounds?  Not in this array!\n        return _new != null && help_copy().remove(i);\n\n      // Handle every 64th bit via using a nested array\n      NBSI nbsi = this;         // The bit array being added into\n      int j = i;                // The bit index being added\n      while( (j&63) == 63 ) {   // Bit 64? (low 6 bits are all set)\n        nbsi = nbsi._nbsi64;    // Recurse\n        j = j>>6;               // Strip off low 6 bits (all set)\n      }\n\n      final long mask = mask(j);\n      long old;\n      do {\n        old = nbsi._bits[j>>6]; // Read old bits\n        if( old < 0 )           // Not mutable?\n          // Not mutable: finish copy of word, and retry on copied word\n          return help_copy_impl(i).help_copy().remove(i);\n        if( (old & mask) == 0 ) return false; // Bit is already clear?\n      } while( !nbsi.CAS( j>>6, old, old & ~mask ) );\n      _size.add(-1);\n      return true;\n    }\n\n    public boolean contains( final int i ) {\n      if( (i>>6) >= _bits.length ) // Out of bounds?  Not in this array!\n        return _new != null && help_copy().contains(i);\n\n      // Handle every 64th bit via using a nested array\n      NBSI nbsi = this;         // The bit array being added into\n      int j = i;                // The bit index being added\n      while( (j&63) == 63 ) {   // Bit 64? (low 6 bits are all set)\n        nbsi = nbsi._nbsi64;    // Recurse\n        j = j>>6;               // Strip off low 6 bits (all set)\n      }\n\n      final long mask = mask(j);\n      long old = nbsi._bits[j>>6]; // Read old bits\n      if( old < 0 )             // Not mutable?\n        // Not mutable: finish copy of word, and retry on copied word\n        return help_copy_impl(i).help_copy().contains(i);\n      // Yes mutable: test & return bit\n      return (old & mask) != 0;\n    }\n\n    public int size() { return (int)_size.get(); }\n\n    // Must grow the current array to hold an element of size i\n    private NBSI install_larger_new_bits( final int i ) {\n      if( _new == null ) {\n        // Grow by powers of 2, to avoid minor grow-by-1's.\n        // Note: must grow by exact powers-of-2 or the by-64-bit trick doesn't work right\n        int sz = (_bits.length<<6)<<1;\n        // CAS to install a new larger size.  Did it work?  Did it fail?  We\n        // don't know and don't care.  Only One can be installed, so if\n        // another thread installed a too-small size, we can't help it - we\n        // must simply install our new larger size as a nested-resize table.\n        CAS_new(new NBSI(sz, _size, _non_blocking_set_int));\n      }\n      // Return self for 'fluid' programming style\n      return this;\n    }\n\n    // Help any top-level NBSI to copy until completed.\n    // Always return the _new version of *this* NBSI, in case we're nested.\n    private NBSI help_copy() {\n      // Pick some words to help with - but only help copy the top-level NBSI.\n      // Nested NBSI waits until the top is done before we start helping.\n      NBSI top_nbsi = _non_blocking_set_int._nbsi;\n      final int HELP = 8;       // Tuning number: how much copy pain are we willing to inflict?\n      // We \"help\" by forcing individual bit indices to copy.  However, bits\n      // come in lumps of 64 per word, so we just advance the bit counter by 64's.\n      int idx = top_nbsi._copyIdx.getAndAdd(64*HELP);\n      for( int i=0; i<HELP; i++ ) {\n        int j = idx+i*64;\n        j %= (top_nbsi._bits.length<<6); // Limit, wrap to array size; means we retry indices\n        top_nbsi.help_copy_impl(j   );\n        top_nbsi.help_copy_impl(j+63); // Also force the nested-by-64 bit\n      }\n\n      // Top level guy ready to promote?\n      // Note: WE may not be the top-level guy!\n      if( top_nbsi._copyDone.get() == top_nbsi._sum_bits_length )\n        // One shot CAS to promote - it may fail since we are racing; others\n        // may promote as well\n        if( _non_blocking_set_int.CAS_nbsi( top_nbsi, top_nbsi._new ) ) {\n          //System.out.println(\"Promote at top level to size \"+(_non_blocking_set_int._nbsi._bits.length<<6));\n        }\n\n      // Return the new bitvector for 'fluid' programming style\n      return _new;\n    }\n\n    // Help copy this one word.  State Machine.\n    // (1) If not \"made immutable\" in the old array, set the sign bit to make\n    //     it immutable.\n    // (2) If non-zero in old array & zero in new, CAS new from 0 to copy-of-old\n    // (3) If non-zero in old array & non-zero in new, CAS old to zero\n    // (4) Zero in old, new is valid\n    // At this point, old should be immutable-zero & new has a copy of bits\n    private NBSI help_copy_impl( int i ) {\n      // Handle every 64th bit via using a nested array\n      NBSI old = this;          // The bit array being copied from\n      NBSI nnn = _new;          // The bit array being copied to\n      if( nnn == null ) return this; // Promoted already\n      int j = i;                // The bit index being added\n      while( (j&63) == 63 ) {   // Bit 64? (low 6 bits are all set)\n        old = old._nbsi64;      // Recurse\n        nnn = nnn._nbsi64;      // Recurse\n        j = j>>6;               // Strip off low 6 bits (all set)\n      }\n\n      // Transit from state 1: word is not immutable yet\n      // Immutable is in bit 63, the sign bit.\n      long bits = old._bits[j>>6];\n      while( bits >= 0 ) {      // Still in state (1)?\n        long oldbits = bits;\n        bits |= mask(63);       // Target state of bits: sign-bit means immutable\n        if( old.CAS( j>>6, oldbits, bits ) ) {\n          if( oldbits == 0 ) _copyDone.addAndGet(1);\n          break;                // Success - old array word is now immutable\n        }\n        bits = old._bits[j>>6]; // Retry if CAS failed\n      }\n\n      // Transit from state 2: non-zero in old and zero in new\n      if( bits != mask(63) ) {  // Non-zero in old?\n        long new_bits = nnn._bits[j>>6];\n        if( new_bits == 0 ) {   // New array is still zero\n          new_bits = bits & ~mask(63); // Desired new value: a mutable copy of bits\n          // One-shot CAS attempt, no loop, from 0 to non-zero.\n          // If it fails, somebody else did the copy for us\n          if( !nnn.CAS( j>>6, 0, new_bits ) )\n            new_bits = nnn._bits[j>>6]; // Since it failed, get the new value\n          assert new_bits != 0;\n        }\n\n        // Transit from state 3: non-zero in old and non-zero in new\n        // One-shot CAS attempt, no loop, from non-zero to 0 (but immutable)\n        if( old.CAS( j>>6, bits, mask(63) ) )\n          _copyDone.addAndGet(1); // One more word finished copying\n      }\n\n      // Now in state 4: zero (and immutable) in old\n\n      // Return the self bitvector for 'fluid' programming style\n      return this;\n    }\n\n    private void print( int d, String msg ) {\n      for( int i=0; i<d; i++ )\n        System.out.print(\"  \");\n      System.out.println(msg);\n    }\n\n    private void print(int d) {\n      StringBuilder buf = new StringBuilder();\n      buf.append(\"NBSI - _bits.len=\");\n      NBSI x = this;\n      while( x != null ) {\n        buf.append(\" \"+x._bits.length);\n        x = x._nbsi64;\n      }\n      print(d,buf.toString());\n\n      x = this;\n      while( x != null ) {\n        for( int i=0; i<x._bits.length; i++ )\n          System.out.print(Long.toHexString(x._bits[i])+\" \");\n        x = x._nbsi64;\n        System.out.println();\n      }\n\n      if( _copyIdx.get() != 0 || _copyDone.get() != 0 )\n        print(d,\"_copyIdx=\"+_copyIdx.get()+\" _copyDone=\"+_copyDone.get()+\" _words_to_cpy=\"+_sum_bits_length);\n      if( _new != null ) {\n        print(d,\"__has_new - \");\n        _new.print(d+1);\n      }\n    }\n  }\n}\n",
        "simple_context": "package org.jctools.maps;\n\nimport static org.jctools.util.UnsafeAccess.UNSAFE;\n\nimport static org.jctools.util.UnsafeAccess.fieldOffset;\n\nimport java.io.IOException;\n\nimport java.io.Serializable;\n\nimport java.lang.reflect.Field;\n\nimport java.util.AbstractSet;\n\nimport java.util.Iterator;\n\nimport java.util.NoSuchElementException;\n\nimport java.util.concurrent.atomic.AtomicInteger;\n\nimport org.jctools.util.RangeUtil;\n\npublic class NonBlockingSetInt extends AbstractSet<Integer> implements Serializable {\n    static final private long serialVersionUID;\n    static final private long _nbsi_offset;\n    final private boolean CAS_nbsi(NBSI old, NBSI nnn);\n    transient private NBSI _nbsi;\n    public NonBlockingSetInt();\n    public boolean add(Integer i);\n    public boolean contains(Object o);\n    public boolean remove(Object o);\n    public boolean add(int i);\n    public boolean contains(int i);\n    public boolean remove(int i);\n    public int size();\n    public int length();\n    public  clear();\n    public  print();\n    public Iterator<Integer> iterator();\n    private class iter implements Iterator<Integer> {\n        NBSI _nbsi2;\n        int _idx;\n        int _prev;\n        iter();\n        public boolean hasNext();\n        private  advance();\n        public Integer next();\n        public  remove();\n    }\n    private  writeObject(java s)throws IOException;\n    private  readObject(java s)throws IOException, ClassNotFoundException;\n    static final private class NBSI {\n        transient final private NonBlockingSetInt _non_blocking_set_int;\n        transient final private ConcurrentAutoTable _size;\n        final private long _bits;\n        static final private int _Lbase;\n        static final private int _Lscale;\n        static private long rawIndex(long[] ary, int idx);\n        final private boolean CAS(int idx, long old, long nnn);\n        private NBSI _new;\n        static final private long _new_offset;\n        final private boolean CAS_new(NBSI nnn);\n        transient final private AtomicInteger _copyIdx;\n        transient final private AtomicInteger _copyDone;\n        transient final private int _sum_bits_length;\n        static final private long mask(int i);\n        final private NBSI _nbsi64;\n        private NBSI(int max_elem, ConcurrentAutoTable ctr, NonBlockingSetInt nonb);\n        public boolean add(int i);\n        public boolean remove(int i);\n        public boolean contains(int i);\n        public int size();\n        private NBSI install_larger_new_bits(int i);\n        private NBSI help_copy();\n        private NBSI help_copy_impl(int i);\n        private  print(int d, String msg);\n        private  print(int d);\n    }\n}\n\n"
    },
    {
        "project_name": "JCTools",
        "file_name": "BaseLinkedQueue.java",
        "relative_path": "JCTools/jctools-core/src/main/java/org/jctools/queues/BaseLinkedQueue.java",
        "execute_path": "JCTools",
        "package": "org.jctools.queues",
        "docstring": "/**\n     * {@inheritDoc} <br>\n     * <p>\n     * IMPLEMENTATION NOTES:<br>\n     * This is an O(n) operation as we run through all the nodes and count them.<br>\n     * The accuracy of the value returned by this method is subject to races with producer/consumer threads. In\n     * particular when racing with the consumer thread this method may under estimate the size.<br>\n     *\n     * @see java.util.Queue#size()\n     */",
        "source_code": "\n@Override\npublic final int size()\n{\n    // Read consumer first, this is important because if the producer is node is 'older' than the consumer\n    // the consumer may overtake it (consume past it) invalidating the 'snapshot' notion of size.\n    LinkedQueueNode<E> chaserNode = lvConsumerNode();\n    LinkedQueueNode<E> producerNode = lvProducerNode();\n    int size = 0;\n    // must chase the nodes all the way to the producer node, but there's no need to count beyond expected head.\n    while (chaserNode != producerNode && // don't go passed producer node\n        chaserNode != null && // stop at last node\n        size < Integer.MAX_VALUE) // stop at max int\n    {\n        LinkedQueueNode<E> next;\n        next = chaserNode.lvNext();\n        // check if this node has been consumed, if so return what we have\n        if (next == chaserNode)\n        {\n            return size;\n        }\n        chaserNode = next;\n        size++;\n    }\n    return size;\n}\n",
        "class_name": "BaseLinkedQueuePad0",
        "method_name": "size",
        "argument_name": [],
        "full_context": "/*\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.jctools.queues;\n\nimport java.util.AbstractQueue;\nimport java.util.Iterator;\nimport java.util.Queue;\n\nimport static org.jctools.util.UnsafeAccess.UNSAFE;\nimport static org.jctools.util.UnsafeAccess.fieldOffset;\n\nabstract class BaseLinkedQueuePad0<E> extends AbstractQueue<E> implements MessagePassingQueue<E>\n{\n    byte b000,b001,b002,b003,b004,b005,b006,b007;//  8b\n    byte b010,b011,b012,b013,b014,b015,b016,b017;// 16b\n    byte b020,b021,b022,b023,b024,b025,b026,b027;// 24b\n    byte b030,b031,b032,b033,b034,b035,b036,b037;// 32b\n    byte b040,b041,b042,b043,b044,b045,b046,b047;// 40b\n    byte b050,b051,b052,b053,b054,b055,b056,b057;// 48b\n    byte b060,b061,b062,b063,b064,b065,b066,b067;// 56b\n    byte b070,b071,b072,b073,b074,b075,b076,b077;// 64b\n    byte b100,b101,b102,b103,b104,b105,b106,b107;// 72b\n    byte b110,b111,b112,b113,b114,b115,b116,b117;// 80b\n    byte b120,b121,b122,b123,b124,b125,b126,b127;// 88b\n    byte b130,b131,b132,b133,b134,b135,b136,b137;// 96b\n    byte b140,b141,b142,b143,b144,b145,b146,b147;//104b\n    byte b150,b151,b152,b153,b154,b155,b156,b157;//112b\n    byte b160,b161,b162,b163,b164,b165,b166,b167;//120b\n    // byte b170,b171,b172,b173,b174,b175,b176,b177;//128b\n    //    * drop 8b as object header acts as padding and is >= 8b *\n}\n\n// $gen:ordered-fields\nabstract class BaseLinkedQueueProducerNodeRef<E> extends BaseLinkedQueuePad0<E>\n{\n    final static long P_NODE_OFFSET = fieldOffset(BaseLinkedQueueProducerNodeRef.class, \"producerNode\");\n\n    private volatile LinkedQueueNode<E> producerNode;\n\n    final void spProducerNode(LinkedQueueNode<E> newValue)\n    {\n        UNSAFE.putObject(this, P_NODE_OFFSET, newValue);\n    }\n\n    final void soProducerNode(LinkedQueueNode<E> newValue)\n    {\n        UNSAFE.putOrderedObject(this, P_NODE_OFFSET, newValue);\n    }\n\n    final LinkedQueueNode<E> lvProducerNode()\n    {\n        return producerNode;\n    }\n\n    final boolean casProducerNode(LinkedQueueNode<E> expect, LinkedQueueNode<E> newValue)\n    {\n        return UNSAFE.compareAndSwapObject(this, P_NODE_OFFSET, expect, newValue);\n    }\n\n    final LinkedQueueNode<E> lpProducerNode()\n    {\n        return producerNode;\n    }\n}\n\nabstract class BaseLinkedQueuePad1<E> extends BaseLinkedQueueProducerNodeRef<E>\n{\n    byte b000,b001,b002,b003,b004,b005,b006,b007;//  8b\n    byte b010,b011,b012,b013,b014,b015,b016,b017;// 16b\n    byte b020,b021,b022,b023,b024,b025,b026,b027;// 24b\n    byte b030,b031,b032,b033,b034,b035,b036,b037;// 32b\n    byte b040,b041,b042,b043,b044,b045,b046,b047;// 40b\n    byte b050,b051,b052,b053,b054,b055,b056,b057;// 48b\n    byte b060,b061,b062,b063,b064,b065,b066,b067;// 56b\n    byte b070,b071,b072,b073,b074,b075,b076,b077;// 64b\n    byte b100,b101,b102,b103,b104,b105,b106,b107;// 72b\n    byte b110,b111,b112,b113,b114,b115,b116,b117;// 80b\n    byte b120,b121,b122,b123,b124,b125,b126,b127;// 88b\n    byte b130,b131,b132,b133,b134,b135,b136,b137;// 96b\n    byte b140,b141,b142,b143,b144,b145,b146,b147;//104b\n    byte b150,b151,b152,b153,b154,b155,b156,b157;//112b\n    byte b160,b161,b162,b163,b164,b165,b166,b167;//120b\n    byte b170,b171,b172,b173,b174,b175,b176,b177;//128b\n}\n\n//$gen:ordered-fields\nabstract class BaseLinkedQueueConsumerNodeRef<E> extends BaseLinkedQueuePad1<E>\n{\n    private final static long C_NODE_OFFSET = fieldOffset(BaseLinkedQueueConsumerNodeRef.class,\"consumerNode\");\n\n    private LinkedQueueNode<E> consumerNode;\n\n    final void spConsumerNode(LinkedQueueNode<E> newValue)\n    {\n        consumerNode = newValue;\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    final LinkedQueueNode<E> lvConsumerNode()\n    {\n        return (LinkedQueueNode<E>) UNSAFE.getObjectVolatile(this, C_NODE_OFFSET);\n    }\n\n    final LinkedQueueNode<E> lpConsumerNode()\n    {\n        return consumerNode;\n    }\n}\n\nabstract class BaseLinkedQueuePad2<E> extends BaseLinkedQueueConsumerNodeRef<E>\n{\n    byte b000,b001,b002,b003,b004,b005,b006,b007;//  8b\n    byte b010,b011,b012,b013,b014,b015,b016,b017;// 16b\n    byte b020,b021,b022,b023,b024,b025,b026,b027;// 24b\n    byte b030,b031,b032,b033,b034,b035,b036,b037;// 32b\n    byte b040,b041,b042,b043,b044,b045,b046,b047;// 40b\n    byte b050,b051,b052,b053,b054,b055,b056,b057;// 48b\n    byte b060,b061,b062,b063,b064,b065,b066,b067;// 56b\n    byte b070,b071,b072,b073,b074,b075,b076,b077;// 64b\n    byte b100,b101,b102,b103,b104,b105,b106,b107;// 72b\n    byte b110,b111,b112,b113,b114,b115,b116,b117;// 80b\n    byte b120,b121,b122,b123,b124,b125,b126,b127;// 88b\n    byte b130,b131,b132,b133,b134,b135,b136,b137;// 96b\n    byte b140,b141,b142,b143,b144,b145,b146,b147;//104b\n    byte b150,b151,b152,b153,b154,b155,b156,b157;//112b\n    byte b160,b161,b162,b163,b164,b165,b166,b167;//120b\n    byte b170,b171,b172,b173,b174,b175,b176,b177;//128b\n}\n\n/**\n * A base data structure for concurrent linked queues. For convenience also pulled in common single consumer\n * methods since at this time there's no plan to implement MC.\n */\nabstract class BaseLinkedQueue<E> extends BaseLinkedQueuePad2<E>\n{\n\n    @Override\n    public final Iterator<E> iterator()\n    {\n        throw new UnsupportedOperationException();\n    }\n\n    @Override\n    public String toString()\n    {\n        return this.getClass().getName();\n    }\n\n    protected final LinkedQueueNode<E> newNode()\n    {\n        return new LinkedQueueNode<E>();\n    }\n\n    protected final LinkedQueueNode<E> newNode(E e)\n    {\n        return new LinkedQueueNode<E>(e);\n    }\n\n    /**\n     * {@inheritDoc} <br>\n     * <p>\n     * IMPLEMENTATION NOTES:<br>\n     * This is an O(n) operation as we run through all the nodes and count them.<br>\n     * The accuracy of the value returned by this method is subject to races with producer/consumer threads. In\n     * particular when racing with the consumer thread this method may under estimate the size.<br>\n     *\n     * @see java.util.Queue#size()\n     */\n    @Override\n    public final int size()\n    {\n        // Read consumer first, this is important because if the producer is node is 'older' than the consumer\n        // the consumer may overtake it (consume past it) invalidating the 'snapshot' notion of size.\n        LinkedQueueNode<E> chaserNode = lvConsumerNode();\n        LinkedQueueNode<E> producerNode = lvProducerNode();\n        int size = 0;\n        // must chase the nodes all the way to the producer node, but there's no need to count beyond expected head.\n        while (chaserNode != producerNode && // don't go passed producer node\n            chaserNode != null && // stop at last node\n            size < Integer.MAX_VALUE) // stop at max int\n        {\n            LinkedQueueNode<E> next;\n            next = chaserNode.lvNext();\n            // check if this node has been consumed, if so return what we have\n            if (next == chaserNode)\n            {\n                return size;\n            }\n            chaserNode = next;\n            size++;\n        }\n        return size;\n    }\n\n    /**\n     * {@inheritDoc} <br>\n     * <p>\n     * IMPLEMENTATION NOTES:<br>\n     * Queue is empty when producerNode is the same as consumerNode. An alternative implementation would be to\n     * observe the producerNode.value is null, which also means an empty queue because only the\n     * consumerNode.value is allowed to be null.\n     *\n     * @see MessagePassingQueue#isEmpty()\n     */\n    @Override\n    public boolean isEmpty()\n    {\n        LinkedQueueNode<E> consumerNode = lvConsumerNode();\n        LinkedQueueNode<E> producerNode = lvProducerNode();\n        return consumerNode == producerNode;\n    }\n\n    protected E getSingleConsumerNodeValue(LinkedQueueNode<E> currConsumerNode, LinkedQueueNode<E> nextNode)\n    {\n        // we have to null out the value because we are going to hang on to the node\n        final E nextValue = nextNode.getAndNullValue();\n\n        // Fix up the next ref of currConsumerNode to prevent promoted nodes from keeping new ones alive.\n        // We use a reference to self instead of null because null is already a meaningful value (the next of\n        // producer node is null).\n        currConsumerNode.soNext(currConsumerNode);\n        spConsumerNode(nextNode);\n        // currConsumerNode is now no longer referenced and can be collected\n        return nextValue;\n    }\n\n    /**\n     * {@inheritDoc} <br>\n     * <p>\n     * IMPLEMENTATION NOTES:<br>\n     * Poll is allowed from a SINGLE thread.<br>\n     * Poll is potentially blocking here as the {@link Queue#poll()} does not allow returning {@code null} if the queue is not\n     * empty. This is very different from the original Vyukov guarantees. See {@link #relaxedPoll()} for the original\n     * semantics.<br>\n     * Poll reads {@code consumerNode.next} and:\n     * <ol>\n     * <li>If it is {@code null} AND the queue is empty return {@code null}, <b>if queue is not empty spin wait for\n     * value to become visible</b>.\n     * <li>If it is not {@code null} set it as the consumer node and return it's now evacuated value.\n     * </ol>\n     * This means the consumerNode.value is always {@code null}, which is also the starting point for the queue.\n     * Because {@code null} values are not allowed to be offered this is the only node with it's value set to\n     * {@code null} at any one time.\n     *\n     * @see MessagePassingQueue#poll()\n     * @see java.util.Queue#poll()\n     */\n    @Override\n    public E poll()\n    {\n        final LinkedQueueNode<E> currConsumerNode = lpConsumerNode();\n        LinkedQueueNode<E> nextNode = currConsumerNode.lvNext();\n        if (nextNode != null)\n        {\n            return getSingleConsumerNodeValue(currConsumerNode, nextNode);\n        }\n        else if (currConsumerNode != lvProducerNode())\n        {\n            nextNode = spinWaitForNextNode(currConsumerNode);\n            // got the next node...\n            return getSingleConsumerNodeValue(currConsumerNode, nextNode);\n        }\n        return null;\n    }\n\n    /**\n     * {@inheritDoc} <br>\n     * <p>\n     * IMPLEMENTATION NOTES:<br>\n     * Peek is allowed from a SINGLE thread.<br>\n     * Peek is potentially blocking here as the {@link Queue#peek()} does not allow returning {@code null} if the queue is not\n     * empty. This is very different from the original Vyukov guarantees. See {@link #relaxedPeek()} for the original\n     * semantics.<br>\n     * Poll reads the next node from the consumerNode and:\n     * <ol>\n     * <li>If it is {@code null} AND the queue is empty return {@code null}, <b>if queue is not empty spin wait for\n     * value to become visible</b>.\n     * <li>If it is not {@code null} return it's value.\n     * </ol>\n     *\n     * @see MessagePassingQueue#peek()\n     * @see java.util.Queue#peek()\n     */\n    @Override\n    public E peek()\n    {\n        final LinkedQueueNode<E> currConsumerNode = lpConsumerNode();\n        LinkedQueueNode<E> nextNode = currConsumerNode.lvNext();\n        if (nextNode != null)\n        {\n            return nextNode.lpValue();\n        }\n        else if (currConsumerNode != lvProducerNode())\n        {\n            nextNode = spinWaitForNextNode(currConsumerNode);\n            // got the next node...\n            return nextNode.lpValue();\n        }\n        return null;\n    }\n\n    LinkedQueueNode<E> spinWaitForNextNode(LinkedQueueNode<E> currNode)\n    {\n        LinkedQueueNode<E> nextNode;\n        while ((nextNode = currNode.lvNext()) == null)\n        {\n            // spin, we are no longer wait free\n        }\n        return nextNode;\n    }\n\n    @Override\n    public E relaxedPoll()\n    {\n        final LinkedQueueNode<E> currConsumerNode = lpConsumerNode();\n        final LinkedQueueNode<E> nextNode = currConsumerNode.lvNext();\n        if (nextNode != null)\n        {\n            return getSingleConsumerNodeValue(currConsumerNode, nextNode);\n        }\n        return null;\n    }\n\n    @Override\n    public E relaxedPeek()\n    {\n        final LinkedQueueNode<E> nextNode = lpConsumerNode().lvNext();\n        if (nextNode != null)\n        {\n            return nextNode.lpValue();\n        }\n        return null;\n    }\n\n    @Override\n    public boolean relaxedOffer(E e)\n    {\n        return offer(e);\n    }\n\n    @Override\n    public int drain(Consumer<E> c, int limit)\n    {\n        if (null == c)\n            throw new IllegalArgumentException(\"c is null\");\n        if (limit < 0)\n            throw new IllegalArgumentException(\"limit is negative: \" + limit);\n        if (limit == 0)\n            return 0;\n\n        LinkedQueueNode<E> chaserNode = this.lpConsumerNode();\n        for (int i = 0; i < limit; i++)\n        {\n            final LinkedQueueNode<E> nextNode = chaserNode.lvNext();\n\n            if (nextNode == null)\n            {\n                return i;\n            }\n            // we have to null out the value because we are going to hang on to the node\n            final E nextValue = getSingleConsumerNodeValue(chaserNode, nextNode);\n            chaserNode = nextNode;\n            c.accept(nextValue);\n        }\n        return limit;\n    }\n\n    @Override\n    public int drain(Consumer<E> c)\n    {\n        return MessagePassingQueueUtil.drain(this, c);\n    }\n\n    @Override\n    public void drain(Consumer<E> c, WaitStrategy wait, ExitCondition exit)\n    {\n        MessagePassingQueueUtil.drain(this, c, wait, exit);\n    }\n\n    @Override\n    public int capacity()\n    {\n        return UNBOUNDED_CAPACITY;\n    }\n\n}\n",
        "simple_context": "package org.jctools.queues;\n\nimport java.util.AbstractQueue;\n\nimport java.util.Iterator;\n\nimport java.util.Queue;\n\nimport static org.jctools.util.UnsafeAccess.UNSAFE;\n\nimport static org.jctools.util.UnsafeAccess.fieldOffset;\n\nabstract class BaseLinkedQueuePad0 extends AbstractQueue<E> implements MessagePassingQueue<E> {\n    byte b000, b001, b002, b003, b004, b005, b006, b007;\n    byte b010, b011, b012, b013, b014, b015, b016, b017;\n    byte b020, b021, b022, b023, b024, b025, b026, b027;\n    byte b030, b031, b032, b033, b034, b035, b036, b037;\n    byte b040, b041, b042, b043, b044, b045, b046, b047;\n    byte b050, b051, b052, b053, b054, b055, b056, b057;\n    byte b060, b061, b062, b063, b064, b065, b066, b067;\n    byte b070, b071, b072, b073, b074, b075, b076, b077;\n    byte b100, b101, b102, b103, b104, b105, b106, b107;\n    byte b110, b111, b112, b113, b114, b115, b116, b117;\n    byte b120, b121, b122, b123, b124, b125, b126, b127;\n    byte b130, b131, b132, b133, b134, b135, b136, b137;\n    byte b140, b141, b142, b143, b144, b145, b146, b147;\n    byte b150, b151, b152, b153, b154, b155, b156, b157;\n    byte b160, b161, b162, b163, b164, b165, b166, b167;\n}\n\nabstract class BaseLinkedQueueProducerNodeRef extends BaseLinkedQueuePad0<E> {\n    static final long P_NODE_OFFSET;\n    volatile private LinkedQueueNode<E> producerNode;\n    final  spProducerNode(LinkedQueueNode<E> newValue);\n    final  soProducerNode(LinkedQueueNode<E> newValue);\n    final LinkedQueueNode<E> lvProducerNode();\n    final boolean casProducerNode(LinkedQueueNode<E> expect, LinkedQueueNode<E> newValue);\n    final LinkedQueueNode<E> lpProducerNode();\n}\n\nabstract class BaseLinkedQueuePad1 extends BaseLinkedQueueProducerNodeRef<E> {\n    byte b000, b001, b002, b003, b004, b005, b006, b007;\n    byte b010, b011, b012, b013, b014, b015, b016, b017;\n    byte b020, b021, b022, b023, b024, b025, b026, b027;\n    byte b030, b031, b032, b033, b034, b035, b036, b037;\n    byte b040, b041, b042, b043, b044, b045, b046, b047;\n    byte b050, b051, b052, b053, b054, b055, b056, b057;\n    byte b060, b061, b062, b063, b064, b065, b066, b067;\n    byte b070, b071, b072, b073, b074, b075, b076, b077;\n    byte b100, b101, b102, b103, b104, b105, b106, b107;\n    byte b110, b111, b112, b113, b114, b115, b116, b117;\n    byte b120, b121, b122, b123, b124, b125, b126, b127;\n    byte b130, b131, b132, b133, b134, b135, b136, b137;\n    byte b140, b141, b142, b143, b144, b145, b146, b147;\n    byte b150, b151, b152, b153, b154, b155, b156, b157;\n    byte b160, b161, b162, b163, b164, b165, b166, b167;\n    byte b170, b171, b172, b173, b174, b175, b176, b177;\n}\n\nabstract class BaseLinkedQueueConsumerNodeRef extends BaseLinkedQueuePad1<E> {\n    static final private long C_NODE_OFFSET;\n    private LinkedQueueNode<E> consumerNode;\n    final  spConsumerNode(LinkedQueueNode<E> newValue);\n    final LinkedQueueNode<E> lvConsumerNode();\n    final LinkedQueueNode<E> lpConsumerNode();\n}\n\nabstract class BaseLinkedQueuePad2 extends BaseLinkedQueueConsumerNodeRef<E> {\n    byte b000, b001, b002, b003, b004, b005, b006, b007;\n    byte b010, b011, b012, b013, b014, b015, b016, b017;\n    byte b020, b021, b022, b023, b024, b025, b026, b027;\n    byte b030, b031, b032, b033, b034, b035, b036, b037;\n    byte b040, b041, b042, b043, b044, b045, b046, b047;\n    byte b050, b051, b052, b053, b054, b055, b056, b057;\n    byte b060, b061, b062, b063, b064, b065, b066, b067;\n    byte b070, b071, b072, b073, b074, b075, b076, b077;\n    byte b100, b101, b102, b103, b104, b105, b106, b107;\n    byte b110, b111, b112, b113, b114, b115, b116, b117;\n    byte b120, b121, b122, b123, b124, b125, b126, b127;\n    byte b130, b131, b132, b133, b134, b135, b136, b137;\n    byte b140, b141, b142, b143, b144, b145, b146, b147;\n    byte b150, b151, b152, b153, b154, b155, b156, b157;\n    byte b160, b161, b162, b163, b164, b165, b166, b167;\n    byte b170, b171, b172, b173, b174, b175, b176, b177;\n}\n\nabstract class BaseLinkedQueue extends BaseLinkedQueuePad2<E> {\n    final public Iterator<E> iterator();\n    public String toString();\n    protected final LinkedQueueNode<E> newNode();\n    protected final LinkedQueueNode<E> newNode(E e);\n    final public int size();\n    public boolean isEmpty();\n    protected E getSingleConsumerNodeValue(LinkedQueueNode<E> currConsumerNode, LinkedQueueNode<E> nextNode);\n    public E poll();\n    public E peek();\n    LinkedQueueNode<E> spinWaitForNextNode(LinkedQueueNode<E> currNode);\n    public E relaxedPoll();\n    public E relaxedPeek();\n    public boolean relaxedOffer(E e);\n    public int drain(Consumer<E> c, int limit);\n    public int drain(Consumer<E> c);\n    public  drain(Consumer<E> c, WaitStrategy wait, ExitCondition exit);\n    public int capacity();\n}\n\n"
    },
    {
        "project_name": "JCTools",
        "file_name": "BaseSpscLinkedArrayQueue.java",
        "relative_path": "JCTools/jctools-core/src/main/java/org/jctools/queues/BaseSpscLinkedArrayQueue.java",
        "execute_path": "JCTools",
        "package": "org.jctools.queues",
        "docstring": "/**\n     * {@inheritDoc}\n     * <p>\n     * This implementation is correct for single producer thread use only.\n     */",
        "source_code": "\n@Override\npublic boolean offer(final E e)\n{\n    // Objects.requireNonNull(e);\n    if (null == e)\n    {\n        throw new NullPointerException();\n    }\n    // local load of field to avoid repeated loads after volatile reads\n    final E[] buffer = producerBuffer;\n    final long index = lpProducerIndex();\n    final long mask = producerMask;\n    final long offset = calcCircularRefElementOffset(index, mask);\n    // expected hot path\n    if (index < producerBufferLimit)\n    {\n        writeToQueue(buffer, e, index, offset);\n        return true;\n    }\n    return offerColdPath(buffer, mask, index, offset, e, null);\n}\n",
        "class_name": "BaseSpscLinkedArrayQueuePrePad",
        "method_name": "offer",
        "argument_name": [
            "E e"
        ],
        "full_context": "/*\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.jctools.queues;\n\nimport org.jctools.queues.IndexedQueueSizeUtil.IndexedQueue;\nimport org.jctools.util.PortableJvmInfo;\n\nimport java.util.AbstractQueue;\nimport java.util.Iterator;\n\nimport static org.jctools.queues.LinkedArrayQueueUtil.length;\nimport static org.jctools.queues.LinkedArrayQueueUtil.nextArrayOffset;\nimport static org.jctools.util.UnsafeAccess.UNSAFE;\nimport static org.jctools.util.UnsafeAccess.fieldOffset;\nimport static org.jctools.util.UnsafeRefArrayAccess.*;\n\nabstract class BaseSpscLinkedArrayQueuePrePad<E> extends AbstractQueue<E> implements IndexedQueue\n{\n    byte b000,b001,b002,b003,b004,b005,b006,b007;//  8b\n    byte b010,b011,b012,b013,b014,b015,b016,b017;// 16b\n    byte b020,b021,b022,b023,b024,b025,b026,b027;// 24b\n    byte b030,b031,b032,b033,b034,b035,b036,b037;// 32b\n    byte b040,b041,b042,b043,b044,b045,b046,b047;// 40b\n    byte b050,b051,b052,b053,b054,b055,b056,b057;// 48b\n    byte b060,b061,b062,b063,b064,b065,b066,b067;// 56b\n    byte b070,b071,b072,b073,b074,b075,b076,b077;// 64b\n    byte b100,b101,b102,b103,b104,b105,b106,b107;// 72b\n    byte b110,b111,b112,b113,b114,b115,b116,b117;// 80b\n    byte b120,b121,b122,b123,b124,b125,b126,b127;// 88b\n    byte b130,b131,b132,b133,b134,b135,b136,b137;// 96b\n    byte b140,b141,b142,b143,b144,b145,b146,b147;//104b\n    byte b150,b151,b152,b153,b154,b155,b156,b157;//112b\n    //byte b160,b161,b162,b163,b164,b165,b166,b167;//120b\n    //byte b170,b171,b172,b173,b174,b175,b176,b177;//128b\n    //  * drop 16b , the cold fields act as buffer *\n}\n\nabstract class BaseSpscLinkedArrayQueueConsumerColdFields<E> extends BaseSpscLinkedArrayQueuePrePad<E>\n{\n    protected long consumerMask;\n    protected E[] consumerBuffer;\n}\n\n// $gen:ordered-fields\nabstract class BaseSpscLinkedArrayQueueConsumerField<E> extends BaseSpscLinkedArrayQueueConsumerColdFields<E>\n{\n    private final static long C_INDEX_OFFSET = fieldOffset(BaseSpscLinkedArrayQueueConsumerField.class, \"consumerIndex\");\n\n    private volatile long consumerIndex;\n\n    @Override\n    public final long lvConsumerIndex()\n    {\n        return consumerIndex;\n    }\n\n    final long lpConsumerIndex()\n    {\n        return UNSAFE.getLong(this, C_INDEX_OFFSET);\n    }\n\n    final void soConsumerIndex(long newValue)\n    {\n        UNSAFE.putOrderedLong(this, C_INDEX_OFFSET, newValue);\n    }\n\n}\n\nabstract class BaseSpscLinkedArrayQueueL2Pad<E> extends BaseSpscLinkedArrayQueueConsumerField<E>\n{\n    byte b000,b001,b002,b003,b004,b005,b006,b007;//  8b\n    byte b010,b011,b012,b013,b014,b015,b016,b017;// 16b\n    byte b020,b021,b022,b023,b024,b025,b026,b027;// 24b\n    byte b030,b031,b032,b033,b034,b035,b036,b037;// 32b\n    byte b040,b041,b042,b043,b044,b045,b046,b047;// 40b\n    byte b050,b051,b052,b053,b054,b055,b056,b057;// 48b\n    byte b060,b061,b062,b063,b064,b065,b066,b067;// 56b\n    byte b070,b071,b072,b073,b074,b075,b076,b077;// 64b\n    byte b100,b101,b102,b103,b104,b105,b106,b107;// 72b\n    byte b110,b111,b112,b113,b114,b115,b116,b117;// 80b\n    byte b120,b121,b122,b123,b124,b125,b126,b127;// 88b\n    byte b130,b131,b132,b133,b134,b135,b136,b137;// 96b\n    byte b140,b141,b142,b143,b144,b145,b146,b147;//104b\n    byte b150,b151,b152,b153,b154,b155,b156,b157;//112b\n    byte b160,b161,b162,b163,b164,b165,b166,b167;//120b\n    byte b170,b171,b172,b173,b174,b175,b176,b177;//128b\n}\n\n// $gen:ordered-fields\nabstract class BaseSpscLinkedArrayQueueProducerFields<E> extends BaseSpscLinkedArrayQueueL2Pad<E>\n{\n    private final static long P_INDEX_OFFSET = fieldOffset(BaseSpscLinkedArrayQueueProducerFields.class,\"producerIndex\");\n\n    private volatile long producerIndex;\n\n    @Override\n    public final long lvProducerIndex()\n    {\n        return producerIndex;\n    }\n\n    final void soProducerIndex(long newValue)\n    {\n        UNSAFE.putOrderedLong(this, P_INDEX_OFFSET, newValue);\n    }\n\n    final long lpProducerIndex()\n    {\n        return UNSAFE.getLong(this, P_INDEX_OFFSET);\n    }\n\n}\n\nabstract class BaseSpscLinkedArrayQueueProducerColdFields<E> extends BaseSpscLinkedArrayQueueProducerFields<E>\n{\n    protected long producerBufferLimit;\n    protected long producerMask; // fixed for chunked and unbounded\n\n    protected E[] producerBuffer;\n}\n\nabstract class BaseSpscLinkedArrayQueue<E> extends BaseSpscLinkedArrayQueueProducerColdFields<E>\n    implements MessagePassingQueue<E>, QueueProgressIndicators\n{\n\n    private static final Object JUMP = new Object();\n\n    @Override\n    public final Iterator<E> iterator()\n    {\n        throw new UnsupportedOperationException();\n    }\n\n    @Override\n    public final int size()\n    {\n        return IndexedQueueSizeUtil.size(this, IndexedQueueSizeUtil.PLAIN_DIVISOR);\n    }\n\n    @Override\n    public final boolean isEmpty()\n    {\n        return IndexedQueueSizeUtil.isEmpty(this);\n    }\n\n    @Override\n    public String toString()\n    {\n        return this.getClass().getName();\n    }\n\n    @Override\n    public long currentProducerIndex()\n    {\n        return lvProducerIndex();\n    }\n\n    @Override\n    public long currentConsumerIndex()\n    {\n        return lvConsumerIndex();\n    }\n\n    protected final void soNext(E[] curr, E[] next)\n    {\n        long offset = nextArrayOffset(curr);\n        soRefElement(curr, offset, next);\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    protected final E[] lvNextArrayAndUnlink(E[] curr)\n    {\n        final long offset = nextArrayOffset(curr);\n        final E[] nextBuffer = (E[]) lvRefElement(curr, offset);\n        // prevent GC nepotism\n        soRefElement(curr, offset, null);\n        return nextBuffer;\n    }\n\n    @Override\n    public boolean relaxedOffer(E e)\n    {\n        return offer(e);\n    }\n\n    @Override\n    public E relaxedPoll()\n    {\n        return poll();\n    }\n\n    @Override\n    public E relaxedPeek()\n    {\n        return peek();\n    }\n\n    @Override\n    public int drain(Consumer<E> c)\n    {\n        return MessagePassingQueueUtil.drain(this, c);\n    }\n\n    @Override\n    public int fill(Supplier<E> s)\n    {\n        long result = 0;// result is a long because we want to have a safepoint check at regular intervals\n        final int capacity = capacity();\n        do\n        {\n            final int filled = fill(s, PortableJvmInfo.RECOMENDED_OFFER_BATCH);\n            if (filled == 0)\n            {\n                return (int) result;\n            }\n            result += filled;\n        }\n        while (result <= capacity);\n        return (int) result;\n    }\n\n    @Override\n    public int drain(Consumer<E> c, int limit)\n    {\n        return MessagePassingQueueUtil.drain(this, c, limit);\n    }\n\n    @Override\n    public int fill(Supplier<E> s, int limit)\n    {\n        if (null == s)\n            throw new IllegalArgumentException(\"supplier is null\");\n        if (limit < 0)\n            throw new IllegalArgumentException(\"limit is negative:\" + limit);\n        if (limit == 0)\n            return 0;\n\n        for (int i = 0; i < limit; i++)\n        {\n            // local load of field to avoid repeated loads after volatile reads\n            final E[] buffer = producerBuffer;\n            final long index = lpProducerIndex();\n            final long mask = producerMask;\n            final long offset = calcCircularRefElementOffset(index, mask);\n            // expected hot path\n            if (index < producerBufferLimit)\n            {\n                writeToQueue(buffer, s.get(), index, offset);\n            }\n            else\n            {\n                if (!offerColdPath(buffer, mask, index, offset, null, s))\n                {\n                    return i;\n                }\n            }\n        }\n        return limit;\n    }\n\n    @Override\n    public void drain(Consumer<E> c, WaitStrategy wait, ExitCondition exit)\n    {\n        MessagePassingQueueUtil.drain(this, c, wait, exit);\n    }\n\n    @Override\n    public void fill(Supplier<E> s, WaitStrategy wait, ExitCondition exit)\n    {\n        MessagePassingQueueUtil.fill(this, s, wait, exit);\n    }\n\n    /**\n     * {@inheritDoc}\n     * <p>\n     * This implementation is correct for single producer thread use only.\n     */\n    @Override\n    public boolean offer(final E e)\n    {\n        // Objects.requireNonNull(e);\n        if (null == e)\n        {\n            throw new NullPointerException();\n        }\n        // local load of field to avoid repeated loads after volatile reads\n        final E[] buffer = producerBuffer;\n        final long index = lpProducerIndex();\n        final long mask = producerMask;\n        final long offset = calcCircularRefElementOffset(index, mask);\n        // expected hot path\n        if (index < producerBufferLimit)\n        {\n            writeToQueue(buffer, e, index, offset);\n            return true;\n        }\n        return offerColdPath(buffer, mask, index, offset, e, null);\n    }\n\n    abstract boolean offerColdPath(\n        E[] buffer,\n        long mask,\n        long pIndex,\n        long offset,\n        E v,\n        Supplier<? extends E> s);\n\n    /**\n     * {@inheritDoc}\n     * <p>\n     * This implementation is correct for single consumer thread use only.\n     */\n    @SuppressWarnings(\"unchecked\")\n    @Override\n    public E poll()\n    {\n        // local load of field to avoid repeated loads after volatile reads\n        final E[] buffer = consumerBuffer;\n        final long index = lpConsumerIndex();\n        final long mask = consumerMask;\n        final long offset = calcCircularRefElementOffset(index, mask);\n        final Object e = lvRefElement(buffer, offset);\n        boolean isNextBuffer = e == JUMP;\n        if (null != e && !isNextBuffer)\n        {\n            soConsumerIndex(index + 1);// this ensures correctness on 32bit platforms\n            soRefElement(buffer, offset, null);\n            return (E) e;\n        }\n        else if (isNextBuffer)\n        {\n            return newBufferPoll(buffer, index);\n        }\n\n        return null;\n    }\n\n    /**\n     * {@inheritDoc}\n     * <p>\n     * This implementation is correct for single consumer thread use only.\n     */\n    @SuppressWarnings(\"unchecked\")\n    @Override\n    public E peek()\n    {\n        final E[] buffer = consumerBuffer;\n        final long index = lpConsumerIndex();\n        final long mask = consumerMask;\n        final long offset = calcCircularRefElementOffset(index, mask);\n        final Object e = lvRefElement(buffer, offset);\n        if (e == JUMP)\n        {\n            return newBufferPeek(buffer, index);\n        }\n\n        return (E) e;\n    }\n\n    final void linkOldToNew(\n        final long currIndex,\n        final E[] oldBuffer, final long offset,\n        final E[] newBuffer, final long offsetInNew,\n        final E e)\n    {\n        soRefElement(newBuffer, offsetInNew, e);\n        // link to next buffer and add next indicator as element of old buffer\n        soNext(oldBuffer, newBuffer);\n        soRefElement(oldBuffer, offset, JUMP);\n        // index is visible after elements (isEmpty/poll ordering)\n        soProducerIndex(currIndex + 1);// this ensures atomic write of long on 32bit platforms\n    }\n\n    final void writeToQueue(final E[] buffer, final E e, final long index, final long offset)\n    {\n        soRefElement(buffer, offset, e);\n        soProducerIndex(index + 1);// this ensures atomic write of long on 32bit platforms\n    }\n\n    private E newBufferPeek(final E[] buffer, final long index)\n    {\n        E[] nextBuffer = lvNextArrayAndUnlink(buffer);\n        consumerBuffer = nextBuffer;\n        final long mask = length(nextBuffer) - 2;\n        consumerMask = mask;\n        final long offset = calcCircularRefElementOffset(index, mask);\n        return lvRefElement(nextBuffer, offset);\n    }\n\n    private E newBufferPoll(final E[] buffer, final long index)\n    {\n        E[] nextBuffer = lvNextArrayAndUnlink(buffer);\n        consumerBuffer = nextBuffer;\n        final long mask = length(nextBuffer) - 2;\n        consumerMask = mask;\n        final long offset = calcCircularRefElementOffset(index, mask);\n        final E n = lvRefElement(nextBuffer, offset);\n        if (null == n)\n        {\n            throw new IllegalStateException(\"new buffer must have at least one element\");\n        }\n        else\n        {\n            soConsumerIndex(index + 1);// this ensures correctness on 32bit platforms\n            soRefElement(nextBuffer, offset, null);\n            return n;\n        }\n    }\n}\n",
        "simple_context": "package org.jctools.queues;\n\nimport org.jctools.queues.IndexedQueueSizeUtil.IndexedQueue;\n\nimport org.jctools.util.PortableJvmInfo;\n\nimport java.util.AbstractQueue;\n\nimport java.util.Iterator;\n\nimport static org.jctools.queues.LinkedArrayQueueUtil.length;\n\nimport static org.jctools.queues.LinkedArrayQueueUtil.nextArrayOffset;\n\nimport static org.jctools.util.UnsafeAccess.UNSAFE;\n\nimport static org.jctools.util.UnsafeAccess.fieldOffset;\n\nimport static org.jctools.util.UnsafeRefArrayAccess;\n\nabstract class BaseSpscLinkedArrayQueuePrePad extends AbstractQueue<E> implements IndexedQueue {\n    byte b000, b001, b002, b003, b004, b005, b006, b007;\n    byte b010, b011, b012, b013, b014, b015, b016, b017;\n    byte b020, b021, b022, b023, b024, b025, b026, b027;\n    byte b030, b031, b032, b033, b034, b035, b036, b037;\n    byte b040, b041, b042, b043, b044, b045, b046, b047;\n    byte b050, b051, b052, b053, b054, b055, b056, b057;\n    byte b060, b061, b062, b063, b064, b065, b066, b067;\n    byte b070, b071, b072, b073, b074, b075, b076, b077;\n    byte b100, b101, b102, b103, b104, b105, b106, b107;\n    byte b110, b111, b112, b113, b114, b115, b116, b117;\n    byte b120, b121, b122, b123, b124, b125, b126, b127;\n    byte b130, b131, b132, b133, b134, b135, b136, b137;\n    byte b140, b141, b142, b143, b144, b145, b146, b147;\n    byte b150, b151, b152, b153, b154, b155, b156, b157;\n}\n\nabstract class BaseSpscLinkedArrayQueueConsumerColdFields extends BaseSpscLinkedArrayQueuePrePad<E> {\n    protected long consumerMask;\n    protected E consumerBuffer;\n}\n\nabstract class BaseSpscLinkedArrayQueueConsumerField extends BaseSpscLinkedArrayQueueConsumerColdFields<E> {\n    static final private long C_INDEX_OFFSET;\n    volatile private long consumerIndex;\n    final public long lvConsumerIndex();\n    final long lpConsumerIndex();\n    final  soConsumerIndex(long newValue);\n}\n\nabstract class BaseSpscLinkedArrayQueueL2Pad extends BaseSpscLinkedArrayQueueConsumerField<E> {\n    byte b000, b001, b002, b003, b004, b005, b006, b007;\n    byte b010, b011, b012, b013, b014, b015, b016, b017;\n    byte b020, b021, b022, b023, b024, b025, b026, b027;\n    byte b030, b031, b032, b033, b034, b035, b036, b037;\n    byte b040, b041, b042, b043, b044, b045, b046, b047;\n    byte b050, b051, b052, b053, b054, b055, b056, b057;\n    byte b060, b061, b062, b063, b064, b065, b066, b067;\n    byte b070, b071, b072, b073, b074, b075, b076, b077;\n    byte b100, b101, b102, b103, b104, b105, b106, b107;\n    byte b110, b111, b112, b113, b114, b115, b116, b117;\n    byte b120, b121, b122, b123, b124, b125, b126, b127;\n    byte b130, b131, b132, b133, b134, b135, b136, b137;\n    byte b140, b141, b142, b143, b144, b145, b146, b147;\n    byte b150, b151, b152, b153, b154, b155, b156, b157;\n    byte b160, b161, b162, b163, b164, b165, b166, b167;\n    byte b170, b171, b172, b173, b174, b175, b176, b177;\n}\n\nabstract class BaseSpscLinkedArrayQueueProducerFields extends BaseSpscLinkedArrayQueueL2Pad<E> {\n    static final private long P_INDEX_OFFSET;\n    volatile private long producerIndex;\n    final public long lvProducerIndex();\n    final  soProducerIndex(long newValue);\n    final long lpProducerIndex();\n}\n\nabstract class BaseSpscLinkedArrayQueueProducerColdFields extends BaseSpscLinkedArrayQueueProducerFields<E> {\n    protected long producerBufferLimit;\n    protected long producerMask;\n    protected E producerBuffer;\n}\n\nabstract class BaseSpscLinkedArrayQueue extends BaseSpscLinkedArrayQueueProducerColdFields<E> implements MessagePassingQueue<E>, QueueProgressIndicators {\n    static final private Object JUMP;\n    final public Iterator<E> iterator();\n    final public int size();\n    final public boolean isEmpty();\n    public String toString();\n    public long currentProducerIndex();\n    public long currentConsumerIndex();\n    protected final  soNext(E curr, E next);\n    protected final E lvNextArrayAndUnlink(E curr);\n    public boolean relaxedOffer(E e);\n    public E relaxedPoll();\n    public E relaxedPeek();\n    public int drain(Consumer<E> c);\n    public int fill(Supplier<E> s);\n    public int drain(Consumer<E> c, int limit);\n    public int fill(Supplier<E> s, int limit);\n    public  drain(Consumer<E> c, WaitStrategy wait, ExitCondition exit);\n    public  fill(Supplier<E> s, WaitStrategy wait, ExitCondition exit);\n    public boolean offer(E e);\n    abstract boolean offerColdPath(E buffer, long mask, long pIndex, long offset, E v, Supplier<E> s);\n    public E poll();\n    public E peek();\n    final  linkOldToNew(long currIndex, E oldBuffer, long offset, E newBuffer, long offsetInNew, E e);\n    final  writeToQueue(E buffer, E e, long index, long offset);\n    private E newBufferPeek(E buffer, long index);\n    private E newBufferPoll(E buffer, long index);\n}\n\n"
    }
]